{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:0.5em;\n",
       "margin-bottom:0.5em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 1.7em;\n",
       "line-height:1.1em;\n",
       "text-align:left;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
       "margin-bottom: -0.1em;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.3em;\n",
       "line-height:1.3em;\n",
       "padding-left:1em;\n",
       "padding-right:1em;\n",
       "}\n",
       "\n",
       "tr.pseq_border{\n",
       " border-bottom:1pt solid black;\n",
       " border: 1px solid green;\n",
       " padding: 5px;\n",
       "}\n",
       "\n",
       ".pseq_class{\n",
       "font-weight:bold;\n",
       "color:blue;\n",
       "}\n",
       ".pseq_attr{\n",
       "font-weight:bold;\n",
       "font-style:italic;\n",
       "}\n",
       ".pseq_method{\n",
       "font-weight:bold;\n",
       "color:blue;\n",
       "}\n",
       ".pseq_args{\n",
       "font-weight:bold;\n",
       "}\n",
       "\n",
       "code.pseq_code{\n",
       "font-size:0.85em;\n",
       "}\n",
       "code.pseq_class{\n",
       "font-size:0.9em;\n",
       "font-weight:bold;\n",
       "color:blue;\n",
       "}\n",
       "code.pseq_method{\n",
       "font-size:0.9em;\n",
       "font-weight:bold;\n",
       "color:blue;\n",
       "}\n",
       "code.pseq_attr{\n",
       "font-size:0.9em;\n",
       "font-weight:bold;\n",
       "font-style:italic;\n",
       "}\n",
       "code.pseq_args{\n",
       "font-size:0.85em;\n",
       "font-weight:bold;\n",
       "}\n",
       "code.pseq_var{\n",
       "font-size:0.85em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use for customizing the display/format of the cells\n",
    "# for more info and resources check these links:\n",
    "# http://stackoverflow.com/questions/34303422/how-to-change-the-font-size-and-color-of-markdown-cell-in-ipython-py-2-7-noteb\n",
    "# http://nbviewer.jupyter.org/github/Carreau/posts/blob/master/Blog1.ipynb\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:0.5em;\n",
    "margin-bottom:0.5em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 1.7em;\n",
    "line-height:1.1em;\n",
    "text-align:left;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
    "margin-bottom: -0.1em;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.3em;\n",
    "line-height:1.3em;\n",
    "padding-left:1em;\n",
    "padding-right:1em;\n",
    "}\n",
    "\n",
    "tr.pseq_border{\n",
    " border-bottom:1pt solid black;\n",
    " border: 1px solid green;\n",
    " padding: 5px;\n",
    "}\n",
    "\n",
    ".pseq_class{\n",
    "font-weight:bold;\n",
    "color:blue;\n",
    "}\n",
    ".pseq_attr{\n",
    "font-weight:bold;\n",
    "font-style:italic;\n",
    "}\n",
    ".pseq_method{\n",
    "font-weight:bold;\n",
    "color:blue;\n",
    "}\n",
    ".pseq_args{\n",
    "font-weight:bold;\n",
    "}\n",
    "\n",
    "code.pseq_code{\n",
    "font-size:0.85em;\n",
    "}\n",
    "code.pseq_class{\n",
    "font-size:0.9em;\n",
    "font-weight:bold;\n",
    "color:blue;\n",
    "}\n",
    "code.pseq_method{\n",
    "font-size:0.9em;\n",
    "font-weight:bold;\n",
    "color:blue;\n",
    "}\n",
    "code.pseq_attr{\n",
    "font-size:0.9em;\n",
    "font-weight:bold;\n",
    "font-style:italic;\n",
    "}\n",
    "code.pseq_args{\n",
    "font-size:0.85em;\n",
    "font-weight:bold;\n",
    "}\n",
    "code.pseq_var{\n",
    "font-size:0.85em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* [1. Objectives and goals](#1.-Objectives-and-goals)\n",
    "* [2. Supported models](#2.-Supported-models)\n",
    "* [3. Model building workflow](#3.-Model-building-workflow)\n",
    "\t* [3.1 Parsing sequences/segments](#3.1-Parsing-sequences/segments)\n",
    "\t* [3.2 Building CRFs model](#3.2-Building-CRFs-model)\n",
    "\t* [3.3 Training CRFs model (i.e. estimating parameters)](#3.3-Training-CRFs-model-%28i.e.-estimating-parameters%29)\n",
    "\t\t* [3.3.1 Training methods -- optimization options](#3.3.1-Training-methods----optimization-options)\n",
    "\t\t* [3.3.2 Learning/estimating model parameters](#3.3.2-Learning/estimating-model-parameters)\n",
    "\t* [3.4 Using trained CRFs model](#3.4-Using-trained-CRFs-model)\n",
    "* [4. Applications](#4.-Applications)\n",
    "* [5. Reference/literature](#5.-Reference/literature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Objectives and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will learn about:\n",
    "<ul>\n",
    "<li> parsing, preparing and representing sequences in a training dataset for model building</li>\n",
    "<li> the different available CRF models in <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab package</a></li>\n",
    "<li> the process/workflow for buidling CRFs models</li>\n",
    "<li> training CRFs model and evaluating model performance</li>\n",
    "<li> reviving learned models and decoding new sequences</li>\n",
    "</ul>\n",
    "\n",
    "<strong><em>Reminder</em></strong>: To work with this tutorial interactively, we need first to clone the <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a> package to our disk locally and then navigate to <strong>[cloned_package_dir]/tutorials</strong> where <strong>[cloned_package_dir]</strong> is the path to the cloned package folder (see the tree path for display).\n",
    "<pre style=\"font-size:0.8em;\">\n",
    "├── pyseqlab\n",
    "    ├── tutorials\n",
    "    │   ├── datasets\n",
    "    │   │   ├── conll2000\n",
    "    │   │   ├── segments\n",
    "\n",
    "</pre>\n",
    "\n",
    "We suggest going through the earlier tutorials:\n",
    "<ol>\n",
    "<li><a href=\"sequence_and_input_structure.ipynb\">sequence_and_input_structure tutorial</a>\n",
    "<li><a href=\"templates_and_features_extraction.ipynb\">templates_and_feature_extraction tutorial</a></li>\n",
    "</ol>\n",
    "\n",
    "before continuing through this notebook. We will use part of the <a href=\"http://www.cnts.ua.ac.be/conll2000/chunking/\">CoNLL 2000 training dataset</a> throughout this tutorial.\n",
    "\n",
    "As a <strong><em>reminder</em></strong>, the CoNLL 2000 task states: <blockquote> Given a set of sentences (our sequences) where each sentence is composed of <span style=\"font-weight:bold;color:green;\">words</span> and their corresponding <span style=\"font-weight:bold;color:green;\">part-of-speech</span>, the goal is to predict the <span style=\"font-weight:bold;color:green;\">chunk/shallow parse label</span> of every word in the sentence. </blockquote>\n",
    "\n",
    "We start by parsing/reading the sentences in the training dataset into sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y sequence:\n",
      " ['B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'B-ADJP', 'B-PP', 'B-NP', 'B-NP', 'O', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "X sequence:\n",
      " {1: {'pos': 'NN', 'w': 'Confidence'}, 2: {'pos': 'IN', 'w': 'in'}, 3: {'pos': 'DT', 'w': 'the'}, 4: {'pos': 'NN', 'w': 'pound'}, 5: {'pos': 'VBZ', 'w': 'is'}, 6: {'pos': 'RB', 'w': 'widely'}, 7: {'pos': 'VBN', 'w': 'expected'}, 8: {'pos': 'TO', 'w': 'to'}, 9: {'pos': 'VB', 'w': 'take'}, 10: {'pos': 'DT', 'w': 'another'}, 11: {'pos': 'JJ', 'w': 'sharp'}, 12: {'pos': 'NN', 'w': 'dive'}, 13: {'pos': 'IN', 'w': 'if'}, 14: {'pos': 'NN', 'w': 'trade'}, 15: {'pos': 'NNS', 'w': 'figures'}, 16: {'pos': 'IN', 'w': 'for'}, 17: {'pos': 'NNP', 'w': 'September'}, 18: {'pos': ',', 'w': ','}, 19: {'pos': 'JJ', 'w': 'due'}, 20: {'pos': 'IN', 'w': 'for'}, 21: {'pos': 'NN', 'w': 'release'}, 22: {'pos': 'NN', 'w': 'tomorrow'}, 23: {'pos': ',', 'w': ','}, 24: {'pos': 'VB', 'w': 'fail'}, 25: {'pos': 'TO', 'w': 'to'}, 26: {'pos': 'VB', 'w': 'show'}, 27: {'pos': 'DT', 'w': 'a'}, 28: {'pos': 'JJ', 'w': 'substantial'}, 29: {'pos': 'NN', 'w': 'improvement'}, 30: {'pos': 'IN', 'w': 'from'}, 31: {'pos': 'NNP', 'w': 'July'}, 32: {'pos': 'CC', 'w': 'and'}, 33: {'pos': 'NNP', 'w': 'August'}, 34: {'pos': 'POS', 'w': \"'s\"}, 35: {'pos': 'JJ', 'w': 'near-record'}, 36: {'pos': 'NNS', 'w': 'deficits'}, 37: {'pos': '.', 'w': '.'}}\n",
      "----------------------------------------\n",
      "type(seq): <class 'pyseqlab.utilities.SequenceStruct'>\n",
      "number of parsed sequences is:  8936\n"
     ]
    }
   ],
   "source": [
    "# importing and defining relevant directories\n",
    "import sys\n",
    "import os\n",
    "# pyseqlab root directory\n",
    "pyseqlab_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# print(\"pyseqlab cloned dir:\", pyseqlab_dir)\n",
    "# inserting the pyseqlab directory to pythons system path -- if pyseqlab is already installed this could be commented out\n",
    "sys.path.insert(0, pyseqlab_dir)\n",
    "# current directory (tutorials)\n",
    "tutorials_dir = os.path.join(pyseqlab_dir, 'tutorials')\n",
    "# print(\"tutorials_dir:\", tutorials_dir)\n",
    "dataset_dir = os.path.join(tutorials_dir, 'datasets', 'conll2000')\n",
    "# print(\"dataset_dir:\", dataset_dir)\n",
    "from pyseqlab.utilities import DataFileParser\n",
    "# initialize a data file parser\n",
    "dparser = DataFileParser()\n",
    "# provide the options to parser such as the header info, the separator between words and if the y label is already existing\n",
    "# main means the header is found in the first line of the file\n",
    "header = \"main\"\n",
    "# y_ref is a boolean indicating if the label to predict is already found in the file\n",
    "y_ref = True\n",
    "# spearator between the words/observations\n",
    "column_sep = \" \"\n",
    "seqs = []\n",
    "for seq in dparser.read_file(os.path.join(dataset_dir, 'train.txt'), header, y_ref=y_ref, column_sep = column_sep):\n",
    "    seqs.append(seq)\n",
    "    \n",
    "# printing one sequence for display\n",
    "print(seqs[0])\n",
    "print(\"type(seq):\", type(seqs[0]))\n",
    "print(\"number of parsed sequences is: \", len(seqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Supported models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before going into model building and training workflow, it is important to discuss and highlight the CRFs models supported in <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a>. Currently, <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a> supports linear-chain (1) conditional random fields (CRFs) and (2) semi-Markov conditional random fields (semi-CRFs). Moreover, it supports first order models (i.e. modeling label patterns using at most two states/labels $\\le$ 2) and higher order models (i.e. modeling label patterns using &gt; 2 states). The table below provides an overview on the implemented CRFs classes. \n",
    "<table>\n",
    "<tr>\n",
    "    <th>Models</th>\n",
    "    <th colspan=\"2\">CRFs</th>\n",
    "    <th colspan=\"2\">semi-CRFs</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<th></th>\n",
    "<th>First order $\\le$ 2 </th>\n",
    "<th>Higher order &gt; 2</th>\n",
    "<th>First order $\\le$ 2 </th>\n",
    "<th>Higher order &gt; 2</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">FirstOrderCRF</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOCRF</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOCRFAD</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "<td></td>\n",
    "<td></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOSemiCRF</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOSemiCRFAD</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "<td>&#10003;</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "The displayed models are all based on the CRFs formalism (undirected discriminative graphical models) where differences among them arise due to: (1) the model order they can support and/or (2) the algorithms used to estimate the probability of the sequences and consequently affecting the gradient and log-likelihood computation. The semi-CRFs are considered generalization to CRFs as they tackle sequence segmentation problems (i.e. using segments in which labels/tags extend across several consecutive observations of the input sequence).  Hence, CRFs could be seen as a special case of semi-CRFs when the segment length is 1 (i.e. each label is assigned to one observation, see (Sarawagi et al., 2005) for further discussion).\n",
    "Below is another table comprising pointers to papers and literature in which the implemented CRFs and semi-CRFs models are based on:\n",
    "<table>\n",
    "<tr>\n",
    "    <th>Models</th>\n",
    "    <th>Short description</th>\n",
    "    <th>Reference</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">FirstOrderCRF</code></td>\n",
    "<td>Original formalism of first order CRF</td>\n",
    "<td>(Lafferty et al., 2001)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOCRF</code></td>\n",
    "<td>Higher order formulation of CRF</td>\n",
    "<td>(Ye, et al., 2009)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOSemiCRF</code></td>\n",
    "<td>Higher order formulation of semi-CRFs</td>\n",
    "<td>(Sarawagi et al., 2005, Cuong et al., 2014)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOCRFAD</code></td>\n",
    "<td>Higher order formulation of CRFs with a better/optimized forward-backward algorithm </td>\n",
    "<td>(Ye, et al., 2009; Vieira et al., 2016)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOSemiCRFAD</code></td>\n",
    "<td>Higher order formulation of semi-CRFs with a better/optimized forward-backward algorithm </td>\n",
    "<td>(Sarawagi et al., 2005, Cuong et al., 2014; Vieira et al., 2016)</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<strong>Question</strong>: So, how do we choose what models to use? <br/>\n",
    "<strong>Answer</strong>: It depends on the training data we have and the order of patterns we want to model.\n",
    "\n",
    "<strong>Examples: </strong>\n",
    "<ul>\n",
    "<li><code class=\"pseq_class\">FirstOrderCRF</code> could be used if our training data consists of sequences and we aim to model features that include at most one or two state/label transitions. Moreover, the <code class=\"pseq_class\">FirstOrderCRF</code> naturally supports the \n",
    "inclusion of __START__ state for building models supporting initial labels and transition label features at the starting position of the sequences. For more info about extracting features that include __START__ state, please see the <a href=\"templates_and_features_extraction.ipynb\">templates_and_feature_extraction tutorial</a>.</li><br/>\n",
    "\n",
    "<li><code class=\"pseq_class\">HOCRF</code> and <code class=\"pseq_class\">HOCRFAD</code> could be used if our training data consists of sequences and we aim to model features with first order and/or higher-order (i.e. that includes label pattern transitions with more than two states). There are no restrictions on the label patterns when using those models. Additionally, both models are equivalent to <code class=\"pseq_class\">FirstOrderCRF</code> when we model features with first order label patterns without including the __START__ state. However, there is a subtle difference between <code class=\"pseq_class\">HOCRF</code> and <code class=\"pseq_class\">HOCRFAD</code> models, where <code class=\"pseq_class\">HOCRFAD</code> provides a more <em>efficient implementation</em> for the forward-backward algorithm. In addition, the <code class=\"pseq_class\">HOCRFAD</code> supports gradient-based training methods while <code class=\"pseq_class\">HOCRF</code> supports perceptron/search-based training methods (see the training section for more info). Hence, we <strong>suggest</strong> using <code class=\"pseq_class\">HOCRFAD</code> as a primary choice in similar contexts/scenario.</li><br/>\n",
    "\n",
    "<li><code class=\"pseq_class\">HOSemiCRF</code> and <code class=\"pseq_class\">HOSemiCRFAD</code> could be used if our training data consists of <strong>segments</strong> or sequences and we aim to model features with first order and/or higher-order (i.e. that includes label pattern transitions with more than two states). There are no restrictions on the label patterns when using those models. However, there is a subtle difference between <code class=\"pseq_class\">HOSemiCRF</code> and <code class=\"pseq_class\">HOSemiCRFAD</code> models, where <code class=\"pseq_class\">HOSemiCRFAD</code> provides a more <em>efficient implementation</em> for the forward-backward algorithm. Both models support gradient-based and perceptron/search-based training methods. It is also worth to mention that these models are of particular use when we are dealing with <strong>segments</strong> even though they can incorporate sequences without any problems. Hence, we <strong>suggest</strong> using <code class=\"pseq_class\">HOSemiCRFAD</code> as a primary choice when we have <strong>segments</strong> and/or have no restriction on the order of label pattern transitions.</li>\n",
    "</ul>\n",
    "\n",
    "Now that we know the different implementaion of CRFs models, it is time to talk about another set of very related classes that are suffixed by <strong><em>ModelRepresentation</em></strong> (such as <code class=\"pseq_class\">FirstOrderCRFModelRepresentation</code> class). These classes primarily hold relevant data structures that are used by the CRFs models. Therefore, for every class representing a CRF model, we have a corresponding model representation class (i.e. <code class=\"pseq_class\">FirstOrderCRF</code> --- <code class=\"pseq_class\">FirstOrderCRFModelRepresentation</code>). Below is a table mapping between both set of classes:\n",
    "<table id=\"pseq_crfmodels_repr_map\">\n",
    "<tr>\n",
    "    <th>CRFs model</th>\n",
    "    <th>CRFs model representation</th>\n",
    "    <th>Module name</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">FirstOrderCRF</code></td>\n",
    "<td><code class=\"pseq_class\">FirstOrderCRFModelRepresentation</code></td>\n",
    "<td><strong>pyseqlab.fo_crf</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOCRF</code></td>\n",
    "<td><code class=\"pseq_class\">HOCRFModelRepresentation</code></td>\n",
    "<td><strong>pyseqlab.ho_crf</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOSemiCRF</code></td>\n",
    "<td><code class=\"pseq_class\">HOSemiCRFModelRepresentation</code></td>\n",
    "<td><strong>pyseqlab.hosemi_crf</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOCRFAD</code></td>\n",
    "<td><code class=\"pseq_class\">HOCRFADModelRepresentation</code></td>\n",
    "<td><strong>pyseqlab.ho_crf_ad</strong></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_class\">HOSemiCRFAD</code></td>\n",
    "<td><code class=\"pseq_class\">HOSemiCRFADModelRepresentation</code></td>\n",
    "<td><strong>pyseqlab.hosemi_crf_ad</strong></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "These two sets of classes are tied together. Whenever we want to use a CRF model class, another corresponding model representation class should be used. Both sets of classes are very important and will be tested when we examine the model building workflow in the following section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model building workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_modelbuild_workflow\"></a>\n",
    "A typical process for building CRF models starting from the file comprising the training data (i.e. sequences or segments) is described as follows:\n",
    "<ol>\n",
    "<li> We are given a dataset (i.e. file) comprising sequences or segments (see <a href=\"sequence_and_input_structure.ipynb\">sequence_and_input_structure tutorial</a> for a refresher).</li>\n",
    "<li> We read the file and generate sequences/segments</li>\n",
    "<li> We decide on a data split strategy in which we obtain a set of sequences for training CRFs model (training set) and another set of sequences for testing/validating the model (testing/validation set)</li>\n",
    "<li> We process the training set (i.e. comprising sequences) and dump them on disk in a relevant format to be later used in the learning framework </li>\n",
    "<li> We build a model based on the processed training set </li>\n",
    "<li> We train the model weights (i.e. estimate the feature weights) using one of the available training methods</li>\n",
    "<li> We test our model by evaluating its decoding performance using the sequences in the test/validation set</li>\n",
    "<li> The trained model is dumped on disk and is always available to be revived and used for decoding new sequences </li>\n",
    "</ol>\n",
    "\n",
    "\n",
    "The listed points represent a common and recurrent workflow in sequence labeling and segmentation problems. For this reason, <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a> provides a <code class=\"pseq_class\">GenericTrainingWorkflow</code> class that takes care of the tasks 1-8, which we aim to further explore in this section. \n",
    "\n",
    "But first, we describe the arguments passed to <code class=\"pseq_class\">GenericTrainingWorkflow</code> constructor:\n",
    "<ul>\n",
    "<li><code class=\"pseq_attr\">aextractor_obj</code>: initialized instance of <code class=\"pseq_class\">GenericAttributeExtractor</code> class/subclass (see attributes extraction in <a href=\"templates_and_features_extraction.ipynb\">templates_and_feature_extraction tutorial</a>) </li>\n",
    "<li><code class=\"pseq_attr\">fextractor_obj</code>: initialized instance of <code class=\"pseq_class\">FeatureExtractor</code> class/subclass (see <code class=\"pseq_class\">FOFeatureExtractor</code> or <code class=\"pseq_class\">HOFeatureExtractor</code> classes in the <a href=\"templates_and_features_extraction.ipynb\">templates_and_feature_extraction tutorial</a>)</li>\n",
    "<li><code class=\"pseq_attr\">feature_filter_obj</code>: <code class=\"pseq_code\" style=\"color:blue;\">None</code> or an initialized instance of <code class=\"pseq_class\">FeatureFilter</code> class (see feature filter section in the <a href=\"templates_and_features_extraction.ipynb\">templates_and_feature_extraction tutorial</a>)</li>\n",
    "<li><code class=\"pseq_attr\">model_repr_class</code>: the CRFs model representation class (see 2nd column <a href=\"#pseq_crfmodels_repr_map\"> in this table</a> for model representation classes)</li>\n",
    "<li><code class=\"pseq_attr\">model_class</code>: the CRFs model class (see 1st column <a href=\"pseq_crfmodels_repr_map\">in this table</a> for model classes)</li>\n",
    "<li><code class=\"pseq_attr\">root_dir</code>: string representing the directory/path where working directory will be created</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Parsing sequences/segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing a <code class=\"pseq_class\">GenericTrainingWorkflow</code> instance, we will use <code class=\"pseq_method\">seq_parsing_workflow(args)</code> method that handles points (1 to 4) in <a href=\"#pseq_modelbuild_workflow\">the above process</a>. This instance method has one argument and multiple keyword arguments.<br/>\n",
    "\n",
    "<strong>Args</strong>:\n",
    "<ul><li>\n",
    "<code class=\"pseq_args\">split_options</code>: dictionary representing options for performing data split strategy. The main key is <code class=\"pseq_var\">'method'</code> which specifies the method for data splitting. It can assume one of the following values <code class=\"pseq_var\">{'none', 'random', 'cross_validation', 'wsample'}</code>. Depending on the chosen method, additional keys and values are specified. For example:\n",
    "<pre style='font-size:0.75em;'>\n",
    "     To perform cross validation, we need to specify\n",
    "               - cross_validation for the `method`\n",
    "               - the number of folds for the `k_fold`\n",
    "               \n",
    "               options = {'method':'cross_validation',\n",
    "                          'k_fold':number\n",
    "                         }\n",
    "                         \n",
    "      To perform random splitting, we need to specify\n",
    "               - random for the `method`\n",
    "               - number of splits for the `num_splits`\n",
    "               - size of the training set in percentage for the `trainset_size`\n",
    "               \n",
    "               options = {'method':'random',\n",
    "                          'num_splits':number,\n",
    "                          'trainset_size':percentage\n",
    "                         }\n",
    "                         \n",
    "      To perform nothing (i.e. use all data as training), we need to specify\n",
    "               - none for the `method`\n",
    "               \n",
    "               options = {'method':'none'\n",
    "                         }\n",
    "                         \n",
    "      To perform weighted sampling (i.e. based on sequences' length), we need to specify\n",
    "               - wsample for the `method`\n",
    "               \n",
    "               options = {'method':'wsample'\n",
    "                         }\n",
    "                   \n",
    "</pre>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "For the keyword arguments, we have two main ones depending on the input (file or sequences) we want to pass.\n",
    "\n",
    "<strong>Keyword args</strong>:\n",
    "\n",
    "<ul><li>\n",
    "<a id=\"pseq_seqfile_option\"></a>\n",
    "<code class=\"pseq_args\">seq_file</code>: string representing the path to the file comprising the sequences/segments. For this option, we have to specify additionally the following keyword arguments: <ul><li><code class=\"pseq_args\">data_parser_options</code>: a dictionary defining the arguments of the <code class=\"pseq_method\">read_file(args)</code> method in the <code class=\"pseq_class\">DataFileParser</code> class (see <a href=\"sequence_and_input_structure.ipynb\">sequence_and_input_structure tutorial</a> for more info about this class).</li>\n",
    "<li><code class=\"pseq_args\">num_seqs</code>: the maximum number of sequences to read/parse from a file. By default it is equal to <code class=\"pseq_code\">-1</code>, which will read the whole file</li><br/>\n",
    "<strong>Example</strong>:\n",
    "<pre style='font-size:0.75em;'>\n",
    "parser_options = {'header': header argument in <code class=\"pseq_method\">read_file(args)</code>\n",
    "                  'y_ref': y_ref argument in <code class=\"pseq_method\">read_file(args)</code>\n",
    "                  'column_sep: column_sep argument in <code class=\"pseq_method\">read_file(args)</code>\n",
    "                  'seg_other_symbol': the seg_other_symbol argument in <code class=\"pseq_method\">read_file(args) </code>           \n",
    "                  }\n",
    "\n",
    "workflow.seq_parsing_workflow(split_options, seq_file=path, \n",
    "                              data_parser_options=parser_options,\n",
    "                              num_seqs=-1)                     \n",
    "</pre></ul></li><br/>\n",
    "\n",
    "<li><code class=\"pseq_args\">seqs</code>: list of sequences that are instances of <code class=\"pseq_class\">SequenceStruct</code> class</li><br/>\n",
    "</ul>\n",
    "\n",
    "We start by initializing an instance of the <code class=\"pseq_class\">GenericTrainingWorkflow</code> class that uses the following setup:\n",
    "\n",
    "<ul>\n",
    "<li>Use <code class=\"pseq_class\">GenericAttributeExtractor</code> with attribute description dictionary equal to\n",
    "<pre style='font-size:0.8em;'>\n",
    "\n",
    "            {'w':{'description': 'word observation track', \n",
    "                  'encoding':'categorical'},\n",
    "             'pos':{'description':'part of speech track',\n",
    "                    'encoding':'categorical'}\n",
    "            }\n",
    "</pre>\n",
    "</li>\n",
    "<li>For both attribute tracks <code class=\"pseq_code\"><strong>w</strong></code> and <code class=\"pseq_code\"><strong>pos</strong></code> we generate the same feature template (<code class=\"pseq_var\">template_XY</code>) that guides/instructs feature extraction by:\n",
    "    <ul><li>Using a centered window of size 3 at each position in the sequence while extracting unigrams and bigrams and joining them with the current label/state.</li></ul>\n",
    "<li>For the label transition template (<code class=\"pseq_var\">template_Y</code>), we request to use the current label, previous and current label at each position in the sequence</li>\n",
    "<li>Use first order feature extractor (<code class=\"pseq_class\">FOFeatureExtractor</code>)</li>\n",
    "<li>Use first order CRFs model representation class (<code class=\"pseq_class\">FirstOrderCRFModelRepresentation</code>)</li>\n",
    "<li>Use first order CRFs model class (<code class=\"pseq_class\">FirstOrderCRF</code>)</li>\n",
    "</ul>\n",
    "\n",
    "Then, we show the two approaches for using the <code class=\"pseq_method\">sequence_parsing_workflow(args)</code> method. The <a href=\"#pseq_datasplit_demo1\">first approach</a> uses the <code class=\"pseq_args\">seqs</code> keyword argument while the <a href=\"#pseq_datasplit_demo2\">second approach</a> uses the <code class=\"pseq_args\">seq_file</code> keyword argument.\n",
    "\n",
    "An example of the return value <code class=\"pseq_code\">data_split</code> for the different options we specified: \n",
    "\n",
    "<strong>'method':'none' -- all training data is used</strong>\n",
    "<pre style='font-size:0.78em;'>\n",
    "data_split:\n",
    "{0: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}}\n",
    "</pre>\n",
    "\n",
    "<strong>'method':'cross_validation' -- 5 folds </strong>\n",
    "<pre style='font-size:0.78em;'>\n",
    "data_split: \n",
    "{0: {'train': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], \n",
    "     'test': [1, 2, 3, 4, 5]}, \n",
    " 1: {'train': [1, 2, 3, 4, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], \n",
    "     'test': [6, 7, 8, 9, 10]}, \n",
    " 2: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], \n",
    "     'test': [11, 12, 13, 14, 15]}, \n",
    " 3: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 22, 23, 24, 25], \n",
    "     'test': [16, 17, 18, 19, 20]},\n",
    " 4: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \n",
    "     'test': [21, 22, 23, 24, 25]}\n",
    "}\n",
    "</pre>\n",
    "<strong>'method':'random' -- 3 splits with train set size 80% </strong>\n",
    "<pre style='font-size:0.78em;'>\n",
    "data_split: 'random'\n",
    "{0: {'train': [22, 3, 6, 24, 9, 13, 1, 8, 25, 16, 15, 14, 20, 2, 4, 10, 7, 19, 17, 11], \n",
    "     'test': [18, 21, 12, 5, 23]}, \n",
    " 1: {'train': [23, 12, 11, 17, 19, 9, 8, 24, 20, 10, 22, 18, 21, 25, 1, 4, 3, 7, 14, 6], \n",
    "     'test': [16, 2, 13, 5, 15]}, \n",
    " 2: {'train': [16, 9, 21, 17, 5, 18, 25, 20, 23, 13, 12, 24, 3, 14, 8, 19, 10, 22, 11, 7], \n",
    "     'test': [1, 2, 4, 6, 15]}\n",
    "}\n",
    "</pre>\n",
    "<strong>'method':'wsample' -- with train set size 80% </strong>\n",
    "<pre style='font-size:0.78em;'>\n",
    "data_split: 'wsample'\n",
    "{0: {'train': [7, 11, 17, 16, 14, 5, 2, 3, 4, 22, 1, 15, 12, 13, 20, 25, 24], \n",
    "     'test': [19, 10, 18, 6, 23, 8, 21, 9]}\n",
    "}\n",
    "</pre>\n",
    "\n",
    "At this point, the sequences are processed, dumped on disk and were assigned a unique id. The parsed sequences will be organized in a folder/directory structure where a <code class=\"pseq_code\">reference_corpus</code> folder suffixed with date/time string is created under the <code class=\"pseq_code\">root</code> directory that we already specified in the <code class=\"pseq_class\">GenericTrainingWorkflow</code> constructor. Under this folder, the process will generate a folder for every sequence under <code class=\"pseq_code\">global_features</code> folder. Additionally, a log file named <code class=\"pseq_code\">log.txt</code> will be added. It will contain the logs generated during the parsing process and info about the total number of features created once we create a CRFs model.\n",
    "<pre style=\"font-size:0.8em;\">\n",
    "working_dir\n",
    "│   ├── reference_corpus_2017_5_17-8_56_49_631884\n",
    "│   │   ├── data_split\n",
    "│   │   ├── global_features\n",
    "│   │   │   ├── log.txt\n",
    "│   │   │   ├── seq_1\n",
    "│   │   │   ├── seq_10\n",
    "│   │   │   ├── seq_11\n",
    "│   │   │   ├── seq_12\n",
    "│   │   │   ├── seq_13\n",
    "│   │   │   ├── seq_14\n",
    "│   │   │   ├── seq_15\n",
    "│   │   │   ├── seq_16\n",
    "│   │   │   ├── seq_17\n",
    "│   │   │   ├── seq_18\n",
    "│   │   │   ├── seq_19\n",
    "│   │   │   ├── seq_2\n",
    "│   │   │   ├── seq_20\n",
    "│   │   │   ├── seq_21\n",
    "│   │   │   ├── seq_22\n",
    "│   │   │   ├── seq_23\n",
    "│   │   │   ├── seq_24\n",
    "│   │   │   ├── seq_25\n",
    "│   │   │   ├── seq_3\n",
    "│   │   │   ├── seq_4\n",
    "│   │   │   ├── seq_5\n",
    "│   │   │   ├── seq_6\n",
    "│   │   │   ├── seq_7\n",
    "│   │   │   ├── seq_8\n",
    "│   │   │   ├── seq_9\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr_desc {'pos': {'description': 'part of speech track', 'repr_func': <bound method GenericAttributeExtractor._represent_categorical_attr of <pyseqlab.attributes_extraction.GenericAttributeExtractor object at 0x7fcdc20924a8>>, 'encoding': 'categorical'}, 'w': {'description': 'word observation track', 'repr_func': <bound method GenericAttributeExtractor._represent_categorical_attr of <pyseqlab.attributes_extraction.GenericAttributeExtractor object at 0x7fcdc20924a8>>, 'encoding': 'categorical'}}\n",
      "\n",
      "template_XY: \n",
      "{'pos': {(0, 1): ((0,),), (0,): ((0,),), (-1,): ((0,),), (1,): ((0,),), (-1, 0): ((0,),)}, 'w': {(0, 1): ((0,),), (0,): ((0,),), (-1,): ((0,),), (1,): ((0,),), (-1, 0): ((0,),)}}\n",
      "\n",
      "template_Y:\n",
      "{'Y': [(0,), (-1, 0)]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,6)\n",
    "from pyseqlab.workflow import GenericTrainingWorkflow\n",
    "from pyseqlab.features_extraction import FOFeatureExtractor\n",
    "from pyseqlab.attributes_extraction import GenericAttributeExtractor\n",
    "from pyseqlab.utilities import TemplateGenerator\n",
    "from pyseqlab.fo_crf import FirstOrderCRF, FirstOrderCRFModelRepresentation\n",
    "from pyseqlab.utilities import ReaderWriter\n",
    "# attribute description for both w and pos attribute tracks\n",
    "attr_desc = {'w':{'description': 'word observation track', \n",
    "                  'encoding':'categorical'\n",
    "                 },\n",
    "             'pos':{'description':'part of speech track',\n",
    "                    'encoding':'categorical'}\n",
    "            }\n",
    "# initialize the attribute extractor instance\n",
    "generic_attr_extractor = GenericAttributeExtractor(attr_desc)\n",
    "print(\"attr_desc {}\".format(generic_attr_extractor.attr_desc))\n",
    "print()\n",
    "# use same template for both tracks w and pos\n",
    "template_XY = {}\n",
    "template_gen = TemplateGenerator()\n",
    "for track_name in ('w', 'pos'):\n",
    "    template_gen.generate_template_XY(track_name, ('1-gram:2-grams', range(-1,2)), '1-state', template_XY)\n",
    "template_Y = template_gen.generate_template_Y('1-state:2-states')\n",
    "print(\"template_XY: \")\n",
    "print(template_XY)\n",
    "print()\n",
    "print(\"template_Y:\")\n",
    "print(template_Y)\n",
    "print()\n",
    "# initialize first order feature extractor instance\n",
    "fo_fe = FOFeatureExtractor(template_XY, template_Y, attr_desc, start_state=False)\n",
    "# no feature filter \n",
    "fe_filter = None\n",
    "working_dir = tutorials_dir\n",
    "workflow = GenericTrainingWorkflow(generic_attr_extractor, fo_fe, fe_filter, \n",
    "                                   FirstOrderCRFModelRepresentation, FirstOrderCRF,\n",
    "                                   working_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_datasplit_demo1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seqs keyword argument option\n",
      "\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  none\n",
      "{0: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  cross_validation\n",
      "{0: {'test': [1, 2, 3, 4, 5], 'train': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}, 1: {'test': [6, 7, 8, 9, 10], 'train': [1, 2, 3, 4, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}, 2: {'test': [11, 12, 13, 14, 15], 'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}, 3: {'test': [16, 17, 18, 19, 20], 'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 22, 23, 24, 25]}, 4: {'test': [21, 22, 23, 24, 25], 'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  random\n",
      "{0: {'test': [25, 18, 4, 21, 22], 'train': [14, 11, 6, 16, 10, 8, 15, 1, 7, 2, 24, 17, 13, 5, 19, 23, 12, 3, 9, 20]}, 1: {'test': [25, 10, 19, 21, 14], 'train': [20, 8, 9, 11, 5, 23, 1, 22, 3, 16, 7, 24, 2, 12, 4, 15, 6, 13, 17, 18]}, 2: {'test': [9, 2, 19, 20, 17], 'train': [15, 14, 6, 24, 10, 18, 5, 8, 7, 4, 22, 1, 11, 12, 25, 16, 23, 21, 13, 3]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  wsample\n",
      "{0: {'test': [6, 23, 11, 16, 3, 12, 13, 24], 'train': [4, 1, 22, 7, 17, 14, 10, 19, 5, 2, 18, 8, 15, 25, 21, 20, 9]}}\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Using seqs keyword argument option\")\n",
    "print()\n",
    "data_split_options = [{'method':'none'}, #  no splitting -- use all data\n",
    "                      {'method':'cross_validation', 'k_fold':5}, # cross_validation 5-fold,\n",
    "                      {'method':'random', 'num_splits':3, 'trainset_size':80}, #  3 random splits with train set 80%\n",
    "                      {'method':'wsample', 'trainset_size':80}# weighted sample by sequence length\n",
    "                     ]\n",
    "for split_option in data_split_options:\n",
    "    data_split = workflow.seq_parsing_workflow(split_option, \n",
    "                                               seqs=seqs[:25], \n",
    "                                               full_parsing = True)\n",
    "    print(\"data_split: \", split_option['method'])\n",
    "    print(data_split)\n",
    "    print()\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_datasplit_demo2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seq_file keyword argument option\n",
      "\n",
      "1 sequences have been processed\n",
      "2 sequences have been processed\n",
      "3 sequences have been processed\n",
      "4 sequences have been processed\n",
      "5 sequences have been processed\n",
      "6 sequences have been processed\n",
      "7 sequences have been processed\n",
      "8 sequences have been processed\n",
      "9 sequences have been processed\n",
      "10 sequences have been processed\n",
      "11 sequences have been processed\n",
      "12 sequences have been processed\n",
      "13 sequences have been processed\n",
      "14 sequences have been processed\n",
      "15 sequences have been processed\n",
      "16 sequences have been processed\n",
      "17 sequences have been processed\n",
      "18 sequences have been processed\n",
      "19 sequences have been processed\n",
      "20 sequences have been processed\n",
      "21 sequences have been processed\n",
      "22 sequences have been processed\n",
      "23 sequences have been processed\n",
      "24 sequences have been processed\n",
      "25 sequences have been processed\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  none\n",
      "{0: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "1 sequences have been processed\n",
      "2 sequences have been processed\n",
      "3 sequences have been processed\n",
      "4 sequences have been processed\n",
      "5 sequences have been processed\n",
      "6 sequences have been processed\n",
      "7 sequences have been processed\n",
      "8 sequences have been processed\n",
      "9 sequences have been processed\n",
      "10 sequences have been processed\n",
      "11 sequences have been processed\n",
      "12 sequences have been processed\n",
      "13 sequences have been processed\n",
      "14 sequences have been processed\n",
      "15 sequences have been processed\n",
      "16 sequences have been processed\n",
      "17 sequences have been processed\n",
      "18 sequences have been processed\n",
      "19 sequences have been processed\n",
      "20 sequences have been processed\n",
      "21 sequences have been processed\n",
      "22 sequences have been processed\n",
      "23 sequences have been processed\n",
      "24 sequences have been processed\n",
      "25 sequences have been processed\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  cross_validation\n",
      "{0: {'test': [1, 2, 3, 4, 5], 'train': [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}, 1: {'test': [6, 7, 8, 9, 10], 'train': [1, 2, 3, 4, 5, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}, 2: {'test': [11, 12, 13, 14, 15], 'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}, 3: {'test': [16, 17, 18, 19, 20], 'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 22, 23, 24, 25]}, 4: {'test': [21, 22, 23, 24, 25], 'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "1 sequences have been processed\n",
      "2 sequences have been processed\n",
      "3 sequences have been processed\n",
      "4 sequences have been processed\n",
      "5 sequences have been processed\n",
      "6 sequences have been processed\n",
      "7 sequences have been processed\n",
      "8 sequences have been processed\n",
      "9 sequences have been processed\n",
      "10 sequences have been processed\n",
      "11 sequences have been processed\n",
      "12 sequences have been processed\n",
      "13 sequences have been processed\n",
      "14 sequences have been processed\n",
      "15 sequences have been processed\n",
      "16 sequences have been processed\n",
      "17 sequences have been processed\n",
      "18 sequences have been processed\n",
      "19 sequences have been processed\n",
      "20 sequences have been processed\n",
      "21 sequences have been processed\n",
      "22 sequences have been processed\n",
      "23 sequences have been processed\n",
      "24 sequences have been processed\n",
      "25 sequences have been processed\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  random\n",
      "{0: {'test': [25, 10, 11, 5, 23], 'train': [21, 22, 1, 15, 3, 18, 13, 8, 9, 7, 20, 2, 19, 14, 12, 4, 17, 6, 24, 16]}, 1: {'test': [24, 10, 3, 4, 15], 'train': [12, 1, 21, 9, 19, 8, 7, 11, 6, 5, 16, 18, 22, 20, 25, 23, 14, 13, 17, 2]}, 2: {'test': [21, 3, 12, 20, 23], 'train': [16, 5, 8, 7, 18, 19, 22, 1, 15, 6, 10, 24, 14, 9, 11, 13, 25, 4, 2, 17]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "1 sequences have been processed\n",
      "2 sequences have been processed\n",
      "3 sequences have been processed\n",
      "4 sequences have been processed\n",
      "5 sequences have been processed\n",
      "6 sequences have been processed\n",
      "7 sequences have been processed\n",
      "8 sequences have been processed\n",
      "9 sequences have been processed\n",
      "10 sequences have been processed\n",
      "11 sequences have been processed\n",
      "12 sequences have been processed\n",
      "13 sequences have been processed\n",
      "14 sequences have been processed\n",
      "15 sequences have been processed\n",
      "16 sequences have been processed\n",
      "17 sequences have been processed\n",
      "18 sequences have been processed\n",
      "19 sequences have been processed\n",
      "20 sequences have been processed\n",
      "21 sequences have been processed\n",
      "22 sequences have been processed\n",
      "23 sequences have been processed\n",
      "24 sequences have been processed\n",
      "25 sequences have been processed\n",
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "data_split:  wsample\n",
      "{0: {'test': [6, 23, 16, 11, 5, 8, 20, 9], 'train': [4, 22, 1, 3, 19, 7, 14, 2, 10, 17, 18, 15, 12, 13, 25, 21, 24]}}\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Using seq_file keyword argument option\")\n",
    "print()\n",
    "# get the path to CoNLL 2000 training file\n",
    "train_file = os.path.join(dataset_dir, 'train.txt')\n",
    "# parser options to read train_file\n",
    "parser_options = {'header': 'main', # main means the header is found in the first line of the file\n",
    "                  'y_ref':True, # y_ref is a boolean indicating if the label to predict is already found in the file\n",
    "                  'column_sep': \" \",\n",
    "                  'seg_other_symbol':None # spearator between the words/observations\n",
    "                  }\n",
    "# parse only 25 sequences for comparison to our previous approach\n",
    "num_seqs = 25\n",
    "# use all passed data as training data \n",
    "data_split_options = [{'method':'none'}, #  no splitting -- use all data\n",
    "                      {'method':'cross_validation', 'k_fold':5}, # cross_validation 5-fold,\n",
    "                      {'method':'random', 'num_splits':3, 'trainset_size':80}, #  3 random splits with train set 80%\n",
    "                      {'method':'wsample', 'trainset_size':80}# weighted sample by sequence length\n",
    "                     ]\n",
    "for split_option in data_split_options:\n",
    "    data_split = workflow.seq_parsing_workflow(split_option, \n",
    "                                               seq_file=train_file,\n",
    "                                               data_parser_options=parser_options,\n",
    "                                               num_seqs=num_seqs,\n",
    "                                               full_parse = True)\n",
    "    print(\"data_split: \", split_option['method'])\n",
    "    print(data_split)\n",
    "    print()\n",
    "    print(\"-\"*50)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Building CRFs model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we parsed and generated a <code class=\"pseq_var\">data_split</code> (i.e. decided the sequences to be used for training/building a CRFs model), we can proceed to build our first CRFs model. Using <code class=\"pseq_method\">build_crf_model(args)</code> method, we can generate our CRFs model that will be an instance of <code class=\"pseq_class\">FirstOrderCRF</code> because it was the class we passed to the <code class=\"pseq_class\">GenericTrainingWorkflow</code> constructor. The <code class=\"pseq_method\">build_crf_model(args)</code> takes the following main arguments:\n",
    "<ul>\n",
    "<li><code class=\"pseq_args\">seqs_id</code>: list of sequence ids referring to the sequences to be used for building the model. These ids are the generated ones after we parsed and prepared the sequences. They are found in the <code class=\"pseq_var\">data_split</code> variable.</li>\n",
    "<li><code class=\"pseq_args\">folder_name</code>: string representing the folder name which will be created under the <code class=\"pseq_code\">reference_corpus_date/time</code> directory. It will hold additional processed sequence info generated by the model building process.</li>\n",
    "</ul>\n",
    "\n",
    "The method will return a CRFs model (<a href=\"#pseq_buildcrfmodel\">see code</a>) that we will later train its parameters (i.e. the weights of the features in the model). Moreover, if we inspect the <code class=\"pseq_code\">reference_corpus_date/time</code> directory, we will notice a new folder having a suffix equal to the <code class=\"pseq_args\">folder_name</code> we specified. More importantly, if we check <code class=\"pseq_code\">log.txt</code> in <code class=\"pseq_code\">global_features</code> folder, we will see the generated log for the number of features created. \n",
    "Tree path/directory of reference corpus:\n",
    "<pre style=\"font-size:0.8em;\">\n",
    "working_dir\n",
    "│   ├── reference_corpus_2017_5_17-8_56_49_631884\n",
    "│   │   ├── data_split\n",
    "│   │   ├── global_features\n",
    "│   │   │   ├── log.txt\n",
    "│   │   │   ├── seq_1\n",
    "│   │   │   ├── seq_10\n",
    "│   │   │   ├── seq_11\n",
    "│   │   │   ├── seq_12\n",
    "│   │   │   ├── seq_13\n",
    "│   │   │   ├── seq_14\n",
    "│   │   │   ├── seq_15\n",
    "│   │   │   ├── seq_16\n",
    "│   │   │   ├── seq_17\n",
    "│   │   │   ├── seq_18\n",
    "│   │   │   ├── seq_19\n",
    "│   │   │   ├── seq_2\n",
    "│   │   │   ├── seq_20\n",
    "│   │   │   ├── seq_21\n",
    "│   │   │   ├── seq_22\n",
    "│   │   │   ├── seq_23\n",
    "│   │   │   ├── seq_24\n",
    "│   │   │   ├── seq_25\n",
    "│   │   │   ├── seq_3\n",
    "│   │   │   ├── seq_4\n",
    "│   │   │   ├── seq_5\n",
    "│   │   │   ├── seq_6\n",
    "│   │   │   ├── seq_7\n",
    "│   │   │   ├── seq_8\n",
    "│   │   │   ├── seq_9\n",
    "│   │   ├── model_activefeatures_f_0 \n",
    "</pre>\n",
    "\n",
    "Inspecting <code class=\"pseq_code\">log.txt</code> under <code class=\"pseq_code\">global_features</code> folder we get the following excerpt:\n",
    "<pre style=\"font-size:0.8em;\">\n",
    "---Preparing/parsing sequences--- starting time: 2017-05-17 08:56:49.635522 \n",
    "Number of sequences prepared/parsed: 25 \n",
    "---Preparing/parsing sequences--- end time: 2017-05-17 08:56:49.691309 \n",
    "\n",
    " \n",
    "---Generating Global Features F_j(X,Y)--- starting time: 2017-05-17 08:56:49.703424 \n",
    "Number of instances/training data processed: 25\n",
    "---Generating Global Features F_j(X,Y)--- end time: 2017-05-17 08:56:49.901177 \n",
    "\n",
    " \n",
    "---Constructing model--- starting time: 2017-05-17 08:56:49.912083 \n",
    "Number of instances/training data processed: 25\n",
    "Number of features: 3318 \n",
    "Number of labels: 13 \n",
    "---Constructing model--- end time: 2017-05-17 08:57:05.827288 \n",
    "</pre>\n",
    "\n",
    "To verify and see these features, we can inspect them by checking the output of <a href=\"#pseq_inspect_modelfeatures\">this code snippet</a> below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_buildcrfmodel\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumping globalfeatures -- processed seqs:  1\n",
      "dumping globalfeatures -- processed seqs:  2\n",
      "dumping globalfeatures -- processed seqs:  3\n",
      "dumping globalfeatures -- processed seqs:  4\n",
      "dumping globalfeatures -- processed seqs:  5\n",
      "dumping globalfeatures -- processed seqs:  6\n",
      "dumping globalfeatures -- processed seqs:  7\n",
      "dumping globalfeatures -- processed seqs:  8\n",
      "dumping globalfeatures -- processed seqs:  9\n",
      "dumping globalfeatures -- processed seqs:  10\n",
      "dumping globalfeatures -- processed seqs:  11\n",
      "dumping globalfeatures -- processed seqs:  12\n",
      "dumping globalfeatures -- processed seqs:  13\n",
      "dumping globalfeatures -- processed seqs:  14\n",
      "dumping globalfeatures -- processed seqs:  15\n",
      "dumping globalfeatures -- processed seqs:  16\n",
      "dumping globalfeatures -- processed seqs:  17\n",
      "dumping globalfeatures -- processed seqs:  18\n",
      "dumping globalfeatures -- processed seqs:  19\n",
      "dumping globalfeatures -- processed seqs:  20\n",
      "dumping globalfeatures -- processed seqs:  21\n",
      "dumping globalfeatures -- processed seqs:  22\n",
      "dumping globalfeatures -- processed seqs:  23\n",
      "dumping globalfeatures -- processed seqs:  24\n",
      "dumping globalfeatures -- processed seqs:  25\n",
      "\n",
      "data_split: 'none' option \n",
      "{0: {'train': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]}}\n",
      "\n",
      "constructing model -- processed seqs:  1\n",
      "constructing model -- processed seqs:  2\n",
      "constructing model -- processed seqs:  3\n",
      "constructing model -- processed seqs:  4\n",
      "constructing model -- processed seqs:  5\n",
      "constructing model -- processed seqs:  6\n",
      "constructing model -- processed seqs:  7\n",
      "constructing model -- processed seqs:  8\n",
      "constructing model -- processed seqs:  9\n",
      "constructing model -- processed seqs:  10\n",
      "constructing model -- processed seqs:  11\n",
      "constructing model -- processed seqs:  12\n",
      "constructing model -- processed seqs:  13\n",
      "constructing model -- processed seqs:  14\n",
      "constructing model -- processed seqs:  15\n",
      "constructing model -- processed seqs:  16\n",
      "constructing model -- processed seqs:  17\n",
      "constructing model -- processed seqs:  18\n",
      "constructing model -- processed seqs:  19\n",
      "constructing model -- processed seqs:  20\n",
      "constructing model -- processed seqs:  21\n",
      "constructing model -- processed seqs:  22\n",
      "constructing model -- processed seqs:  23\n",
      "constructing model -- processed seqs:  24\n",
      "constructing model -- processed seqs:  25\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "\n",
      "type of built model:\n",
      "<class 'pyseqlab.fo_crf.FirstOrderCRF'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use all passed data as training data -- no splitting\n",
    "data_split_options = {'method':'none'}\n",
    "data_split = workflow.seq_parsing_workflow(data_split_options, seqs=seqs[:25])\n",
    "print()\n",
    "print(\"data_split: 'none' option \")\n",
    "print(data_split)\n",
    "print()\n",
    "\n",
    "# build and return a CRFs model\n",
    "# folder name will be f_0 as fold 0\n",
    "crf_m = workflow.build_crf_model(data_split[0]['train'], \"f_0\")\n",
    "print()\n",
    "print(\"type of built model:\")\n",
    "print(type(crf_m))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_inspect_modelfeatures\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of generated features:\n",
      "3318\n",
      "features:\n",
      "{'I-NP|B-ADJP': Counter({'I-NP|B-ADJP': 1}), 'B-ADJP|B-SBAR': Counter({'B-ADJP|B-SBAR': 2}), 'O|B-VP': Counter({'O|B-VP': 8}), 'I-ADJP|B-PP': Counter({'I-ADJP|B-PP': 1}), 'B-NP|B-NP': Counter({'B-NP|B-NP': 3}), 'B-PP|I-PP': Counter({'B-PP|I-PP': 1}), 'B-NP|B-ADVP': Counter({'B-NP|B-ADVP': 1}), 'B-ADJP': Counter({'B-ADJP': 12, 'pos[1]=IN': 6, 'pos[0]=JJ': 6, 'pos[0]|pos[1]=JJ|IN': 4, 'pos[0]=RB': 3, 'pos[0]|pos[1]=RB|JJ': 2, 'pos[-1]|pos[0]=IN|JJ': 2, 'pos[-1]=IN': 2, 'pos[1]=JJ': 2, 'w[-1]=remains': 2, 'pos[-1]=NN': 2, 'w[0]=necessary': 2, 'w[1]=for': 2, 'w[-1]|w[0]=remains|fairly': 2, 'pos[-1]=VBZ': 2, 'pos[-1]|pos[0]=VBZ|RB': 2, 'w[-1]=if': 2, 'w[-1]|w[0]=if|necessary': 2, 'w[0]=fairly': 2, 'w[1]=than': 1, 'w[-1]|w[0]=-LRB-|$': 1, 'pos[-1]|pos[0]=(|$': 1, 'pos[0]=JJR': 1, 'w[-1]|w[0]=sterling|firm': 1, 'pos[-1]=PRP': 1, 'w[0]|w[1]=firm|at': 1, 'w[-1]|w[0]=still|quite': 1, 'w[0]=$': 1, 'w[0]|w[1]=$|3.2': 1, 'w[-1]|w[0]=pushed|higher': 1, 'pos[-1]|pos[0]=NN|NN': 1, 'w[0]|w[1]=necessary|.': 1, 'pos[0]|pos[1]=RB|VBN': 1, 'w[0]|w[1]=due|for': 1, 'pos[0]|pos[1]=NN|IN': 1, 'pos[0]=NN': 1, 'pos[0]|pos[1]=JJ|.': 1, 'w[0]=other': 1, 'pos[0]=$': 1, 'w[1]=that': 1, 'w[-1]=sterling': 1, 'w[0]=higher': 1, 'w[1]=clouded': 1, 'w[1]=strong': 1, 'w[-1]=moment': 1, 'w[-1]=still': 1, 'pos[-1]|pos[0]=PRP|JJ': 1, 'pos[0]|pos[1]=JJ|TO': 1, 'pos[-1]=VBP': 1, 'pos[1]=.': 1, 'pos[0]|pos[1]=$|CD': 1, 'w[0]|w[1]=higher|if': 1, 'pos[-1]|pos[0]=VBN|JJR': 1, 'pos[-1]|pos[0]=RB|RB': 1, 'w[-1]=it': 1, 'pos[-1]|pos[0]=NN|JJ': 1, 'w[-1]=,': 1, 'w[0]=firm': 1, 'pos[-1]|pos[0]=,|JJ': 1, 'pos[-1]=RB': 1, 'w[0]=quite': 1, 'w[0]|w[1]=bullish|for': 1, 'pos[1]=CD': 1, 'w[-1]=-LRB-': 1, 'pos[-1]|pos[0]=VBP|JJ': 1, 'pos[1]=VBN': 1, 'w[0]=bullish': 1, 'w[0]|w[1]=fairly|clouded': 1, 'w[1]=3.2': 1, 'pos[1]=TO': 1, 'w[0]|w[1]=other|than': 1, 'w[0]|w[1]=fairly|pessimistic': 1, 'w[-1]|w[0]=moment|other': 1, 'w[1]=if': 1, 'w[-1]|w[0]=it|clear': 1, 'w[0]|w[1]=clear|that': 1, 'w[1]=to': 1, 'w[-1]|w[0]=,|due': 1, 'w[1]=pessimistic': 1, 'pos[0]|pos[1]=JJR|IN': 1, 'w[-1]=pushed': 1, 'w[0]|w[1]=necessary|to': 1, 'w[1]=.': 1, 'pos[-1]=,': 1, 'w[0]=clear': 1, 'w[0]|w[1]=quite|strong': 1, 'w[1]=at': 1, 'pos[-1]=(': 1, 'w[-1]=are': 1, 'pos[-1]=VBN': 1, 'w[0]=due': 1, 'w[-1]|w[0]=are|bullish': 1}), 'B-PP|B-PP': Counter({'B-PP|B-PP': 1}), 'B-ADVP|I-ADVP': Counter({'B-ADVP|I-ADVP': 3}), 'B-NP|O': Counter({'B-NP|O': 15}), 'B-VP|B-SBAR': Counter({'B-VP|B-SBAR': 3}), 'I-NP|O': Counter({'I-NP|O': 31}), 'I-ADVP|B-PP': Counter({'I-ADVP|B-PP': 1}), 'I-VP|I-VP': Counter({'I-VP|I-VP': 23}), 'B-ADJP|I-ADJP': Counter({'B-ADJP|I-ADJP': 3}), 'I-NP|B-ADVP': Counter({'I-NP|B-ADVP': 2}), 'B-ADVP|B-SBAR': Counter({'B-ADVP|B-SBAR': 1}), 'I-ADVP|B-NP': Counter({'I-ADVP|B-NP': 1}), 'I-ADVP': Counter({'I-ADVP': 3, 'pos[0]=RB': 2, 'pos[1]=DT': 1, 'pos[-1]=RB': 1, 'w[-1]=that': 1, 'w[-1]|w[0]=that|quickly': 1, 'w[0]=quickly': 1, 'w[-1]|w[0]=very|heavily': 1, 'w[1]=on': 1, 'pos[1]=.': 1, 'pos[0]=JJS': 1, 'pos[-1]=DT': 1, 'w[-1]=at': 1, 'pos[0]|pos[1]=RB|.': 1, 'pos[-1]|pos[0]=IN|JJS': 1, 'pos[-1]=IN': 1, 'w[1]=.': 1, 'pos[-1]|pos[0]=RB|RB': 1, 'pos[0]|pos[1]=RB|IN': 1, 'w[-1]|w[0]=at|least': 1, 'pos[0]|pos[1]=JJS|DT': 1, 'w[1]=some': 1, 'w[-1]=very': 1, 'pos[-1]|pos[0]=DT|RB': 1, 'w[0]=least': 1, 'w[0]|w[1]=quickly|.': 1, 'w[0]|w[1]=least|some': 1, 'w[0]=heavily': 1, 'pos[1]=IN': 1, 'w[0]|w[1]=heavily|on': 1}), 'B-NP|B-VP': Counter({'B-NP|B-VP': 24}), 'I-ADJP|O': Counter({'I-ADJP|O': 2}), 'O|B-PP': Counter({'O|B-PP': 3}), 'I-VP|B-PP': Counter({'I-VP|B-PP': 6}), 'B-NP|B-SBAR': Counter({'B-NP|B-SBAR': 2}), 'B-ADVP|B-ADJP': Counter({'B-ADVP|B-ADJP': 1}), 'B-SBAR': Counter({'B-SBAR': 17, 'pos[0]=IN': 16, 'w[0]=that': 10, 'pos[1]=DT': 6, 'pos[0]|pos[1]=IN|DT': 6, 'pos[-1]=NN': 4, 'pos[-1]|pos[0]=NN|IN': 4, 'w[0]=if': 3, 'w[1]=the': 3, 'w[1]=a': 3, 'w[0]|w[1]=that|a': 3, 'pos[0]|pos[1]=IN|NN': 2, 'pos[1]=NN': 2, 'pos[1]=NNS': 2, 'pos[-1]|pos[0]=VB|IN': 2, 'pos[-1]|pos[0]=JJ|IN': 2, 'pos[-1]|pos[0]=VBZ|IN': 2, 'pos[0]|pos[1]=IN|JJ': 2, 'pos[-1]=VB': 2, 'pos[-1]=VBZ': 2, 'pos[0]|pos[1]=IN|NNS': 2, 'w[0]|w[1]=if|necessary': 2, 'w[0]|w[1]=that|the': 2, 'pos[1]=JJ': 2, 'pos[-1]=JJ': 2, 'w[1]=necessary': 2, 'pos[1]=EX': 1, 'w[1]=he': 1, 'w[-1]|w[0]=again|if': 1, 'pos[-1]=VBD': 1, 'w[0]|w[1]=even|if': 1, 'w[-1]|w[0]=expected|as': 1, 'pos[1]=PRP': 1, 'w[0]=even': 1, 'w[-1]=audience': 1, 'w[-1]=believes': 1, 'pos[-1]=IN': 1, 'w[-1]|w[0]=that|even': 1, 'pos[0]|pos[1]=IN|RB': 1, 'pos[0]|pos[1]=RB|IN': 1, 'w[-1]|w[0]=believes|that': 1, 'w[1]=Britain': 1, 'w[-1]|w[0]=``|If': 1, 'pos[-1]=``': 1, 'w[1]=trade': 1, 'w[-1]=suggestions': 1, 'pos[0]|pos[1]=IN|PRP': 1, 'pos[1]=NNP': 1, 'w[-1]|w[0]=suggest|that': 1, 'w[0]=because': 1, 'pos[1]=RB': 1, 'w[0]|w[1]=that|much': 1, 'w[-1]=higher': 1, 'w[-1]=sign': 1, 'w[-1]=warned': 1, 'w[1]=rates': 1, 'w[0]|w[1]=that|he': 1, 'w[-1]|w[0]=warned|that': 1, 'w[-1]=expected': 1, 'pos[0]|pos[1]=IN|NNP': 1, 'w[-1]|w[0]=dive|if': 1, 'w[0]|w[1]=that|Britain': 1, 'w[-1]|w[0]=promise|that': 1, 'pos[-1]=NNS': 1, 'w[-1]=again': 1, 'pos[-1]=RB': 1, 'w[-1]=that': 1, 'w[0]|w[1]=that|even': 1, 'w[-1]|w[0]=ensure|that': 1, 'w[-1]|w[0]=clear|that': 1, 'w[1]=investors': 1, 'w[-1]=dive': 1, 'w[1]=there': 1, 'pos[-1]|pos[0]=JJR|IN': 1, 'pos[-1]=JJR': 1, 'w[-1]|w[0]=suggestions|that': 1, 'pos[-1]|pos[0]=VBN|IN': 1, 'pos[-1]|pos[0]=IN|RB': 1, 'pos[0]|pos[1]=IN|EX': 1, 'w[-1]|w[0]=audience|that': 1, 'pos[-1]|pos[0]=NNS|IN': 1, 'w[1]=if': 1, 'w[0]=as': 1, 'pos[1]=IN': 1, 'w[-1]=``': 1, 'w[-1]=promise': 1, 'pos[-1]|pos[0]=VBD|IN': 1, 'pos[-1]|pos[0]=``|IN': 1, 'pos[0]=RB': 1, 'w[0]=If': 1, 'w[0]|w[1]=If|there': 1, 'w[1]=even': 1, 'w[-1]|w[0]=sign|that': 1, 'w[-1]=clear': 1, 'w[0]|w[1]=as|the': 1, 'w[-1]|w[0]=higher|if': 1, 'w[0]|w[1]=because|investors': 1, 'pos[-1]|pos[0]=RB|IN': 1, 'w[-1]=suggest': 1, 'w[-1]=warns': 1, 'w[0]|w[1]=that|rates': 1, 'pos[-1]=VBN': 1, 'w[1]=much': 1, 'w[-1]|w[0]=warns|that': 1, 'w[-1]|w[0]=much|because': 1, 'w[-1]=ensure': 1, 'w[0]|w[1]=if|trade': 1, 'w[-1]=much': 1}), 'I-ADVP|O': Counter({'I-ADVP|O': 1}), 'B-NP|B-PP': Counter({'B-NP|B-PP': 9}), 'I-ADJP': Counter({'pos[-1]=RB': 3, 'I-ADJP': 3, 'w[-1]=fairly': 2, 'pos[-1]|pos[0]=RB|JJ': 2, 'pos[0]=JJ': 2, 'w[0]|w[1]=strong|,': 1, 'pos[0]|pos[1]=JJ|,': 1, 'w[-1]|w[0]=fairly|clouded': 1, 'w[1]=,': 1, 'w[1]=about': 1, 'pos[1]=,': 1, 'w[1]=.': 1, 'w[-1]|w[0]=fairly|pessimistic': 1, 'w[0]|w[1]=pessimistic|about': 1, 'w[-1]|w[0]=quite|strong': 1, 'w[0]=pessimistic': 1, 'w[0]=clouded': 1, 'pos[1]=IN': 1, 'pos[0]=VBN': 1, 'pos[0]|pos[1]=JJ|IN': 1, 'w[0]|w[1]=clouded|.': 1, 'pos[-1]|pos[0]=RB|VBN': 1, 'w[-1]=quite': 1, 'pos[1]=.': 1, 'pos[0]|pos[1]=VBN|.': 1, 'w[0]=strong': 1}), 'B-SBAR|I-SBAR': Counter({'B-SBAR|I-SBAR': 1}), 'I-NP|B-NP': Counter({'I-NP|B-NP': 7}), 'I-VP|B-ADJP': Counter({'I-VP|B-ADJP': 1}), 'B-ADVP|O': Counter({'B-ADVP|O': 7}), 'I-VP': Counter({'I-VP': 54, 'pos[0]=VB': 27, 'w[-1]=to': 13, 'pos[-1]=TO': 13, 'pos[1]=VB': 12, 'pos[0]=VBN': 12, 'pos[-1]|pos[0]=TO|VB': 12, 'pos[-1]=MD': 11, 'pos[1]=DT': 10, 'pos[-1]=VBZ': 10, 'w[1]=to': 9, 'pos[1]=TO': 9, 'pos[-1]|pos[0]=MD|VB': 9, 'pos[0]|pos[1]=VB|DT': 8, 'pos[0]=TO': 7, 'w[0]=to': 7, 'pos[0]|pos[1]=TO|VB': 7, 'pos[-1]=VB': 6, 'pos[1]=IN': 6, 'pos[-1]=VBN': 5, 'pos[-1]|pos[0]=VBZ|VBN': 5, 'pos[-1]=RB': 5, 'pos[1]=VBN': 5, 'pos[0]=RB': 5, 'pos[0]|pos[1]=VB|TO': 5, 'w[0]=be': 4, 'pos[0]|pos[1]=VBN|TO': 4, 'w[-1]=has': 4, 'pos[-1]|pos[0]=VBN|TO': 4, 'pos[-1]|pos[0]=RB|VB': 4, 'pos[0]|pos[1]=RB|VB': 4, 'w[-1]=will': 4, 'w[-1]=is': 4, 'pos[-1]|pos[0]=VB|TO': 3, 'pos[0]|pos[1]=VB|NN': 3, 'pos[1]=NN': 3, \"w[-1]=n't\": 3, 'w[1]=the': 3, 'pos[0]|pos[1]=VB|IN': 3, 'pos[-1]|pos[0]=VB|VBN': 3, 'pos[1]=JJ': 3, 'pos[0]|pos[1]=VBN|IN': 3, 'w[1]=a': 3, \"w[0]=n't\": 3, 'w[-1]=be': 3, 'w[1]=that': 3, 'pos[0]|pos[1]=VB|VBN': 3, 'w[-1]=could': 3, 'pos[0]|pos[1]=VB|JJ': 3, 'w[-1]|w[0]=will|want': 2, 'w[0]=narrow': 2, 'w[-1]=want': 2, 'w[-1]|w[0]=to|increase': 2, 'pos[-1]|pos[0]=VBZ|VBG': 2, 'w[1]=by': 2, 'pos[1]=NNS': 2, 'w[1]=increase': 2, 'w[-1]|w[0]=to|show': 2, 'w[0]=show': 2, 'pos[-1]|pos[0]=MD|RB': 2, 'pos[-1]|pos[0]=VBZ|RB': 2, 'w[0]=take': 2, 'w[-1]=can': 2, 'w[0]|w[1]=want|to': 2, 'pos[0]|pos[1]=VB|NNS': 2, 'w[1]=further': 2, 'w[0]=increase': 2, 'w[0]=want': 2, 'pos[-1]=VBP': 2, 'pos[1]=PRP': 2, 'w[0]=expected': 2, 'w[-1]=does': 2, 'w[0]|w[1]=show|a': 2, 'w[0]|w[1]=narrow|to': 2, 'w[0]|w[1]=to|increase': 2, 'pos[0]=VBG': 2, 'w[-1]|w[0]=want|to': 2, 'w[1]=expected': 2, 'w[0]=eroded': 1, 'w[0]=boost': 1, 'w[-1]=being': 1, 'pos[0]|pos[1]=RB|VBN': 1, 'w[0]|w[1]=prepared|to': 1, 'w[-1]=been': 1, 'w[0]|w[1]=been|eroded': 1, 'w[0]|w[1]=not|allow': 1, 'w[-1]|w[0]=has|been': 1, 'w[-1]|w[0]=prepared|to': 1, \"w[0]|w[1]=n't|suggest\": 1, 'w[0]|w[1]=take|another': 1, \"w[-1]|w[0]=n't|suggest\": 1, 'w[0]=made': 1, 'w[0]|w[1]=be|pushed': 1, \"w[-1]|w[0]=n't|decline\": 1, 'w[1]=itself': 1, 'w[0]|w[1]=lead|to': 1, 'w[-1]|w[0]=to|go': 1, 'w[0]|w[1]=expected|as': 1, 'w[1]=only': 1, 'w[0]|w[1]=increase|base': 1, 'w[0]|w[1]=widely|expected': 1, 'w[0]|w[1]=increased|the': 1, 'pos[-1]=VBG': 1, 'w[0]|w[1]=to|see': 1, 'pos[1]=JJR': 1, 'w[0]=ensure': 1, 'w[0]|w[1]=defend|the': 1, 'w[0]=increased': 1, 'w[0]=pushed': 1, 'w[0]|w[1]=allow|the': 1, 'w[-1]|w[0]=to|boost': 1, 'w[1]=it': 1, 'w[0]|w[1]=see|further': 1, 'w[0]|w[1]=announce|any': 1, 'w[0]|w[1]=undermined|by': 1, 'w[-1]|w[0]=expected|to': 1, 'w[-1]|w[0]=has|helped': 1, 'w[0]|w[1]=to|show': 1, 'w[-1]|w[0]=are|topped': 1, 'w[-1]=expected': 1, 'w[1]=show': 1, 'w[0]|w[1]=decline|further': 1, 'w[-1]|w[0]=does|take': 1, 'w[-1]|w[0]=is|slowing': 1, 'w[0]|w[1]=helped|to': 1, 'w[-1]|w[0]=to|prevent': 1, 'w[-1]|w[0]=to|be': 1, 'w[0]|w[1]=ensure|that': 1, 'w[0]=transforming': 1, 'pos[-1]=DT': 1, 'w[1]=decline': 1, 'w[-1]=helped': 1, 'w[0]|w[1]=forced|to': 1, 'w[0]|w[1]=topped|only': 1, 'w[-1]|w[0]=be|undermined': 1, 'w[0]|w[1]=both|ensure': 1, 'pos[-1]|pos[0]=VBP|VBN': 1, 'w[-1]|w[0]=is|widely': 1, 'w[0]=prevent': 1, 'w[1]=higher': 1, 'w[-1]|w[0]=to|defend': 1, 'w[0]=prepared': 1, 'w[0]=announce': 1, 'w[0]|w[1]=transforming|itself': 1, 'w[-1]|w[0]=has|made': 1, 'w[0]=helped': 1, 'w[-1]|w[0]=to|take': 1, 'w[-1]|w[0]=helped|to': 1, \"w[-1]|w[0]=n't|advance\": 1, 'pos[-1]|pos[0]=VBN|VBN': 1, 'w[1]=interest': 1, \"w[-1]|w[0]=wo|n't\": 1, 'w[0]=slowing': 1, 'w[-1]|w[0]=should|reduce': 1, 'w[0]=decline': 1, 'w[-1]|w[0]=been|eroded': 1, 'w[0]|w[1]=go|into': 1, 'pos[0]=DT': 1, 'pos[0]|pos[1]=VBN|JJR': 1, 'w[0]=both': 1, 'w[1]=much': 1, 'w[0]=forced': 1, 'w[0]=advance': 1, 'pos[0]|pos[1]=VBN|RB': 1, 'w[-1]|w[0]=has|increased': 1, 'w[-1]=forced': 1, 'w[-1]=fail': 1, 'w[0]|w[1]=suggest|that': 1, 'w[0]|w[1]=expected|to': 1, 'w[0]=go': 1, \"w[0]|w[1]=n't|advance\": 1, 'w[0]=not': 1, \"w[-1]|w[0]=do|n't\": 1, 'pos[0]|pos[1]=VBN|VBN': 1, 'w[-1]|w[0]=both|ensure': 1, 'w[1]=as': 1, 'w[-1]=both': 1, 'w[-1]|w[0]=could|lead': 1, 'w[0]=undermined': 1, 'w[-1]|w[0]=will|narrow': 1, 'w[1]=undermined': 1, 'pos[0]|pos[1]=VBG|DT': 1, 'pos[0]|pos[1]=VBN|PRP': 1, 'w[-1]|w[0]=widely|expected': 1, 'pos[0]|pos[1]=VBG|PRP': 1, 'pos[0]|pos[1]=VBN|DT': 1, 'w[0]|w[1]=increase|interest': 1, 'w[1]=fears': 1, 'w[-1]|w[0]=will|be': 1, 'w[0]|w[1]=slowing|that': 1, 'pos[-1]|pos[0]=TO|DT': 1, 'w[0]|w[1]=be|an': 1, 'w[1]=prevent': 1, 'w[-1]|w[0]=being|forced': 1, 'w[1]=go': 1, 'w[0]=see': 1, 'w[1]=any': 1, 'w[-1]|w[0]=can|be': 1, 'w[0]=topped': 1, 'w[0]|w[1]=to|take': 1, 'w[1]=allow': 1, 'w[-1]|w[0]=is|prepared': 1, 'w[0]|w[1]=to|go': 1, 'w[-1]|w[0]=fail|to': 1, 'w[0]=lead': 1, 'w[0]=defend': 1, 'w[0]=been': 1, 'w[-1]=do': 1, 'w[1]=eroded': 1, 'w[0]|w[1]=to|prevent': 1, 'w[-1]|w[0]=be|pushed': 1, 'w[0]=suggest': 1, 'w[-1]|w[0]=forced|to': 1, 'w[-1]=not': 1, 'w[0]|w[1]=pushed|higher': 1, 'pos[-1]|pos[0]=VBP|RB': 1, 'pos[-1]|pos[0]=VBG|VBN': 1, \"w[-1]|w[0]=does|n't\": 1, 'w[0]|w[1]=advance|much': 1, 'w[-1]|w[0]=is|transforming': 1, 'w[0]|w[1]=be|undermined': 1, 'w[0]=widely': 1, 'w[-1]=wo': 1, 'w[-1]|w[0]=be|expected': 1, 'w[1]=see': 1, 'pos[-1]|pos[0]=DT|VB': 1, 'pos[0]|pos[1]=DT|VB': 1, 'w[0]|w[1]=made|it': 1, 'w[-1]|w[0]=not|allow': 1, 'pos[-1]|pos[0]=RB|VBN': 1, 'w[1]=base': 1, \"w[0]|w[1]=n't|decline\": 1, 'w[1]=place': 1, 'w[1]=ensure': 1, 'w[1]=into': 1, 'w[-1]|w[0]=could|narrow': 1, 'pos[1]=RB': 1, 'w[1]=an': 1, 'w[1]=take': 1, 'pos[-1]|pos[0]=VBZ|VB': 1, 'w[-1]|w[0]=can|not': 1, 'w[0]|w[1]=boost|exports': 1, 'w[0]=reduce': 1, 'w[-1]=widely': 1, 'w[1]=exports': 1, 'w[0]|w[1]=reduce|fears': 1, 'w[-1]|w[0]=to|announce': 1, 'w[-1]=should': 1, 'w[1]=another': 1, 'w[-1]=prepared': 1, 'w[1]=suggest': 1, 'w[0]|w[1]=eroded|by': 1, 'w[0]|w[1]=take|place': 1, 'w[0]=allow': 1, 'w[0]|w[1]=be|expected': 1, 'w[-1]=are': 1, 'w[-1]|w[0]=could|be': 1, 'w[-1]|w[0]=to|see': 1, 'w[1]=advance': 1, 'w[-1]|w[0]=to|both': 1, 'w[1]=pushed': 1, 'w[0]|w[1]=prevent|a': 1}), 'B-VP|B-ADJP': Counter({'B-VP|B-ADJP': 3}), 'B-NP|B-ADJP': Counter({'B-NP|B-ADJP': 2}), 'I-VP|B-SBAR': Counter({'I-VP|B-SBAR': 3}), 'B-VP|B-ADVP': Counter({'B-VP|B-ADVP': 4}), 'I-SBAR|B-NP': Counter({'I-SBAR|B-NP': 1}), 'I-NP|I-NP': Counter({'I-NP|I-NP': 86}), 'I-NP|B-PP': Counter({'I-NP|B-PP': 38}), 'B-PP|B-ADVP': Counter({'B-PP|B-ADVP': 1}), 'I-NP': Counter({'I-NP': 203, 'pos[0]=NN': 97, 'pos[-1]=DT': 64, 'pos[1]=NN': 50, 'pos[1]=IN': 41, 'pos[-1]=JJ': 38, 'w[-1]=the': 38, 'pos[0]|pos[1]=NN|IN': 34, 'pos[-1]|pos[0]=JJ|NN': 32, 'pos[-1]=NN': 29, 'pos[-1]|pos[0]=DT|NN': 29, 'pos[0]=JJ': 28, 'pos[0]|pos[1]=JJ|NN': 25, 'pos[-1]=NNP': 25, 'pos[0]=NNP': 25, 'pos[0]=NNS': 22, 'pos[-1]|pos[0]=DT|JJ': 21, 'pos[-1]|pos[0]=NNP|NNP': 16, 'pos[-1]=CD': 15, 'w[-1]=a': 15, 'pos[-1]|pos[0]=NN|NNS': 14, 'pos[0]=CD': 14, 'pos[1]=,': 13, 'w[1]=,': 13, 'pos[1]=.': 12, 'w[1]=.': 12, 'pos[-1]|pos[0]=NN|NN': 12, 'pos[1]=NNS': 11, 'pos[1]=CD': 11, 'w[1]=in': 10, 'pos[0]|pos[1]=NN|NN': 10, 'pos[0]|pos[1]=NN|NNS': 9, 'pos[-1]|pos[0]=CD|NN': 8, 'pos[0]|pos[1]=NN|VBZ': 8, 'pos[1]=VBZ': 8, 'w[1]=of': 8, 'pos[1]=VBP': 8, 'w[1]=from': 7, 'pos[1]=NNP': 7, 'pos[0]|pos[1]=NN|,': 7, 'pos[0]|pos[1]=NNS|VBP': 7, 'pos[1]=TO': 6, 'w[-1]=trade': 6, 'pos[-1]=POS': 6, 'w[1]=to': 6, \"w[-1]='s\": 6, 'pos[0]|pos[1]=NNP|,': 6, 'pos[1]=VBD': 6, 'w[0]=%': 6, 'pos[1]=MD': 6, 'pos[-1]|pos[0]=NNP|NN': 6, 'pos[0]|pos[1]=CD|CD': 5, 'pos[1]=CC': 5, 'w[0]=figures': 5, 'pos[0]=#': 5, 'w[-1]=#': 5, 'pos[0]|pos[1]=NNP|NNP': 5, 'w[1]=billion': 5, 'pos[0]|pos[1]=#|CD': 5, 'pos[0]|pos[1]=CD|NN': 5, 'w[-1]=Mr.': 5, 'w[0]=trade': 5, 'w[0]=billion': 5, 'w[0]=#': 5, 'pos[-1]|pos[0]=#|CD': 5, 'w[1]=for': 5, 'pos[-1]|pos[0]=CD|CD': 5, 'pos[-1]=PRP$': 5, 'pos[-1]=#': 5, 'pos[0]|pos[1]=NNP|NN': 5, 'w[0]=current': 4, 'w[-1]|w[0]=trade|figures': 4, 'w[0]=deficit': 4, 'pos[0]|pos[1]=NN|TO': 4, 'w[-1]=current': 4, 'pos[0]|pos[1]=NNS|.': 4, 'pos[-1]|pos[0]=DT|NNS': 4, 'w[0]=rates': 4, 'w[0]=quarter': 4, 'pos[0]|pos[1]=NN|CC': 4, 'pos[1]=POS': 4, \"w[1]='s\": 4, 'pos[0]|pos[1]=NN|MD': 4, 'w[-1]=U.K.': 4, 'w[1]=quarter': 4, 'pos[1]=JJ': 4, 'w[1]=and': 4, 'pos[0]|pos[1]=NNS|IN': 4, 'w[0]=policy': 3, 'w[0]=account': 3, 'w[-1]=his': 3, 'pos[-1]|pos[0]=DT|NNP': 3, 'pos[-1]=RB': 3, 'w[1]=figures': 3, 'w[1]=account': 3, 'w[1]=are': 3, 'w[0]=economy': 3, 'w[0]=Lawson': 3, 'w[-1]=The': 3, 'w[1]=is': 3, 'pos[0]|pos[1]=NNP|.': 3, 'w[0]=second': 3, 'pos[0]|pos[1]=NNP|VBD': 3, 'w[-1]=billion': 3, 'pos[-1]=CC': 3, 'pos[0]|pos[1]=NNP|POS': 3, 'w[0]|w[1]=trade|figures': 3, 'w[-1]=consumer': 3, 'w[0]=data': 3, 'w[0]=economist': 3, 'w[-1]=%': 3, 'w[1]=that': 3, 'w[-1]|w[0]=current|account': 3, 'pos[0]=CC': 3, 'pos[0]|pos[1]=NN|JJ': 3, 'w[0]=pound': 3, 'w[-1]|w[0]=the|second': 3, 'pos[-1]|pos[0]=POS|NN': 3, 'w[-1]|w[0]=the|pound': 3, 'pos[-1]|pos[0]=DT|#': 3, 'w[0]|w[1]=current|account': 3, 'w[-1]|w[0]=the|trade': 3, 'w[0]=Dillow': 3, 'pos[0]|pos[1]=NN|.': 3, 'w[1]=%': 3, 'w[1]=deficit': 3, 'pos[0]|pos[1]=VBN|NN': 2, 'w[0]|w[1]=second|quarter': 2, 'w[1]=improvement': 2, 'w[0]|w[1]=House|speech': 2, 'w[-1]|w[0]=U.K.|economist': 2, 'w[0]=Mansion': 2, 'w[1]=House': 2, 'pos[0]|pos[1]=NNS|TO': 2, 'w[0]|w[1]=%|from': 2, 'w[-1]=Mansion': 2, 'pos[-1]|pos[0]=JJ|NNS': 2, 'w[-1]=bad': 2, 'w[0]=slowdown': 2, 'w[-1]=last': 2, 'w[-1]=sharp': 2, 'w[1]=``': 2, 'pos[-1]=VBN': 2, 'pos[-1]|pos[0]=PRP$|NNP': 2, 'w[0]|w[1]=Mansion|House': 2, 'w[-1]|w[0]=second|quarter': 2, 'w[1]=1.3': 2, 'w[-1]|w[0]=Mr.|Dillow': 2, 'w[-1]=House': 2, 'w[1]=said': 2, 'w[-1]=base': 2, 'w[0]|w[1]=Dillow|said': 2, 'pos[1]=RB': 2, 'w[-1]=and': 2, 'w[-1]=1.3': 2, 'w[1]=gap': 2, 'w[-1]|w[0]=interest|rates': 2, 'w[-1]|w[0]=monetary|policy': 2, 'pos[-1]|pos[0]=VBN|NN': 2, 'pos[0]|pos[1]=CD|.': 2, 'w[-1]=interest': 2, 'w[0]=sharp': 2, 'pos[0]|pos[1]=NN|``': 2, 'w[0]=gap': 2, 'w[0]=improvement': 2, 'w[-1]|w[0]=the|government': 2, 'w[0]=government': 2, 'w[-1]=substantial': 2, 'pos[0]=VBN': 2, 'pos[-1]|pos[0]=CC|NNP': 2, 'w[-1]=account': 2, 'w[-1]|w[0]=a|substantial': 2, 'pos[-1]|pos[0]=JJ|NNP': 2, 'w[-1]|w[0]=Mansion|House': 2, 'w[1]=slowdown': 2, 'w[0]=speech': 2, 'w[0]=bad': 2, 'w[0]=goods': 2, 'w[0]=August': 2, 'w[-1]=another': 2, 'pos[0]|pos[1]=NN|VBD': 2, 'w[0]|w[1]=bad|trade': 2, 'w[0]|w[1]=1.3|billion': 2, 'w[0]|w[1]=improvement|from': 2, 'pos[1]=VBG': 2, 'w[-1]|w[0]=base|rates': 2, 'w[1]=at': 2, 'w[0]=1.3': 2, 'pos[-1]|pos[0]=DT|CD': 2, 'w[0]=and': 2, 'w[-1]=exchange': 2, 'w[-1]=their': 2, 'w[1]=trade': 2, 'w[-1]|w[0]=1.3|billion': 2, 'w[0]=rise': 2, 'w[0]=chancellor': 2, 'w[-1]|w[0]=Mr.|Lawson': 2, 'w[1]=policy': 2, 'w[-1]|w[0]=the|economy': 2, 'w[1]=rise': 2, 'pos[1]=VBN': 2, 'w[-1]|w[0]=the|#': 2, 'w[0]=level': 2, 'w[-1]|w[0]=the|chancellor': 2, 'w[-1]=further': 2, 'w[-1]|w[0]=the|data': 2, 'pos[0]|pos[1]=CC|NNP': 2, 'w[1]=speech': 2, 'w[0]=substantial': 2, 'w[-1]|w[0]=his|Mansion': 2, 'w[1]=level': 2, 'w[-1]|w[0]=House|speech': 2, 'w[0]=House': 2, 'w[0]=Briscoe': 2, 'w[-1]=monetary': 2, \"w[0]|w[1]=Lawson|'s\": 2, 'w[1]=show': 2, 'pos[0]|pos[1]=NN|VBG': 2, 'w[0]|w[1]=rise|in': 2, 'w[-1]|w[0]=bad|trade': 2, 'w[-1]|w[0]=the|current': 2, 'w[0]|w[1]=#|1.3': 2, 'pos[-1]|pos[0]=POS|JJ': 2, 'w[0]|w[1]=quarter|and': 2, 'w[0]|w[1]=economist|at': 2, 'w[-1]=second': 2, 'w[-1]|w[0]=#|1.3': 2, 'pos[1]=``': 2, 'w[0]=U.K.': 2, 'w[-1]=Midland': 2, 'w[-1]=as': 2, 'w[0]=evidence': 2, 'w[0]|w[1]=Briscoe|,': 2, 'w[1]=has': 2, 'w[1]=will': 2, 'w[-1]|w[0]=2.3|billion': 1, 'pos[-1]=VBG': 1, 'w[0]|w[1]=rates|to': 1, 'w[0]|w[1]=pound|,': 1, 'w[-1]|w[0]=exchange|rate': 1, 'w[0]|w[1]=trade|number': 1, 'w[0]|w[1]=dive|if': 1, 'w[0]=this': 1, 'w[0]=promise': 1, 'pos[-1]|pos[0]=VBG|NN': 1, 'w[-1]|w[0]=a|freefall': 1, 'w[0]|w[1]=one|will': 1, 'pos[0]|pos[1]=NN|VBP': 1, 'w[0]=exchange': 1, 'w[-1]|w[0]=eight|years': 1, 'w[-1]|w[0]=and|capital': 1, 'w[0]|w[1]=Bank|PLC': 1, 'w[0]|w[1]=level|to': 1, 'pos[-1]=JJS': 1, 'w[0]|w[1]=market|analysts': 1, 'w[-1]|w[0]=awful|lot': 1, 'w[0]|w[1]=figures|show': 1, 'w[0]|w[1]=number|,': 1, 'w[0]|w[1]=drop|in': 1, 'w[1]=&': 1, 'w[0]=Co.': 1, 'w[0]=1988': 1, 'w[-1]|w[0]=few|economists': 1, 'w[0]|w[1]=as|#': 1, 'w[0]|w[1]=figures|without': 1, 'w[-1]|w[0]=consumer|expenditure': 1, 'w[0]|w[1]=marked|improvement': 1, 'w[-1]|w[0]=a|1.6': 1, 'w[1]=Institute': 1, 'w[0]|w[1]=unit|of': 1, 'w[-1]|w[0]=policy|measures': 1, 'w[-1]|w[0]=manufacturing|industry': 1, 'w[1]=number': 1, 'w[0]=base': 1, \"w[-1]|w[0]='s|promise\": 1, 'pos[-1]|pos[0]=JJ|IN': 1, 'w[0]=reduction': 1, 'w[0]|w[1]=figures|range': 1, 'w[-1]=high': 1, 'w[-1]=firm': 1, 'w[0]=consumer': 1, 'w[-1]|w[0]=15|%': 1, 'w[0]|w[1]=sharp|drop': 1, 'w[0]|w[1]=government|being': 1, 'w[0]=very': 1, 'w[-1]|w[0]=3.8|%': 1, 'w[-1]|w[0]=Mr.|Briscoe': 1, 'pos[-1]|pos[0]=NN|VBG': 1, \"w[0]|w[1]=August|'s\": 1, \"w[-1]|w[0]='s|near-record\": 1, 'w[-1]=policy': 1, 'w[1]=without': 1, 'w[1]=could': 1, 'w[-1]=rate': 1, 'pos[0]|pos[1]=DT|NN': 1, 'w[-1]|w[0]=a|further': 1, 'w[0]=restated': 1, 'w[0]|w[1]=economy|remains': 1, 'w[0]|w[1]=%|in': 1, 'w[0]|w[1]=month|takes': 1, 'w[-1]=&': 1, 'w[0]|w[1]=quarter|of': 1, 'pos[-1]|pos[0]=RB|#': 1, 'w[1]=economy': 1, 'w[0]=2.3': 1, 'w[0]=economists': 1, 'w[0]|w[1]=goods|inflows': 1, 'w[0]|w[1]=billion|deficit': 1, 'w[-1]|w[0]=another|sharp': 1, 'w[-1]|w[0]=Research|Institute': 1, 'w[0]=deficits': 1, 'w[-1]|w[0]=rate|weakness': 1, 'w[-1]|w[0]=U.K.|base': 1, 'w[0]|w[1]=failure|to': 1, 'w[1]=15': 1, 'w[-1]|w[0]=trade|figure': 1, 'w[1]=commitment': 1, 'pos[0]=IN': 1, 'w[-1]=Chris': 1, 'w[-1]=1.8': 1, 'w[-1]|w[0]=Midland|Bank': 1, 'pos[0]|pos[1]=NNS|RB': 1, 'w[0]=Bank': 1, 'w[-1]=market': 1, 'w[-1]=Sanjay': 1, 'w[0]|w[1]=Institute|.': 1, 'w[0]|w[1]=new|policy': 1, 'w[0]|w[1]=year|ago': 1, 'pos[-1]|pos[0]=PRP$|JJS': 1, 'w[-1]=Bank': 1, 'w[0]|w[1]=near-record|deficits': 1, 'w[-1]|w[0]=account|gap': 1, 'w[1]=rigor': 1, 'w[-1]|w[0]=a|#': 1, 'w[-1]|w[0]=no|sign': 1, 'w[0]=firm': 1, 'w[0]=Brothers': 1, 'w[0]=number': 1, 'w[-1]=unexpected': 1, 'w[-1]=same': 1, 'w[0]|w[1]=evidence|on': 1, 'w[-1]=goods': 1, 'w[0]=monetary': 1, 'w[-1]=0.1': 1, 'w[-1]|w[0]=last|Thursday': 1, 'w[1]=consumer': 1, 'w[1]=should': 1, 'w[0]=outlook': 1, 'w[0]|w[1]=trade|figure': 1, 'w[0]=Joshi': 1, 'w[0]=drop': 1, 'w[0]|w[1]=import|rises': 1, 'w[0]|w[1]=spending|went': 1, 'w[0]|w[1]=deficit|could': 1, 'w[0]=expenditure': 1, 'w[1]=weakness': 1, 'w[-1]=No': 1, 'w[-1]|w[0]=third|quarter': 1, 'pos[0]|pos[1]=NNS|VBD': 1, 'w[1]=market': 1, 'w[0]|w[1]=turnaround|before': 1, 'pos[0]|pos[1]=IN|#': 1, \"w[-1]|w[0]='s|manufacturing\": 1, 'w[0]=high': 1, 'w[0]|w[1]=5.4|%': 1, 'w[0]=time': 1, 'w[0]=month': 1, 'w[-1]|w[0]=August|deficit': 1, 'w[0]|w[1]=same|time': 1, 'w[-1]|w[0]=account|deficit': 1, 'w[-1]|w[0]=market|analysts': 1, 'w[-1]|w[0]=billion|current': 1, 'w[-1]|w[0]=senior|U.K.': 1, 'w[-1]|w[0]=foreign|exchange': 1, 'w[0]=last': 1, 'w[1]=2.3': 1, 'w[1]=registered': 1, 'w[0]|w[1]=goods|should': 1, 'pos[-1]|pos[0]=NNP|CC': 1, 'pos[0]=RB': 1, 'w[0]|w[1]=gap|,': 1, 'w[0]=risks': 1, 'w[0]=2.2': 1, 'pos[-1]|pos[0]=DT|PRP': 1, 'w[-1]|w[0]=&|Co.': 1, 'w[-1]=flat': 1, 'w[0]=audience': 1, 'w[0]=inflows': 1, 'w[0]|w[1]=and|August': 1, 'w[1]=expect': 1, 'w[0]|w[1]=Dillow|,': 1, 'w[-1]|w[0]=goods|inflows': 1, 'w[0]=market': 1, 'w[-1]=16': 1, 'pos[-1]|pos[0]=DT|RB': 1, 'w[0]|w[1]=rebound|in': 1, \"pos[0]|pos[1]=NN|''\": 1, 'w[-1]=underlying': 1, 'w[1]=does': 1, 'w[-1]|w[0]=the|deficit': 1, 'w[-1]|w[0]=first|quarter': 1, 'w[0]|w[1]=expenditure|data': 1, 'w[0]|w[1]=billion|current': 1, 'w[-1]=overall': 1, 'pos[-1]|pos[0]=IN|#': 1, 'pos[0]|pos[1]=CD|JJ': 1, 'w[0]|w[1]=measures|in': 1, 'w[0]|w[1]=1988|.': 1, 'w[-1]|w[0]=further|slowdown': 1, 'w[0]|w[1]=account|reported': 1, 'pos[0]|pos[1]=VBG|IN': 1, 'pos[0]|pos[1]=NN|RB': 1, 'w[-1]|w[0]=a|flat': 1, 'w[-1]=marked': 1, 'w[-1]|w[0]=The|figures': 1, 'w[-1]|w[0]=the|spending': 1, 'w[0]=1.6': 1, 'w[0]|w[1]=firm|monetary': 1, 'w[0]|w[1]=industry|is': 1, 'w[0]|w[1]=time|,': 1, 'w[0]|w[1]=deficit|of': 1, 'w[0]|w[1]=policy|measures': 1, 'w[-1]=15': 1, 'w[-1]|w[0]=some|rebound': 1, 'w[-1]|w[0]=import|rises': 1, 'w[-1]|w[0]=the|third': 1, 'pos[-1]|pos[0]=VBD|JJ': 1, 'w[0]|w[1]=consumer|and': 1, 'w[-1]|w[0]=another|bad': 1, 'w[0]|w[1]=impact|of': 1, 'w[-1]|w[0]=flat|position': 1, 'w[0]=further': 1, 'w[0]|w[1]=side|,': 1, 'w[0]=spending': 1, 'w[-1]|w[0]=the|turnaround': 1, 'pos[-1]=JJR': 1, 'w[-1]=2.3': 1, 'w[1]=dive': 1, 'w[0]=little': 1, 'w[0]|w[1]=Thursday|.': 1, 'w[0]|w[1]=speech|,': 1, 'w[1]=warned': 1, 'w[-1]=August': 1, 'w[-1]|w[0]=Chris|Dillow': 1, 'w[-1]=near-record': 1, 'w[1]=being': 1, 'w[1]=last': 1, 'pos[1]=#': 1, 'w[-1]|w[0]=the|Exchequer': 1, 'w[1]=rates': 1, 'w[0]|w[1]=2.3|billion': 1, 'w[0]=weakness': 1, 'pos[-1]|pos[0]=JJ|CD': 1, 'w[0]|w[1]=data|show': 1, 'w[1]=industry': 1, 'w[-1]|w[0]=the|first': 1, 'w[-1]=capital': 1, 'w[0]=years': 1, 'pos[-1]|pos[0]=NN|JJ': 1, 'w[0]|w[1]=deficit|will': 1, 'pos[0]|pos[1]=NN|VBN': 1, 'w[-1]|w[0]=earlier|this': 1, 'w[0]=new': 1, 'w[0]|w[1]=further|slowdown': 1, 'w[1]=#': 1, 'w[1]=released': 1, \"pos[1]=''\": 1, 'w[0]|w[1]=substantial|improvement': 1, 'w[-1]|w[0]=Nigel|Lawson': 1, 'w[-1]=Research': 1, 'w[0]|w[1]=second|from': 1, 'w[0]|w[1]=Montagu|,': 1, 'w[0]=industry': 1, 'w[-1]|w[0]=continued|high': 1, 'w[1]=stockbuilding': 1, 'w[1]=position': 1, 'w[1]=before': 1, 'w[-1]|w[0]=a|reduction': 1, 'w[-1]|w[0]=a|firm': 1, 'w[0]=unit': 1, 'w[-1]|w[0]=the|last': 1, 'w[-1]|w[0]=the|risk': 1, 'w[0]|w[1]=#|2.2': 1, 'w[1]=lot': 1, 'w[-1]=necessary': 1, 'w[0]|w[1]=pound|.': 1, 'w[-1]=first': 1, 'w[0]=necessary': 1, 'w[-1]=new': 1, 'w[-1]=down': 1, 'w[0]=highest': 1, 'w[-1]|w[0]=as|little': 1, 'w[0]|w[1]=reduction|in': 1, 'pos[0]|pos[1]=NNPS|CC': 1, 'w[1]=as': 1, 'w[0]|w[1]=evidence|of': 1, 'w[-1]=manufacturing': 1, 'w[0]|w[1]=Research|Institute': 1, 'w[1]=reported': 1, 'w[0]=manufacturing': 1, 'w[-1]=Nomura': 1, 'w[-1]=some': 1, 'w[0]=stockbuilding': 1, 'w[-1]|w[0]=July|and': 1, 'w[0]|w[1]=rate|weakness': 1, 'w[-1]|w[0]=The|risks': 1, 'w[1]=month': 1, 'w[0]|w[1]=slowdown|does': 1, 'w[0]|w[1]=promise|that': 1, 'w[0]=flat': 1, 'pos[0]|pos[1]=CC|NN': 1, 'w[0]|w[1]=commitment|to': 1, 'w[0]|w[1]=account|deficit': 1, 'w[0]|w[1]=risks|for': 1, 'w[0]|w[1]=economy|is': 1, 'w[0]|w[1]=rigor|of': 1, 'w[0]|w[1]=down|side': 1, 'w[0]=awful': 1, 'w[0]|w[1]=exchange|market': 1, 'w[-1]|w[0]=1.6|%': 1, 'w[1]=economist': 1, 'w[0]|w[1]=this|month': 1, 'w[0]|w[1]=speech|last': 1, 'w[0]|w[1]=last|rise': 1, 'w[0]|w[1]=billion|.': 1, 'w[-1]|w[0]=little|as': 1, 'w[-1]|w[0]=Nomura|Research': 1, 'w[0]|w[1]=Brothers|&': 1, 'w[0]=turnaround': 1, 'w[-1]|w[0]=substantial|slowdown': 1, 'w[0]=marked': 1, 'w[-1]|w[0]=current|15': 1, 'w[0]|w[1]=highest|level': 1, 'w[-1]|w[0]=a|very': 1, 'w[-1]|w[0]=his|audience': 1, 'w[0]=risk': 1, 'w[0]|w[1]=and|capital': 1, 'w[0]=failure': 1, 'w[0]|w[1]=August|deficit': 1, 'w[0]=same': 1, 'w[0]|w[1]=figures|for': 1, 'w[0]|w[1]=years|.': 1, 'w[1]=deficits': 1, 'w[-1]|w[0]=their|highest': 1, 'w[-1]|w[0]=trade|number': 1, 'w[-1]|w[0]=material|stockbuilding': 1, 'w[1]=2.2': 1, 'w[0]|w[1]=week|.': 1, 'w[0]|w[1]=monetary|policy': 1, 'w[1]=ago': 1, 'w[1]=Nigel': 1, 'w[-1]|w[0]=the|impact': 1, 'w[-1]|w[0]=this|month': 1, 'w[-1]|w[0]=#|2.3': 1, 'w[0]=one': 1, 'w[0]=as': 1, 'w[-1]=eight': 1, 'w[-1]|w[0]=consumer|goods': 1, 'w[1]=PLC': 1, 'pos[0]|pos[1]=RB|VBN': 1, 'w[0]|w[1]=gap|registered': 1, 'pos[-1]|pos[0]=NN|CC': 1, 'w[0]|w[1]=figure|are': 1, \"w[-1]|w[0]='s|unexpected\": 1, 'w[0]|w[1]=quarter|from': 1, \"w[-1]|w[0]='s|restated\": 1, 'w[0]|w[1]=rises|.': 1, 'pos[-1]|pos[0]=JJR|NN': 1, 'w[0]|w[1]=past|week': 1, 'w[-1]=expenditure': 1, 'w[-1]|w[0]=the|outlook': 1, 'w[1]=other': 1, 'w[0]=Thursday': 1, 'w[1]=August': 1, 'w[-1]|w[0]=the|same': 1, 'w[1]=capital': 1, 'w[0]=down': 1, 'w[-1]|w[0]=necessary|rigor': 1, 'w[-1]|w[0]=past|week': 1, 'w[-1]|w[0]=highest|level': 1, 'w[1]=again': 1, 'w[1]=went': 1, 'pos[0]|pos[1]=JJ|CD': 1, 'w[-1]|w[0]=the|U.K.': 1, 'w[0]|w[1]=restated|commitment': 1, 'w[0]|w[1]=decline|,': 1, 'w[-1]|w[0]=expenditure|data': 1, 'w[0]=rigor': 1, 'w[1]=by': 1, 'pos[-1]|pos[0]=NNP|NNPS': 1, 'w[-1]|w[0]=Baring|Brothers': 1, 'w[-1]=July': 1, 'w[-1]|w[0]=any|new': 1, 'pos[0]|pos[1]=JJS|NN': 1, 'w[1]=increase': 1, 'w[0]=1.8': 1, 'w[0]|w[1]=capital|goods': 1, 'w[0]=measures': 1, 'pos[0]|pos[1]=NNS|RBR': 1, \"w[-1]|w[0]='s|failure\": 1, 'w[-1]|w[0]=the|down': 1, 'w[1]=say': 1, 'w[-1]|w[0]=the|currency': 1, 'pos[-1]|pos[0]=PRP$|NN': 1, 'w[0]=Montagu': 1, \"w[0]|w[1]=chancellor|'s\": 1, 'w[-1]=this': 1, 'w[-1]|w[0]=underlying|support': 1, 'w[0]|w[1]=awful|lot': 1, 'w[0]|w[1]=analysts|say': 1, 'w[0]|w[1]=%|rise': 1, 'w[-1]=highest': 1, 'pos[-1]|pos[0]=NNP|CD': 1, 'w[1]=current': 1, 'w[0]|w[1]=rates|are': 1, 'w[-1]|w[0]=down|side': 1, 'w[1]=if': 1, 'w[0]=analysts': 1, 'w[1]=remains': 1, 'w[0]=15': 1, 'w[-1]|w[0]=No|one': 1, 'pos[-1]|pos[0]=NNPS|CC': 1, 'w[-1]=awful': 1, 'w[-1]|w[0]=The|August': 1, 'pos[0]=JJS': 1, 'w[-1]=few': 1, 'pos[-1]=RBR': 1, 'w[1]=marked': 1, 'w[0]=decline': 1, 'pos[-1]=IN': 1, 'pos[0]=DT': 1, 'w[0]|w[1]=economists|expect': 1, 'pos[0]|pos[1]=CD|IN': 1, 'pos[0]|pos[1]=JJ|IN': 1, 'pos[-1]=NNS': 1, 'pos[-1]|pos[0]=CC|NN': 1, 'w[-1]=3.8': 1, 'w[0]|w[1]=billion|gap': 1, 'w[0]|w[1]=flat|position': 1, 'w[-1]=October': 1, 'w[0]=&': 1, 'w[-1]=an': 1, 'w[0]|w[1]=third|quarter': 1, 'w[1]=on': 1, 'w[0]|w[1]=currency|wo': 1, 'w[0]|w[1]=#|1.8': 1, 'w[-1]|w[0]=October|1988': 1, 'w[0]|w[1]=account|gap': 1, 'w[0]|w[1]=chancellor|has': 1, 'w[-1]|w[0]=%|rise': 1, 'w[0]|w[1]=level|in': 1, 'w[0]|w[1]=rates|earlier': 1, 'w[-1]=Nigel': 1, 'w[-1]=Baring': 1, 'w[-1]|w[0]=%|increase': 1, 'w[-1]|w[0]=as|#': 1, 'w[-1]=any': 1, 'w[1]=monetary': 1, 'w[0]|w[1]=little|as': 1, 'w[0]|w[1]=Exchequer|Nigel': 1, 'w[-1]|w[0]=raw|material': 1, 'w[0]=Institute': 1, 'w[0]|w[1]=#|2.3': 1, 'w[-1]|w[0]=unexpected|decline': 1, 'w[-1]=Simon': 1, 'w[0]|w[1]=%|increase': 1, 'w[1]=figure': 1, 'w[0]|w[1]=slowdown|can': 1, 'w[0]=material': 1, 'w[-1]=raw': 1, 'w[0]|w[1]=lot|of': 1, 'w[-1]|w[0]=5.4|%': 1, 'w[0]|w[1]=moment|other': 1, 'w[0]=impact': 1, 'w[0]=past': 1, 'w[-1]=little': 1, 'w[0]|w[1]=freefall|in': 1, 'w[0]=dive': 1, 'w[-1]|w[0]=billion|gap': 1, 'w[-1]|w[0]=firm|monetary': 1, 'w[-1]|w[0]=new|policy': 1, 'w[0]|w[1]=sign|that': 1, 'w[0]|w[1]=base|rates': 1, 'w[-1]=2.2': 1, 'w[-1]=more': 1, 'w[1]=side': 1, 'pos[0]=VBG': 1, 'w[0]|w[1]=sharp|dive': 1, 'pos[-1]|pos[0]=RB|VBN': 1, 'w[0]|w[1]=deficit|and': 1, 'w[-1]|w[0]=very|marked': 1, 'w[0]=sign': 1, 'w[0]=capital': 1, 'w[-1]|w[0]=a|unit': 1, 'w[0]=import': 1, 'w[-1]=third': 1, 'w[-1]=5.4': 1, 'pos[-1]|pos[0]=RB|JJ': 1, 'w[0]|w[1]=economist|for': 1, 'w[1]=week': 1, 'w[-1]|w[0]=an|awful': 1, 'w[0]=Research': 1, 'w[0]=increase': 1, 'pos[0]|pos[1]=JJ|NNS': 1, 'w[0]|w[1]=policy|to': 1, 'w[-1]=1.6': 1, 'w[-1]|w[0]=1.8|billion': 1, 'w[-1]=senior': 1, 'w[0]|w[1]=15|%': 1, 'w[0]|w[1]=data|released': 1, 'w[-1]=restated': 1, 'w[0]|w[1]=very|marked': 1, 'w[0]|w[1]=rates|again': 1, 'w[0]|w[1]=stockbuilding|by': 1, 'w[0]|w[1]=necessary|rigor': 1, 'w[-1]=foreign': 1, 'w[-1]=no': 1, 'pos[-1]=NNPS': 1, 'w[1]=time': 1, 'pos[-1]|pos[0]=PRP$|JJ': 1, 'w[0]=PLC': 1, 'w[-1]|w[0]=a|5.4': 1, 'w[-1]|w[0]=consumer|and': 1, 'w[1]=Co.': 1, 'pos[-1]=VBD': 1, \"w[0]|w[1]=position|''\": 1, 'w[0]|w[1]=support|for': 1, 'pos[-1]|pos[0]=CD|NNS': 1, 'w[0]|w[1]=substantial|slowdown': 1, 'w[0]|w[1]=material|stockbuilding': 1, 'w[-1]=past': 1, 'w[-1]|w[0]=only|#': 1, 'w[1]=drop': 1, 'w[-1]=only': 1, 'w[-1]|w[0]=near-record|deficits': 1, 'w[0]|w[1]=government|``': 1, 'w[0]|w[1]=U.K.|economist': 1, 'w[1]=wo': 1, 'w[-1]|w[0]=U.K.|economy': 1, 'pos[-1]|pos[0]=POS|VBN': 1, 'w[1]=rises': 1, 'w[0]|w[1]=U.K.|economy': 1, 'w[-1]|w[0]=the|moment': 1, 'w[0]|w[1]=outlook|for': 1, 'w[1]=decline': 1, 'w[1]=can': 1, 'w[-1]|w[0]=and|August': 1, 'w[0]|w[1]=1.8|billion': 1, 'w[0]=currency': 1, 'w[0]=moment': 1, 'w[-1]|w[0]=capital|goods': 1, 'pos[0]|pos[1]=NN|POS': 1, 'w[0]|w[1]=Co.|,': 1, 'w[0]=rate': 1, 'pos[0]|pos[1]=NNS|NNS': 1, 'w[-1]|w[0]=#|1.8': 1, 'w[-1]|w[0]=billion|deficit': 1, 'w[0]=rebound': 1, 'w[-1]|w[0]=sharp|dive': 1, 'w[0]=lot': 1, 'w[0]|w[1]=&|Co.': 1, 'w[-1]|w[0]=last|rise': 1, 'w[1]=analysts': 1, 'w[-1]=earlier': 1, 'w[-1]|w[0]=Bank|PLC': 1, 'w[-1]|w[0]=more|import': 1, \"w[1]=''\": 1, 'w[-1]=European': 1, 'w[-1]|w[0]=substantial|improvement': 1, 'w[0]|w[1]=policy|has': 1, 'w[-1]|w[0]=exchange|market': 1, 'w[-1]=continued': 1, 'w[0]|w[1]=manufacturing|industry': 1, 'w[0]|w[1]=risk|of': 1, 'w[-1]=import': 1, 'w[0]=year': 1, 'w[-1]|w[0]=Brothers|&': 1, 'w[1]=goods': 1, 'w[-1]|w[0]=restated|commitment': 1, 'w[0]|w[1]=first|quarter': 1, 'w[-1]|w[0]=0.1|%': 1, 'w[0]|w[1]=weakness|.': 1, 'w[-1]|w[0]=European|economist': 1, 'w[1]=takes': 1, 'w[-1]|w[0]=the|necessary': 1, 'w[0]=unexpected': 1, 'w[0]|w[1]=economy|``': 1, 'w[0]=position': 1, 'w[-1]|w[0]=the|past': 1, 'w[0]|w[1]=data|to': 1, 'w[1]=earlier': 1, 'w[0]|w[1]=audience|that': 1, 'pos[0]|pos[1]=NNS|MD': 1, 'w[-1]|w[0]=same|time': 1, 'w[-1]|w[0]=overall|evidence': 1, 'w[0]|w[1]=Lawson|warned': 1, 'pos[-1]|pos[0]=RBR|DT': 1, 'w[0]|w[1]=high|consumer': 1, 'w[-1]=very': 1, 'w[-1]=Brothers': 1, 'w[1]=inflows': 1, 'w[0]|w[1]=increase|from': 1, 'w[0]|w[1]=PLC|.': 1, 'w[1]=data': 1, 'w[0]|w[1]=deficits|.': 1, 'w[0]=freefall': 1, 'w[0]|w[1]=figures|are': 1, 'w[0]=first': 1, 'pos[0]=NNPS': 1, 'w[0]=week': 1, 'w[0]|w[1]=%|level': 1, 'w[0]|w[1]=Joshi|,': 1, 'w[0]=side': 1, 'w[0]=figure': 1, 'pos[-1]|pos[0]=JJS|NN': 1, 'w[-1]|w[0]=Midland|Montagu': 1, 'w[-1]|w[0]=2.2|billion': 1, 'w[-1]|w[0]=Sanjay|Joshi': 1, 'w[0]|w[1]=inflows|.': 1, 'w[-1]|w[0]=sharp|drop': 1, 'w[0]=support': 1, 'w[-1]|w[0]=#|2.2': 1, 'w[0]=third': 1, 'w[1]=range': 1, 'pos[0]|pos[1]=PRP|MD': 1, 'w[0]|w[1]=1.6|%': 1, 'pos[0]=PRP': 1, 'w[-1]|w[0]=a|bad': 1, 'w[-1]|w[0]=further|evidence': 1, 'w[-1]|w[0]=high|consumer': 1, 'w[1]=1.8': 1, 'w[0]=near-record': 1, 'pos[-1]|pos[0]=NNS|NNS': 1, 'w[-1]|w[0]=marked|improvement': 1, 'w[-1]|w[0]=a|sharp': 1, 'w[0]=commitment': 1, 'w[-1]|w[0]=Simon|Briscoe': 1, 'w[-1]|w[0]=16|%': 1, 'w[0]|w[1]=billion|in': 1, 'pos[-1]|pos[0]=CD|JJ': 1, 'w[0]|w[1]=2.2|billion': 1, 'w[-1]|w[0]=%|level': 1, 'w[0]=5.4': 1, 'w[0]|w[1]=unexpected|decline': 1, 'w[-1]|w[0]=their|current': 1, 'w[-1]=material': 1, 'w[0]|w[1]=pound|is': 1, 'w[0]=rises': 1, 'pos[1]=RBR': 1, 'w[-1]|w[0]=a|year': 1, 'w[0]|w[1]=current|15': 1, 'w[1]=measures': 1, 'w[0]=Exchequer': 1}), 'B-PP|B-NP': Counter({'B-PP|B-NP': 67}), 'B-VP': Counter({'B-VP': 69, 'pos[-1]=NN': 24, 'pos[0]=VBZ': 22, 'pos[1]=VB': 15, 'pos[-1]=NNS': 14, 'pos[0]=VBD': 13, 'pos[0]=VBP': 12, 'pos[0]=MD': 11, 'pos[1]=RB': 10, 'pos[-1]|pos[0]=NN|VBZ': 10, 'pos[1]=IN': 9, 'pos[1]=DT': 9, 'pos[0]|pos[1]=MD|VB': 9, 'pos[-1]|pos[0]=NNS|VBP': 9, 'w[0]=is': 8, 'pos[-1]=PRP': 8, 'pos[1]=VBN': 7, 'pos[0]=TO': 6, 'w[0]=to': 6, 'pos[-1]=NNP': 5, 'pos[0]|pos[1]=TO|VB': 5, 'pos[0]|pos[1]=VBZ|RB': 5, 'pos[0]|pos[1]=VBZ|VBN': 5, 'pos[-1]|pos[0]=NN|MD': 5, 'w[-1]=he': 5, 'w[1]=the': 4, 'w[0]=are': 4, 'w[0]=has': 4, 'w[-1]=there': 4, 'pos[-1]|pos[0]=PRP|VBZ': 4, 'w[0]=said': 4, 'w[0]=will': 4, 'pos[-1]=EX': 4, 'w[1]=that': 4, 'pos[0]|pos[1]=VBD|IN': 4, 'w[1]=be': 4, 'pos[0]|pos[1]=VBZ|DT': 4, 'pos[-1]|pos[0]=NNP|VBD': 3, 'pos[0]|pos[1]=VBP|RB': 3, 'pos[-1]|pos[0]=EX|VBZ': 3, 'w[-1]=data': 3, 'w[-1]=,': 3, 'pos[1]=VBG': 3, 'w[-1]|w[0]=there|is': 3, 'pos[-1]|pos[0]=NN|TO': 3, 'pos[0]|pos[1]=VBP|DT': 3, 'pos[1]=NNP': 3, 'pos[-1]=,': 3, 'pos[-1]|pos[0]=NNS|MD': 3, 'w[0]=could': 3, 'pos[0]|pos[1]=VBZ|IN': 3, 'pos[-1]|pos[0]=NN|VBD': 3, \"w[1]=n't\": 3, 'w[-1]=figures': 3, 'pos[0]|pos[1]=VBD|NNP': 3, 'w[1]=fairly': 2, 'w[-1]=sterling': 2, 'pos[-1]=``': 2, 'w[1]=narrow': 2, 'w[-1]=analysts': 2, 'w[-1]=Dillow': 2, 'w[-1]=policy': 2, \"w[-1]=''\": 2, 'w[0]=remains': 2, 'w[-1]=spending': 2, 'pos[1]=NN': 2, 'w[-1]=industry': 2, 'pos[0]|pos[1]=VBZ|VBG': 2, 'w[0]|w[1]=will|want': 2, 'pos[-1]=DT': 2, \"pos[-1]|pos[0]=''|VBD\": 2, 'w[0]|w[1]=remains|fairly': 2, 'pos[0]=VBG': 2, 'w[-1]=``': 2, 'w[-1]=deficit': 2, 'pos[-1]=JJ': 2, 'w[0]=show': 2, 'pos[1]=JJ': 2, 'pos[-1]|pos[0]=PRP|VBD': 2, 'w[-1]=slowdown': 2, 'w[0]=noted': 2, 'w[-1]|w[0]=Dillow|said': 2, 'w[-1]=economy': 2, 'w[0]=does': 2, 'pos[1]=EX': 2, \"pos[-1]=''\": 2, 'w[1]=want': 2, 'pos[0]|pos[1]=MD|RB': 2, 'pos[-1]|pos[0]=NNP|VBP': 2, 'w[1]=widely': 2, 'w[1]=there': 2, 'w[-1]=rates': 2, 'w[-1]=This': 2, 'w[0]=can': 2, 'pos[-1]|pos[0]=DT|VBZ': 2, 'w[0]|w[1]=can|be': 1, 'w[0]=believes': 1, 'w[1]=he': 1, 'w[0]|w[1]=holding|sterling': 1, 'w[0]|w[1]=registered|in': 1, 'pos[-1]|pos[0]=,|VB': 1, 'w[-1]|w[0]=data|show': 1, 'w[0]=fail': 1, 'pos[0]|pos[1]=VBD|CD': 1, 'w[0]|w[1]=to|boost': 1, 'w[1]=made': 1, 'w[0]=rose': 1, 'pos[-1]|pos[0]=``|VBZ': 1, 'w[0]=say': 1, 'pos[1]=.': 1, 'pos[-1]|pos[0]=JJ|NN': 1, 'w[0]|w[1]=went|on': 1, 'w[0]|w[1]=to|both': 1, 'w[-1]|w[0]=chancellor|has': 1, 'w[0]|w[1]=rose|0.1': 1, 'pos[0]|pos[1]=VBZ|JJ': 1, 'w[1]=been': 1, 'w[-1]|w[0]=deficit|could': 1, 'w[-1]=and': 1, 'w[0]|w[1]=will|be': 1, 'w[0]|w[1]=noted|,': 1, 'w[0]|w[1]=has|been': 1, 'pos[-1]|pos[0]=NNS|TO': 1, 'w[-1]|w[0]=Friday|do': 1, 'w[-1]=July': 1, 'w[1]=boost': 1, 'w[0]|w[1]=range|widely': 1, 'w[-1]|w[0]=he|remains': 1, 'w[-1]|w[0]=slowdown|can': 1, 'w[0]|w[1]=fail|to': 1, 'w[-1]=Friday': 1, 'w[0]=do': 1, 'w[0]|w[1]=could|narrow': 1, 'pos[0]|pos[1]=VBP|VBG': 1, 'w[-1]|w[0]=rates|are': 1, 'w[-1]|w[0]=July|are': 1, 'w[0]|w[1]=expect|the': 1, 'w[-1]|w[0]=sterling|does': 1, 'w[1]=topped': 1, 'pos[1]=TO': 1, 'w[-1]|w[0]=pound|is': 1, 'w[-1]|w[0]=level|to': 1, 'pos[-1]|pos[0]=NN|VBG': 1, 'pos[-1]|pos[0]=CC|VBD': 1, 'w[-1]|w[0]=government|being': 1, \"w[-1]|w[0]=''|noted\": 1, 'w[1]=to': 1, 'w[1]=lead': 1, 'w[-1]=gap': 1, 'w[-1]|w[0]=account|reported': 1, 'w[0]|w[1]=has|helped': 1, 'w[1]=no': 1, 'pos[0]|pos[1]=VBG|VBN': 1, 'w[0]=wo': 1, 'w[0]=should': 1, \"w[0]|w[1]=do|n't\": 1, 'pos[0]=VB': 1, 'w[0]=released': 1, 'pos[0]|pos[1]=VBN|IN': 1, 'w[-1]=He': 1, 'w[-1]=chancellor': 1, 'w[1]=a': 1, 'w[-1]=account': 1, 'w[-1]=figure': 1, 'pos[0]|pos[1]=VB|TO': 1, 'w[0]=compares': 1, 'w[-1]|w[0]=,|said': 1, 'w[0]|w[1]=to|be': 1, 'w[1]=very': 1, 'w[-1]=investors': 1, 'pos[0]|pos[1]=VBD|DT': 1, 'w[-1]|w[0]=gap|registered': 1, 'w[1]=on': 1, 'w[-1]|w[0]=one|will': 1, 'w[-1]|w[0]=,|warns': 1, 'w[1]=forced': 1, 'w[0]|w[1]=is|slowing': 1, 'w[-1]|w[0]=there|could': 1, 'w[-1]|w[0]=failure|to': 1, 'pos[-1]|pos[0]=IN|VBG': 1, 'w[1]=still': 1, 'pos[0]|pos[1]=VBP|JJ': 1, 'w[1]=at': 1, 'w[0]|w[1]=could|lead': 1, 'w[-1]|w[0]=economists|expect': 1, 'w[1]=,': 1, 'w[-1]=goods': 1, 'w[-1]|w[0]=economy|is': 1, 'w[-1]|w[0]=data|to': 1, 'w[-1]=also': 1, 'pos[0]|pos[1]=VBG|NNS': 1, 'w[1]=bullish': 1, 'w[0]=holding': 1, 'w[0]|w[1]=is|transforming': 1, 'pos[0]|pos[1]=VBD|PRP$': 1, 'w[1]=effect': 1, 'w[1]=0.1': 1, 'w[0]|w[1]=is|no': 1, 'w[-1]|w[0]=``|can': 1, 'w[-1]|w[0]=He|reckons': 1, 'w[0]=registered': 1, 'w[-1]=little': 1, 'w[0]=agree': 1, 'pos[-1]=RB': 1, 'w[-1]|w[0]=``|is': 1, 'w[-1]|w[0]=little|holding': 1, 'w[-1]|w[0]=rates|will': 1, 'w[0]|w[1]=takes|effect': 1, 'w[0]|w[1]=reckon|underlying': 1, 'pos[0]|pos[1]=VBD|,': 1, 'w[-1]|w[0]=Lawson|warned': 1, 'w[-1]|w[0]=spending|rose': 1, 'w[-1]=government': 1, 'w[-1]=economists': 1, 'w[-1]=failure': 1, 'w[-1]=Analysts': 1, 'w[0]|w[1]=reckons|the': 1, 'w[-1]|w[0]=deficit|will': 1, 'w[0]|w[1]=should|reduce': 1, 'w[-1]|w[0]=currency|wo': 1, 'w[-1]|w[0]=figures|show': 1, 'w[-1]|w[0]=analysts|say': 1, 'w[0]|w[1]=could|be': 1, 'w[0]|w[1]=to|defend': 1, 'w[0]|w[1]=say|.': 1, 'w[0]|w[1]=has|made': 1, 'w[0]|w[1]=warns|that': 1, 'w[0]=reckons': 1, 'w[0]|w[1]=show|that': 1, 'w[-1]|w[0]=Analysts|agree': 1, 'pos[0]|pos[1]=VBD|PRP': 1, 'pos[0]=NN': 1, 'w[1]=both': 1, 'w[1]=underlying': 1, 'w[-1]|w[0]=spending|went': 1, 'w[0]=warned': 1, \"w[0]|w[1]=does|n't\": 1, 'w[0]=expect': 1, 'w[0]=went': 1, 'w[-1]|w[0]=goods|should': 1, 'w[-1]|w[0]=before|adjusting': 1, 'pos[-1]|pos[0]=EX|MD': 1, 'pos[0]|pos[1]=TO|DT': 1, 'w[-1]|w[0]=,|fail': 1, 'w[1]=defend': 1, 'w[0]|w[1]=being|forced': 1, 'pos[0]|pos[1]=VBZ|NN': 1, 'w[-1]|w[0]=industry|is': 1, 'w[-1]=Lawson': 1, 'w[-1]=pound': 1, 'w[0]|w[1]=is|little': 1, 'w[0]|w[1]=adjusting|positions': 1, 'pos[-1]=IN': 1, 'w[-1]|w[0]=This|compares': 1, 'w[-1]|w[0]=figures|range': 1, 'w[1]=with': 1, 'pos[0]|pos[1]=VBZ|VB': 1, 'w[1]=announce': 1, 'pos[-1]|pos[0]=NN|VBP': 1, 'w[-1]|w[0]=figure|are': 1, 'w[-1]|w[0]=slowdown|does': 1, 'w[-1]|w[0]=he|noted': 1, 'w[0]|w[1]=can|not': 1, 'w[1]=in': 1, 'w[0]|w[1]=are|bullish': 1, 'w[0]|w[1]=forecasts|a': 1, 'w[0]|w[1]=to|show': 1, 'w[1]=Friday': 1, 'w[1]=show': 1, 'w[-1]|w[0]=itself|to': 1, 'w[0]|w[1]=compares|with': 1, 'pos[-1]|pos[0]=PRP|TO': 1, 'w[-1]|w[0]=he|believes': 1, 'pos[1]=NNS': 1, 'w[0]|w[1]=has|increased': 1, 'pos[0]|pos[1]=VBP|VBN': 1, 'w[-1]|w[0]=data|released': 1, 'w[0]|w[1]=reported|for': 1, 'pos[-1]|pos[0]=NN|VBN': 1, 'w[0]=reminded': 1, 'w[1]=up': 1, 'w[-1]=level': 1, 'w[-1]=one': 1, 'w[0]|w[1]=is|still': 1, 'w[0]=range': 1, 'w[-1]=month': 1, 'w[0]|w[1]=are|very': 1, 'w[-1]|w[0]=necessary|to': 1, 'w[0]|w[1]=agree|there': 1, \"w[-1]|w[0]=''|said\": 1, 'w[0]=warns': 1, 'w[1]=little': 1, 'w[0]=forecasts': 1, 'w[0]|w[1]=said|the': 1, 'w[-1]|w[0]=analysts|reckon': 1, 'w[-1]|w[0]=he|reminded': 1, 'w[0]|w[1]=is|another': 1, 'w[-1]|w[0]=he|is': 1, 'w[0]|w[1]=warned|that': 1, 'pos[0]|pos[1]=VBP|EX': 1, 'w[0]|w[1]=are|at': 1, 'w[-1]|w[0]=policy|has': 1, 'w[0]=reported': 1, 'pos[0]|pos[1]=VBP|.': 1, 'w[0]|w[1]=show|the': 1, 'w[0]|w[1]=believes|that': 1, 'w[0]|w[1]=to|announce': 1, 'w[1]=his': 1, 'w[0]|w[1]=is|prepared': 1, 'w[1]=positions': 1, 'w[1]=increased': 1, 'pos[-1]|pos[0]=``|MD': 1, 'w[-1]=itself': 1, 'w[-1]=necessary': 1, 'w[-1]|w[0]=policy|to': 1, 'w[0]=was': 1, 'w[-1]=currency': 1, 'w[-1]|w[0]=investors|will': 1, 'w[0]|w[1]=noted|Simon': 1, 'w[-1]|w[0]=figures|are': 1, \"w[0]|w[1]=wo|n't\": 1, 'pos[-1]|pos[0]=RB|VBZ': 1, 'pos[1]=,': 1, 'w[0]|w[1]=will|narrow': 1, 'w[1]=slowing': 1, 'w[0]|w[1]=released|Friday': 1, 'w[-1]|w[0]=also|forecasts': 1, 'pos[1]=PRP$': 1, 'pos[-1]|pos[0]=PRP|MD': 1, 'pos[1]=PRP': 1, 'w[-1]|w[0]=industry|could': 1, 'pos[0]|pos[1]=VBD|EX': 1, 'w[1]=prepared': 1, 'pos[0]=VBN': 1, 'w[1]=transforming': 1, 'pos[-1]|pos[0]=NNS|VBD': 1, 'w[0]=adjusting': 1, 'w[-1]|w[0]=month|takes': 1, 'w[1]=helped': 1, 'w[-1]|w[0]=and|was': 1, 'pos[-1]|pos[0]=,|VBD': 1, 'pos[1]=CD': 1, 'w[0]|w[1]=are|topped': 1, 'pos[-1]=CC': 1, 'w[0]|w[1]=was|up': 1, 'w[0]|w[1]=said|there': 1, 'w[-1]=before': 1, 'w[0]|w[1]=said|Chris': 1, 'w[1]=Chris': 1, 'w[0]|w[1]=reminded|his': 1, 'w[0]=reckon': 1, 'w[1]=for': 1, 'w[-1]|w[0]=This|has': 1, 'w[-1]|w[0]=sterling|has': 1, 'pos[-1]|pos[0]=,|VBZ': 1, 'w[1]=not': 1, 'w[1]=take': 1, 'pos[0]|pos[1]=NN|NN': 1, 'w[1]=.': 1, 'w[0]=takes': 1, 'w[1]=another': 1, 'w[1]=Simon': 1, 'pos[0]|pos[1]=VBP|IN': 1, 'w[1]=reduce': 1, 'pos[-1]|pos[0]=JJ|TO': 1, 'w[0]=being': 1, 'w[-1]|w[0]=economy|remains': 1, 'w[0]|w[1]=said|he': 1, 'w[0]|w[1]=does|take': 1, 'w[0]|w[1]=is|widely': 1, 'w[1]=sterling': 1}), 'O|B-ADJP': Counter({'O|B-ADJP': 2}), 'B-ADJP|B-PP': Counter({'B-ADJP|B-PP': 4}), 'B-ADJP|B-VP': Counter({'B-ADJP|B-VP': 1}), 'B-ADVP': Counter({'B-ADVP': 15, 'pos[0]=RB': 11, 'w[1]=,': 5, 'pos[1]=,': 5, 'pos[0]|pos[1]=RB|,': 5, 'pos[1]=RB': 3, 'pos[0]=IN': 2, 'pos[0]|pos[1]=RB|IN': 2, 'pos[1]=.': 2, 'pos[-1]=VBP': 2, 'pos[1]=IN': 2, 'w[1]=.': 2, 'pos[-1]|pos[0]=VBP|RB': 2, 'pos[0]|pos[1]=RB|RB': 2, 'w[1]=quite': 1, 'pos[-1]=VBG': 1, 'w[0]=still': 1, 'pos[-1]=NN': 1, 'w[-1]=year': 1, 'pos[-1]|pos[0]=VBN|RB': 1, 'w[-1]|w[0]=was|up': 1, 'w[1]=forecasts': 1, 'w[0]|w[1]=again|if': 1, 'pos[-1]=IN': 1, 'w[0]=Meanwhile': 1, 'w[0]=However': 1, 'pos[0]|pos[1]=JJ|.': 1, 'w[-1]|w[0]=range|widely': 1, 'w[-1]|w[0]=slowing|that': 1, 'pos[-1]|pos[0]=NN|RB': 1, 'pos[-1]=VBD': 1, 'w[0]|w[1]=that|quickly': 1, 'w[-1]|w[0]=rates|again': 1, 'w[0]=further': 1, 'pos[0]|pos[1]=IN|CD': 1, 'w[-1]=range': 1, 'w[1]=least': 1, 'w[-1]|w[0]=decline|further': 1, 'w[-1]=is': 1, 'w[0]|w[1]=only|by': 1, 'w[1]=by': 1, 'w[-1]=rates': 1, 'w[-1]=topped': 1, 'w[0]=Nevertheless': 1, 'w[0]|w[1]=Nevertheless|,': 1, 'w[-1]=decline': 1, 'w[0]=up': 1, 'w[-1]=with': 1, 'w[0]=only': 1, 'w[0]|w[1]=further|.': 1, 'pos[-1]|pos[0]=VB|JJ': 1, 'pos[1]=JJS': 1, 'pos[0]=DT': 1, 'pos[0]|pos[1]=RB|VBZ': 1, 'w[0]|w[1]=ago|.': 1, 'pos[-1]|pos[0]=VBG|DT': 1, 'w[-1]|w[0]=is|still': 1, 'w[1]=3.8': 1, 'pos[-1]|pos[0]=NNS|RB': 1, 'pos[1]=CD': 1, 'w[0]=that': 1, 'w[-1]|w[0]=with|at': 1, 'w[0]|w[1]=still|quite': 1, 'pos[1]=VBZ': 1, 'w[0]|w[1]=up|3.8': 1, 'w[0]=widely': 1, 'w[0]=Certainly': 1, 'w[-1]=was': 1, 'w[0]|w[1]=very|heavily': 1, 'w[0]|w[1]=widely|,': 1, 'pos[-1]=VB': 1, 'w[0]=very': 1, 'w[0]=also': 1, 'w[0]=ago': 1, 'w[0]|w[1]=also|forecasts': 1, 'w[1]=if': 1, 'pos[-1]=NNS': 1, 'w[-1]=who': 1, 'pos[-1]|pos[0]=VBD|IN': 1, 'pos[-1]=VBZ': 1, 'pos[-1]|pos[0]=IN|IN': 1, 'pos[-1]|pos[0]=WP|RB': 1, 'w[0]|w[1]=However|,': 1, 'w[1]=heavily': 1, 'w[-1]|w[0]=who|also': 1, 'w[0]|w[1]=at|least': 1, 'pos[-1]|pos[0]=VBZ|RB': 1, 'pos[0]|pos[1]=DT|RB': 1, 'w[0]|w[1]=Certainly|,': 1, 'w[-1]=slowing': 1, 'pos[0]|pos[1]=RB|.': 1, 'w[-1]|w[0]=topped|only': 1, 'w[1]=quickly': 1, 'w[-1]|w[0]=are|very': 1, 'pos[0]=JJ': 1, 'w[-1]=are': 1, 'w[0]|w[1]=Meanwhile|,': 1, 'w[0]=at': 1, 'pos[-1]=VBN': 1, 'pos[0]|pos[1]=IN|JJS': 1, 'w[0]=again': 1, 'w[-1]|w[0]=year|ago': 1, 'pos[-1]=WP': 1}), 'O|B-SBAR': Counter({'O|B-SBAR': 1}), 'B-ADVP|B-NP': Counter({'B-ADVP|B-NP': 1}), 'B-PP|O': Counter({'B-PP|O': 1}), 'O|B-NP': Counter({'O|B-NP': 28}), 'O|O': Counter({'O|O': 14}), 'B-SBAR|B-NP': Counter({'B-SBAR|B-NP': 13}), 'B-SBAR|B-SBAR': Counter({'B-SBAR|B-SBAR': 1}), 'I-SBAR': Counter({'pos[1]=DT': 1, 'pos[-1]=RB': 1, 'pos[-1]|pos[0]=RB|IN': 1, 'pos[0]|pos[1]=IN|DT': 1, 'I-SBAR': 1, 'w[0]=if': 1, 'w[-1]=even': 1, 'w[0]|w[1]=if|the': 1, 'w[1]=the': 1, 'w[-1]|w[0]=even|if': 1, 'pos[0]=IN': 1}), 'I-PP': Counter({'pos[-1]=RB': 1, 'pos[-1]|pos[0]=RB|IN': 1, 'w[0]|w[1]=than|consumer': 1, 'pos[0]|pos[1]=IN|NN': 1, 'w[-1]=rather': 1, 'w[-1]|w[0]=rather|than': 1, 'pos[1]=NN': 1, 'w[0]=than': 1, 'w[1]=consumer': 1, 'pos[0]=IN': 1, 'I-PP': 1}), 'I-NP|B-VP': Counter({'I-NP|B-VP': 34}), 'B-ADVP|B-PP': Counter({'B-ADVP|B-PP': 1}), 'B-VP|I-VP': Counter({'B-VP|I-VP': 31}), 'B-ADJP|O': Counter({'B-ADJP|O': 2}), 'I-VP|B-NP': Counter({'I-VP|B-NP': 18}), 'B-VP|O': Counter({'B-VP|O': 3}), 'B-NP|I-NP': Counter({'B-NP|I-NP': 117}), 'B-ADVP|B-VP': Counter({'B-ADVP|B-VP': 1}), 'B-PP': Counter({'B-PP': 72, 'pos[0]=IN': 64, 'pos[-1]=NN': 37, 'pos[-1]|pos[0]=NN|IN': 36, 'pos[1]=DT': 30, 'pos[0]|pos[1]=IN|DT': 28, 'w[1]=the': 24, 'w[0]=in': 14, 'w[0]=of': 12, 'pos[1]=NNP': 12, 'pos[0]|pos[1]=IN|NNP': 12, 'pos[0]|pos[1]=IN|NN': 9, 'w[0]=for': 9, 'pos[1]=NN': 9, 'pos[-1]=NNS': 9, 'w[0]=from': 7, 'pos[-1]|pos[0]=NNS|IN': 7, 'w[1]=a': 6, 'w[0]|w[1]=in|the': 5, 'pos[0]=TO': 5, 'w[0]=to': 5, 'w[0]|w[1]=of|the': 5, 'w[0]|w[1]=from|the': 4, 'pos[0]|pos[1]=IN|PRP$': 4, 'pos[1]=NNS': 4, 'pos[-1]|pos[0]=JJ|IN': 4, 'pos[-1]=VB': 4, 'w[0]=by': 4, 'pos[1]=PRP$': 4, 'pos[-1]=JJ': 4, 'w[0]=at': 4, 'pos[-1]|pos[0]=VBN|IN': 4, 'pos[-1]=VBN': 4, 'pos[0]|pos[1]=IN|NNS': 4, 'w[1]=sterling': 4, 'pos[-1]|pos[0]=VB|TO': 3, 'w[0]|w[1]=for|sterling': 3, 'w[0]=on': 3, 'w[-1]=%': 3, 'pos[1]=IN': 3, 'w[-1]=economist': 3, 'pos[1]=CD': 3, 'pos[0]|pos[1]=TO|DT': 2, 'w[1]=their': 2, 'pos[1]=JJ': 2, 'w[1]=August': 2, 'w[-1]|w[0]=narrow|to': 2, 'pos[0]|pos[1]=TO|RB': 2, 'w[1]=imports': 2, 'w[0]=with': 2, 'w[-1]=evidence': 2, 'pos[-1]|pos[0]=VBD|IN': 2, 'w[-1]=narrow': 2, 'w[1]=his': 2, 'w[-1]=rise': 2, 'w[-1]=figures': 2, 'pos[-1]=VBD': 2, 'w[-1]|w[0]=economist|at': 2, 'w[-1]=improvement': 2, 'w[1]=September': 2, 'w[-1]=sterling': 2, 'pos[0]=VBN': 2, 'w[1]=Midland': 2, 'w[1]=July': 2, 'pos[-1]=RB': 2, 'w[-1]|w[0]=rise|in': 2, 'w[0]|w[1]=by|the': 2, 'pos[0]|pos[1]=IN|JJ': 2, 'w[0]|w[1]=on|the': 2, 'w[-1]=deficit': 2, 'pos[1]=RB': 2, 'pos[0]|pos[1]=IN|CD': 2, 'w[-1]|w[0]=%|from': 2, 'pos[-1]|pos[0]=RB|IN': 2, 'w[0]|w[1]=to|a': 2, 'w[-1]=quarter': 2, 'w[-1]|w[0]=improvement|from': 2, 'w[-1]|w[0]=due|for': 1, 'w[1]=than': 1, 'w[1]=16': 1, 'w[0]|w[1]=in|exports': 1, 'w[-1]|w[0]=registered|in': 1, 'w[-1]=undermined': 1, 'w[-1]=exports': 1, 'w[0]|w[1]=of|1988': 1, 'w[0]|w[1]=of|monetary': 1, 'w[0]=Combined': 1, 'w[-1]=firm': 1, 'w[1]=exchange': 1, 'w[0]|w[1]=In|his': 1, 'w[0]|w[1]=to|16': 1, 'w[-1]=Combined': 1, 'w[0]|w[1]=at|Nomura': 1, 'w[1]=Nomura': 1, 'w[0]|w[1]=for|imports': 1, 'w[1]=only': 1, 'w[1]=with': 1, 'w[-1]|w[0]=deficit|of': 1, 'w[1]=raw': 1, 'w[-1]=increase': 1, 'w[-1]=stockbuilding': 1, 'pos[0]|pos[1]=IN|JJR': 1, 'pos[1]=JJR': 1, 'w[1]=services': 1, 'w[-1]|w[0]=went|on': 1, 'w[0]|w[1]=from|a': 1, 'pos[0]|pos[1]=IN|VBG': 1, 'w[0]|w[1]=in|eight': 1, 'w[0]|w[1]=in|September': 1, 'w[-1]=rigor': 1, 'w[1]=interest': 1, 'w[0]|w[1]=in|sterling': 1, 'w[0]|w[1]=of|pressure': 1, 'w[0]|w[1]=of|Midland': 1, 'w[-1]|w[0]=are|at': 1, 'pos[-1]|pos[0]=VBG|IN': 1, 'w[-1]=only': 1, 'w[-1]=risk': 1, 'pos[0]|pos[1]=TO|CD': 1, 'w[-1]|w[0]=risk|of': 1, 'w[-1]|w[0]=Confidence|in': 1, 'w[0]=over': 1, 'pos[-1]|pos[0]=NNS|TO': 1, 'w[0]|w[1]=with|a': 1, 'w[-1]|w[0]=commitment|to': 1, 'w[0]|w[1]=in|his': 1, 'w[-1]=commitment': 1, 'w[0]|w[1]=At|the': 1, 'w[0]=after': 1, 'pos[0]|pos[1]=RB|IN': 1, 'w[-1]|w[0]=support|for': 1, 'pos[-1]|pos[0]=NNP|IN': 1, 'w[-1]|w[0]=sterling|of': 1, 'w[-1]=outlook': 1, 'w[0]|w[1]=for|release': 1, \"w[-1]|w[0]=''|in\": 1, 'w[-1]|w[0]=lot|of': 1, 'w[-1]|w[0]=undermined|by': 1, 'w[1]=adjusting': 1, 'w[-1]|w[0]=Chancellor|of': 1, 'w[-1]=unit': 1, 'w[-1]|w[0]=services|rather': 1, 'w[0]|w[1]=in|imports': 1, 'pos[0]|pos[1]=VBN|VBD': 1, 'w[-1]|w[0]=reduction|in': 1, \"w[-1]=''\": 1, 'pos[0]|pos[1]=IN|IN': 1, 'w[1]=Baring': 1, 'w[-1]|w[0]=turnaround|before': 1, 'w[0]|w[1]=to|as': 1, 'w[0]|w[1]=in|July': 1, 'w[-1]|w[0]=impact|of': 1, 'w[-1]=freefall': 1, 'w[0]|w[1]=of|a': 1, 'pos[-1]=VBZ': 1, 'w[-1]=due': 1, 'w[0]|w[1]=without|a': 1, 'pos[1]=VBG': 1, 'pos[-1]|pos[0]=CD|IN': 1, 'w[0]|w[1]=rather|than': 1, 'w[-1]=eroded': 1, 'w[-1]|w[0]=%|in': 1, 'w[-1]=measures': 1, 'w[0]|w[1]=Combined|with': 1, 'w[-1]|w[0]=quarter|from': 1, 'w[-1]=heavily': 1, 'w[0]|w[1]=into|the': 1, 'w[-1]|w[0]=deficit|in': 1, 'w[-1]=Confidence': 1, 'w[-1]=,': 1, 'w[-1]=go': 1, 'w[1]=at': 1, 'w[-1]|w[0]=firm|at': 1, 'w[-1]=Chancellor': 1, 'w[1]=pressure': 1, \"pos[-1]|pos[0]=''|IN\": 1, 'pos[0]|pos[1]=VBN|IN': 1, 'w[-1]|w[0]=outlook|for': 1, 'w[0]|w[1]=on|services': 1, 'w[-1]=pessimistic': 1, 'w[-1]|w[0]=freefall|in': 1, 'w[-1]|w[0]=figures|without': 1, 'w[-1]=went': 1, 'pos[-1]=CD': 1, 'pos[-1]=VBG': 1, 'w[0]|w[1]=by|exchange': 1, 'w[1]=release': 1, 'w[-1]|w[0]=unit|of': 1, 'w[-1]|w[0]=Forecasts|for': 1, 'w[-1]|w[0]=second|from': 1, 'w[-1]|w[0]=Combined|with': 1, 'w[0]|w[1]=about|the': 1, 'w[-1]|w[0]=much|of': 1, 'w[0]|w[1]=from|their': 1, 'w[0]|w[1]=in|interest': 1, 'pos[-1]|pos[0]=VB|IN': 1, 'w[0]|w[1]=before|adjusting': 1, 'w[-1]=services': 1, 'w[-1]=level': 1, 'w[-1]|w[0]=only|by': 1, 'w[0]|w[1]=after|August': 1, 'w[0]=At': 1, 'w[1]=industry': 1, 'w[-1]=support': 1, 'pos[-1]|pos[0]=NN|TO': 1, 'w[-1]|w[0]=level|in': 1, 'w[1]=Mr.': 1, 'w[-1]|w[0]=rates|to': 1, 'w[-1]=fears': 1, 'w[-1]|w[0]=bullish|for': 1, 'w[-1]|w[0]=evidence|of': 1, 'w[0]=before': 1, 'w[0]|w[1]=of|more': 1, 'w[0]=without': 1, 'w[1]=as': 1, 'w[-1]|w[0]=,|given': 1, 'w[-1]=reduction': 1, 'w[-1]|w[0]=quarter|of': 1, 'w[-1]|w[0]=compares|with': 1, 'pos[-1]|pos[0]=VBP|IN': 1, 'w[0]|w[1]=in|raw': 1, 'w[-1]|w[0]=measures|in': 1, 'w[0]=rather': 1, 'pos[-1]|pos[0]=,|VBN': 1, 'pos[-1]|pos[0]=NNS|RB': 1, 'w[0]|w[1]=at|Baring': 1, 'w[1]=monetary': 1, 'w[-1]|w[0]=other|than': 1, 'pos[-1]=VBP': 1, 'w[-1]|w[0]=fears|of': 1, 'w[-1]|w[0]=figures|for': 1, 'w[-1]=lot': 1, 'w[-1]=reported': 1, 'w[-1]=bullish': 1, 'w[-1]=billion': 1, 'w[0]|w[1]=of|October': 1, 'w[0]|w[1]=over|the': 1, 'w[0]|w[1]=for|Midland': 1, 'w[1]=continued': 1, 'w[0]|w[1]=than|Mr.': 1, 'w[-1]=turnaround': 1, 'w[0]|w[1]=at|their': 1, 'w[0]=In': 1, 'w[-1]|w[0]=increase|from': 1, 'w[0]|w[1]=by|industry': 1, 'w[0]|w[1]=for|August': 1, 'w[-1]|w[0]=rigor|of': 1, 'w[0]|w[1]=given|continued': 1, 'w[1]=1988': 1, 'w[-1]|w[0]=go|into': 1, 'w[-1]|w[0]=lead|to': 1, 'pos[-1]|pos[0]=VBZ|IN': 1, 'w[-1]|w[0]=exports|after': 1, 'w[-1]=lead': 1, 'w[-1]=impact': 1, 'w[-1]=Forecasts': 1, 'w[-1]=much': 1, 'w[-1]|w[0]=stockbuilding|by': 1, 'w[0]=into': 1, 'w[1]=exports': 1, 'w[0]=than': 1, 'w[-1]|w[0]=risks|for': 1, 'w[0]=given': 1, 'w[-1]=second': 1, 'w[-1]=rates': 1, 'w[-1]|w[0]=eroded|by': 1, 'w[-1]|w[0]=reported|for': 1, 'w[0]=about': 1, 'w[-1]|w[0]=heavily|on': 1, 'w[-1]|w[0]=pessimistic|about': 1, 'w[-1]=drop': 1, 'w[-1]|w[0]=economist|for': 1, 'w[-1]|w[0]=drop|in': 1, 'w[0]|w[1]=with|at': 1, 'w[-1]=registered': 1, 'pos[0]=RB': 1, 'w[0]|w[1]=at|the': 1, 'w[1]=October': 1, 'w[-1]=risks': 1, 'pos[-1]=,': 1, 'w[-1]=rebound': 1, 'w[-1]|w[0]=rebound|in': 1, 'w[0]|w[1]=from|July': 1, 'w[-1]=other': 1, 'w[0]|w[1]=for|the': 1, \"pos[-1]=''\": 1, 'pos[-1]=NNP': 1, 'w[-1]|w[0]=evidence|on': 1, 'w[0]|w[1]=to|only': 1, 'w[-1]=are': 1, 'w[-1]|w[0]=billion|in': 1, 'pos[1]=VBD': 1, 'w[-1]=compares': 1, 'w[1]=eight': 1, 'w[-1]|w[0]=sterling|over': 1, 'w[1]=more': 1, 'w[0]|w[1]=for|September': 1}), 'I-PP|B-NP': Counter({'I-PP|B-NP': 1}), 'I-VP|B-ADVP': Counter({'I-VP|B-ADVP': 3}), 'B-VP|B-NP': Counter({'B-VP|B-NP': 20}), 'I-NP|B-SBAR': Counter({'I-NP|B-SBAR': 4}), 'B-NP': Counter({'B-NP': 173, 'pos[-1]=IN': 77, 'pos[0]=DT': 65, 'pos[1]=NN': 50, 'w[0]=the': 38, 'pos[-1]|pos[0]=IN|DT': 34, 'pos[0]|pos[1]=DT|NN': 28, 'pos[1]=JJ': 27, 'pos[0]=NNP': 24, 'pos[0]=NN': 23, 'pos[0]|pos[1]=DT|JJ': 21, 'pos[1]=NNP': 19, 'pos[-1]=,': 16, 'w[-1]=,': 16, 'w[0]=a': 15, 'pos[-1]=VB': 15, 'w[-1]=in': 14, 'pos[0]=NNS': 14, 'pos[-1]|pos[0]=IN|NNP': 13, 'pos[0]|pos[1]=NNP|NNP': 12, 'pos[-1]|pos[0]=IN|NN': 12, 'w[-1]=of': 12, 'pos[0]=JJ': 12, 'pos[1]=NNS': 11, 'pos[1]=VBZ': 11, 'w[-1]=that': 11, 'pos[1]=IN': 10, 'w[-1]=for': 9, 'pos[-1]=VBD': 8, 'pos[0]|pos[1]=JJ|NN': 8, 'pos[-1]|pos[0]=VB|DT': 8, 'pos[0]=PRP': 8, 'pos[1]=.': 7, 'pos[-1]=CC': 7, 'w[1]=.': 7, 'pos[0]=POS': 6, 'pos[-1]|pos[0]=IN|NNS': 6, 'pos[-1]=VBZ': 6, \"w[0]='s\": 6, 'w[-1]=from': 6, 'pos[1]=,': 6, 'pos[-1]=NNP': 6, 'w[0]=sterling': 6, 'w[1]=,': 6, 'w[0]=he': 5, 'pos[0]=PRP$': 5, 'w[-1]|w[0]=of|the': 5, 'pos[-1]|pos[0]=NNP|POS': 5, 'w[-1]=to': 5, 'pos[0]|pos[1]=NN|NNS': 5, 'pos[0]|pos[1]=NN|IN': 5, 'w[0]=Mr.': 5, 'pos[-1]=TO': 5, 'w[-1]|w[0]=in|the': 5, 'pos[0]=CD': 5, 'pos[0]|pos[1]=DT|NNS': 4, 'pos[0]|pos[1]=PRP|VBZ': 4, 'pos[-1]|pos[0]=VBZ|DT': 4, 'w[1]=#': 4, 'w[-1]=said': 4, 'w[1]=is': 4, 'pos[-1]|pos[0]=IN|PRP$': 4, 'pos[-1]=NN': 4, 'pos[-1]|pos[0]=,|DT': 4, 'pos[-1]=VBP': 4, 'w[-1]=by': 4, 'pos[0]|pos[1]=NNS|IN': 4, 'w[0]=there': 4, 'pos[1]=#': 4, 'pos[1]=MD': 4, 'pos[0]=EX': 4, 'pos[0]|pos[1]=NN|NN': 4, 'pos[1]=VBP': 4, 'w[-1]=at': 4, 'w[-1]|w[0]=,|he': 3, 'w[1]=Dillow': 3, 'pos[1]=CC': 3, 'w[-1]=and': 3, 'w[1]=second': 3, 'w[1]=rates': 3, 'w[0]|w[1]=the|trade': 3, 'pos[0]|pos[1]=DT|#': 3, 'w[1]=current': 3, 'w[-1]=on': 3, 'pos[-1]=VBN': 3, 'pos[0]|pos[1]=NNS|.': 3, 'pos[-1]|pos[0]=,|PRP': 3, 'w[-1]|w[0]=for|sterling': 3, 'pos[-1]|pos[0]=,|NNP': 3, 'pos[1]=RB': 3, 'pos[0]|pos[1]=EX|VBZ': 3, 'w[1]=pound': 3, 'pos[-1]|pos[0]=VB|NN': 3, 'w[-1]|w[0]=from|the': 3, 'pos[-1]|pos[0]=VBD|NNP': 3, 'w[0]|w[1]=the|pound': 3, 'pos[0]|pos[1]=DT|NNP': 3, 'w[0]|w[1]=there|is': 3, 'w[1]=of': 3, 'w[0]|w[1]=the|second': 3, 'w[-1]|w[0]=that|a': 3, 'w[-1]=show': 3, 'w[-1]|w[0]=,|the': 3, 'w[-1]=is': 3, 'pos[0]|pos[1]=CD|NN': 3, 'w[1]=Lawson': 3, 'pos[1]=VBD': 3, 'w[0]=his': 3, 'pos[0]|pos[1]=NN|,': 3, 'pos[-1]|pos[0]=IN|CD': 3, 'w[1]=and': 3, 'w[0]=The': 3, 'w[1]=trade': 3, 'pos[-1]|pos[0]=,|JJ': 3, 'pos[1]=CD': 3, 'w[1]=%': 3, 'pos[0]|pos[1]=POS|NN': 3, 'w[-1]=than': 2, 'pos[-1]=VBG': 2, 'w[0]|w[1]=a|substantial': 2, 'w[-1]|w[0]=,|Mr.': 2, 'pos[-1]|pos[0]=VB|JJ': 2, 'pos[-1]|pos[0]=VBP|DT': 2, 'w[0]|w[1]=the|current': 2, 'w[1]=could': 2, 'pos[0]|pos[1]=NN|VBZ': 2, 'w[1]=substantial': 2, 'w[-1]|w[0]=that|the': 2, 'w[1]=Briscoe': 2, 'w[0]=exports': 2, 'pos[0]|pos[1]=NNP|VBP': 2, 'w[1]=government': 2, 'pos[0]|pos[1]=PRP$|NNP': 2, 'pos[-1]=DT': 2, 'w[0]|w[1]=his|Mansion': 2, 'w[0]=much': 2, 'pos[-1]|pos[0]=VB|NNS': 2, 'pos[-1]|pos[0]=CC|NNS': 2, 'w[0]=September': 2, 'pos[0]|pos[1]=NNP|.': 2, 'w[0]|w[1]=Mr.|Lawson': 2, 'pos[0]|pos[1]=PRP|VBD': 2, 'w[0]|w[1]=the|data': 2, 'w[-1]=``': 2, 'w[-1]|w[0]=to|a': 2, \"w[1]='s\": 2, 'w[1]=evidence': 2, 'pos[0]=RB': 2, 'w[0]=interest': 2, 'w[-1]|w[0]=on|the': 2, 'w[0]|w[1]=the|economy': 2, 'w[1]=U.K.': 2, 'pos[-1]|pos[0]=CC|DT': 2, 'w[0]=Midland': 2, 'w[0]|w[1]=Mr.|Dillow': 2, 'w[1]=bad': 2, 'w[-1]=take': 2, 'pos[0]|pos[1]=POS|JJ': 2, 'w[1]=economist': 2, 'pos[-1]|pos[0]=CC|JJ': 2, 'w[1]=in': 2, 'w[0]=consumer': 2, 'w[-1]=if': 2, 'pos[-1]|pos[0]=TO|DT': 2, 'w[1]=data': 2, 'pos[0]|pos[1]=NNP|POS': 2, \"w[-1]|w[0]=August|'s\": 2, 'w[0]=their': 2, 'w[0]=August': 2, 'w[-1]=increase': 2, 'pos[-1]=``': 2, 'w[0]=another': 2, 'pos[1]=POS': 2, 'w[1]=chancellor': 2, 'w[0]|w[1]=the|#': 2, 'w[-1]|w[0]=by|the': 2, 'w[-1]=But': 2, 'pos[0]|pos[1]=NNP|,': 2, 'w[1]=economy': 2, 'pos[0]|pos[1]=JJ|NNP': 2, 'w[0]=imports': 2, \"w[-1]|w[0]=Lawson|'s\": 2, 'pos[-1]|pos[0]=IN|JJ': 2, 'pos[0]|pos[1]=DT|CD': 2, 'w[1]=figures': 2, 'w[1]=sharp': 2, 'w[0]|w[1]=interest|rates': 2, 'pos[-1]|pos[0]=``|DT': 2, 'w[-1]=but': 2, 'pos[0]|pos[1]=NNS|VBP': 2, 'w[0]=This': 2, 'pos[0]|pos[1]=DT|VBZ': 2, 'w[-1]=August': 2, 'w[1]=has': 2, 'w[1]=firm': 2, 'pos[-1]|pos[0]=NN|NN': 2, 'w[0]|w[1]=the|government': 2, 'pos[-1]|pos[0]=DT|NN': 2, 'w[-1]=Lawson': 2, 'w[0]=July': 2, 'pos[0]|pos[1]=NNS|MD': 2, 'w[0]=U.K.': 2, 'w[-1]|w[0]=show|a': 2, 'pos[-1]|pos[0]=TO|RB': 2, 'w[1]=Mansion': 2, 'w[0]|w[1]=the|chancellor': 2, 'w[1]=will': 2, 'w[0]|w[1]=the|risk': 1, 'w[0]=who': 1, 'w[0]=pressure': 1, 'w[1]=this': 1, 'w[0]|w[1]=their|highest': 1, 'w[0]|w[1]=as|little': 1, 'w[0]|w[1]=a|further': 1, 'w[1]=over': 1, 'w[-1]|w[0]=that|much': 1, 'w[0]|w[1]=he|believes': 1, 'w[-1]|w[0]=at|Nomura': 1, 'w[-1]|w[0]=of|pressure': 1, 'w[-1]|w[0]=agree|there': 1, 'w[0]=exchange': 1, 'w[1]=high': 1, 'w[0]|w[1]=foreign|exchange': 1, 'w[0]|w[1]=0.1|%': 1, 'w[0]|w[1]=16|%': 1, 'w[1]=Research': 1, 'pos[-1]=JJS': 1, 'w[0]=earlier': 1, 'w[-1]|w[0]=increase|base': 1, 'w[0]=1988': 1, 'w[-1]=boost': 1, 'w[0]=Simon': 1, 'w[0]=Sanjay': 1, 'w[1]=freefall': 1, 'pos[-1]|pos[0]=NN|JJ': 1, 'w[0]|w[1]=deficit|in': 1, 'w[-1]|w[0]=in|his': 1, 'w[0]|w[1]=more|import': 1, 'w[0]=industry': 1, 'w[0]|w[1]=tomorrow|,': 1, 'w[-1]|w[0]=speech|last': 1, 'w[0]=base': 1, 'w[-1]=announce': 1, 'w[1]=restated': 1, 'w[0]=investors': 1, 'w[1]=promise': 1, 'w[0]|w[1]=exports|.': 1, 'w[1]=impact': 1, 'w[1]=near-record': 1, 'pos[1]=TO': 1, 'pos[-1]|pos[0]=VBN|DT': 1, 'w[0]=senior': 1, \"w[0]|w[1]=August|'s\": 1, 'w[-1]|w[0]=At|the': 1, 'w[0]=Confidence': 1, 'w[0]|w[1]=he|reminded': 1, 'w[0]=fears': 1, 'w[0]|w[1]=the|spending': 1, 'w[0]|w[1]=last|Thursday': 1, 'w[-1]|w[0]=in|eight': 1, 'w[0]|w[1]=the|moment': 1, 'pos[-1]|pos[0]=IN|JJR': 1, 'w[-1]=-RRB-': 1, 'w[1]=support': 1, 'w[-1]|w[0]=at|Baring': 1, 'w[0]=any': 1, 'w[1]=year': 1, 'w[0]=it': 1, 'w[0]|w[1]=Forecasts|for': 1, 'w[1]=awful': 1, 'w[0]|w[1]=the|currency': 1, 'w[0]=spending': 1, 'w[0]=16': 1, 'w[0]|w[1]=a|bad': 1, 'w[1]=sign': 1, 'pos[-1]|pos[0]=VBP|EX': 1, 'w[1]=unit': 1, 'w[-1]=because': 1, 'w[1]=further': 1, 'w[-1]|w[0]=in|September': 1, 'w[0]|w[1]=a|sharp': 1, 'pos[0]|pos[1]=NNS|RB': 1, 'w[0]=3.8': 1, 'w[0]|w[1]=their|current': 1, 'w[-1]|w[0]=and|a': 1, 'w[0]|w[1]=consumer|goods': 1, 'w[-1]|w[0]=,|European': 1, 'w[1]=policy': 1, 'w[-1]|w[0]=from|their': 1, 'w[0]|w[1]=release|tomorrow': 1, 'w[-1]|w[0]=is|no': 1, 'w[-1]=after': 1, 'w[-1]|w[0]=is|little': 1, 'w[-1]|w[0]=of|Midland': 1, 'w[-1]=reckon': 1, 'w[-1]=allow': 1, 'w[1]=past': 1, 'w[-1]|w[0]=on|services': 1, 'w[0]|w[1]=the|turnaround': 1, 'w[0]|w[1]=industry|could': 1, 'w[0]|w[1]=suggestions|that': 1, 'w[-1]=prevent': 1, 'w[1]=because': 1, 'w[-1]|w[0]=from|a': 1, 'w[0]|w[1]=European|economist': 1, 'w[-1]|w[0]=for|August': 1, 'w[0]|w[1]=he|remains': 1, \"w[0]|w[1]='s|restated\": 1, 'w[0]|w[1]=the|U.K.': 1, 'w[0]|w[1]=the|last': 1, 'w[-1]|w[0]=at|their': 1, 'w[0]|w[1]=The|figures': 1, 'w[0]|w[1]=a|year': 1, 'w[-1]|w[0]=in|raw': 1, 'w[-1]=defend': 1, 'w[1]=Brothers': 1, 'pos[-1]|pos[0]=NNP|NNP': 1, 'pos[-1]|pos[0]=)|NN': 1, 'w[0]=last': 1, 'w[0]=an': 1, 'w[0]|w[1]=only|#': 1, 'pos[-1]|pos[0]=NNS|RBR': 1, 'w[0]=Chris': 1, 'w[0]|w[1]=the|impact': 1, 'w[1]=rose': 1, 'w[-1]|w[0]=take|place': 1, 'w[1]=reckon': 1, 'w[-1]=holding': 1, 'w[0]|w[1]=positions|.': 1, 'w[-1]|w[0]=,|economists': 1, 'w[0]|w[1]=itself|to': 1, 'w[-1]|w[0]=than|consumer': 1, 'w[-1]|w[0]=in|interest': 1, 'w[0]=monetary': 1, 'pos[0]|pos[1]=NNP|NNPS': 1, 'w[0]=0.1': 1, 'w[-1]|w[0]=allow|the': 1, 'w[-1]|w[0]=prevent|a': 1, 'w[-1]|w[0]=that|sterling': 1, 'w[-1]|w[0]=If|there': 1, 'w[0]|w[1]=exports|after': 1, 'w[0]|w[1]=Analysts|agree': 1, 'w[-1]|w[0]=``|No': 1, 'w[-1]|w[0]=defend|the': 1, \"w[0]|w[1]=Britain|'s\": 1, 'w[-1]=advance': 1, 'w[0]|w[1]=the|down': 1, 'w[1]=5.4': 1, 'w[1]=are': 1, 'w[-1]=released': 1, 'w[-1]|w[0]=without|a': 1, 'w[0]=Analysts': 1, 'w[-1]=reminded': 1, 'pos[-1]|pos[0]=IN|PRP': 1, 'w[0]|w[1]=services|rather': 1, 'w[1]=outlook': 1, 'w[0]|w[1]=the|first': 1, 'w[0]|w[1]=a|flat': 1, 'w[-1]|w[0]=as|the': 1, 'w[0]=further': 1, 'w[0]|w[1]=spending|rose': 1, 'w[0]|w[1]=Chris|Dillow': 1, 'w[1]=reckons': 1, 'pos[0]|pos[1]=CD|.': 1, 'w[-1]|w[0]=of|October': 1, 'pos[-1]|pos[0]=IN|EX': 1, 'w[-1]=In': 1, 'w[-1]=At': 1, 'w[-1]|w[0]=increase|interest': 1, 'w[1]=turnaround': 1, 'w[-1]|w[0]=at|the': 1, 'w[-1]=forecasts': 1, 'w[1]=holding': 1, 'w[0]|w[1]=September|,': 1, 'w[-1]|w[0]=,|a': 1, 'w[1]=one': 1, 'w[0]|w[1]=there|could': 1, 'pos[0]|pos[1]=NNS|CC': 1, 'pos[-1]|pos[0]=JJS|DT': 1, 'w[-1]|w[0]=said|he': 1, 'w[0]|w[1]=September|.': 1, 'w[0]|w[1]=who|also': 1, 'w[0]|w[1]=place|and': 1, 'pos[0]|pos[1]=WP|RB': 1, 'w[1]=exchange': 1, 'w[1]=little': 1, 'w[0]=continued': 1, \"w[-1]|w[0]=Britain|'s\": 1, 'w[0]=rates': 1, 'w[0]=deficit': 1, 'w[0]|w[1]=sterling|firm': 1, 'w[1]=same': 1, 'w[0]|w[1]=Friday|do': 1, 'w[0]|w[1]=U.K.|base': 1, 'w[-1]=release': 1, 'w[0]|w[1]=the|deficit': 1, 'w[-1]=without': 1, 'w[-1]|w[0]=for|the': 1, 'w[0]=Forecasts': 1, 'w[-1]|w[0]=But|consumer': 1, 'w[1]=rate': 1, 'w[1]=necessary': 1, 'pos[-1]|pos[0]=VBN|PRP': 1, 'w[-1]|w[0]=of|more': 1, 'w[-1]|w[0]=holding|sterling': 1, 'w[0]|w[1]=imports|.': 1, 'w[0]=Baring': 1, 'w[1]=believes': 1, 'pos[0]=JJR': 1, 'w[0]|w[1]=Simon|Briscoe': 1, 'w[-1]=about': 1, 'w[0]=Nigel': 1, 'w[-1]|w[0]=increased|the': 1, 'w[0]|w[1]=rates|will': 1, 'w[-1]|w[0]=because|investors': 1, 'w[-1]=be': 1, 'pos[-1]|pos[0]=VBN|VBD': 1, 'w[0]=foreign': 1, 'w[1]=reminded': 1, 'w[1]=manufacturing': 1, 'w[0]|w[1]=Thursday|,': 1, 'w[-1]|w[0]=about|the': 1, 'pos[1]=NNPS': 1, 'w[0]|w[1]=earlier|this': 1, 'w[1]=1988': 1, 'w[0]|w[1]=a|very': 1, 'pos[0]|pos[1]=PRP|TO': 1, 'w[1]=first': 1, 'w[0]|w[1]=sterling|does': 1, 'w[-1]=reckons': 1, 'w[-1]|w[0]=said|Chris': 1, 'w[0]|w[1]=raw|material': 1, 'w[0]=Britain': 1, 'w[0]|w[1]=He|reckons': 1, 'w[0]|w[1]=The|August': 1, 'w[-1]|w[0]=over|the': 1, 'w[0]|w[1]=pressure|,': 1, 'w[0]|w[1]=he|noted': 1, 'w[1]=agree': 1, 'w[-1]|w[0]=for|Midland': 1, 'w[0]|w[1]=some|rebound': 1, 'pos[-1]=NNS': 1, 'pos[-1]|pos[0]=VBP|VBG': 1, 'w[1]=risk': 1, 'w[1]=material': 1, 'w[-1]=given': 1, 'pos[0]|pos[1]=PRP$|NN': 1, 'pos[-1]|pos[0]=,|WP': 1, 'pos[-1]|pos[0]=VBG|NNS': 1, 'w[0]|w[1]=eight|years': 1, 'w[-1]|w[0]=by|industry': 1, 'pos[-1]|pos[0]=VBD|PRP': 1, 'w[0]=overall': 1, 'w[1]=do': 1, 'w[0]|w[1]=Mr.|Briscoe': 1, 'w[0]|w[1]=a|1.6': 1, 'w[-1]|w[0]=from|July': 1, 'w[-1]|w[0]=rates|earlier': 1, 'w[0]|w[1]=October|1988': 1, 'w[0]|w[1]=This|has': 1, 'w[-1]=Exchequer': 1, 'w[0]|w[1]=Confidence|in': 1, 'w[-1]=noted': 1, 'w[-1]|w[0]=,|senior': 1, 'w[0]|w[1]=investors|will': 1, 'w[-1]|w[0]=of|1988': 1, 'w[0]|w[1]=another|bad': 1, 'w[1]=does': 1, 'w[-1]|w[0]=,|there': 1, 'w[0]=some': 1, 'w[-1]|w[0]=to|only': 1, 'w[-1]|w[0]=In|his': 1, 'pos[-1]|pos[0]=VBD|CD': 1, 'pos[0]|pos[1]=CD|NNS': 1, 'w[0]=as': 1, 'w[0]|w[1]=much|of': 1, 'pos[0]|pos[1]=VBG|NN': 1, 'pos[0]|pos[1]=RB|#': 1, 'pos[-1]|pos[0]=VBD|DT': 1, 'w[-1]=reduce': 1, 'w[0]|w[1]=monetary|policy': 1, 'w[1]=noted': 1, 'w[-1]|w[0]=boost|exports': 1, 'pos[0]|pos[1]=NN|CC': 1, 'w[-1]|w[0]=for|release': 1, 'w[0]|w[1]=Nomura|Research': 1, 'w[0]=itself': 1, 'w[1]=reduction': 1, 'w[0]=Thursday': 1, 'w[-1]=see': 1, 'w[1]=August': 1, \"w[0]|w[1]='s|promise\": 1, 'w[-1]|w[0]=of|monetary': 1, 'w[-1]|w[0]=advance|much': 1, 'w[1]=that': 1, 'w[0]|w[1]=it|clear': 1, 'w[0]|w[1]=the|Exchequer': 1, 'w[1]=base': 1, 'w[0]=positions': 1, 'w[0]|w[1]=a|freefall': 1, 'w[0]|w[1]=the|third': 1, 'pos[-1]|pos[0]=VBD|EX': 1, 'w[-1]|w[0]=made|it': 1, 'pos[0]|pos[1]=PRP$|JJS': 1, 'w[-1]|w[0]=reminded|his': 1, 'w[0]|w[1]=little|holding': 1, 'w[-1]=least': 1, 'w[0]=analysts': 1, 'w[1]=clear': 1, 'w[0]=Friday': 1, 'pos[0]|pos[1]=NN|VBD': 1, 'w[-1]=over': 1, 'w[-1]|w[0]=is|another': 1, 'w[1]=remains': 1, 'w[1]=highest': 1, 'w[-1]|w[0]=by|exchange': 1, 'w[0]|w[1]=overall|evidence': 1, 'w[0]|w[1]=July|are': 1, 'w[0]|w[1]=an|awful': 1, 'w[-1]|w[0]=said|there': 1, 'pos[0]=VBD': 1, 'w[-1]|w[0]=up|3.8': 1, 'w[0]|w[1]=a|reduction': 1, 'w[-1]=increased': 1, 'w[0]|w[1]=a|5.4': 1, 'w[0]|w[1]=further|evidence': 1, 'w[1]=to': 1, 'pos[0]|pos[1]=PRP|JJ': 1, 'pos[1]=JJS': 1, 'w[-1]=with': 1, 'w[0]|w[1]=a|unit': 1, 'w[1]=third': 1, 'w[1]=very': 1, 'pos[-1]|pos[0]=NN|POS': 1, 'pos[-1]|pos[0]=VBD|PRP$': 1, 'w[0]|w[1]=the|outlook': 1, 'w[-1]|w[0]=in|July': 1, 'pos[0]|pos[1]=NN|MD': 1, 'w[-1]|w[0]=and|the': 1, 'w[1]=flat': 1, 'w[1]=Joshi': 1, 'w[0]|w[1]=No|one': 1, 'pos[0]|pos[1]=JJ|IN': 1, 'pos[-1]|pos[0]=CC|NN': 1, 'w[-1]|w[0]=adjusting|positions': 1, 'w[-1]|w[0]=released|Friday': 1, 'w[0]|w[1]=Nigel|Lawson': 1, 'w[-1]|w[0]=be|an': 1, 'w[0]=Nomura': 1, \"w[0]|w[1]='s|failure\": 1, 'w[-1]|w[0]=rose|0.1': 1, 'w[0]=no': 1, 'pos[0]=RBR': 1, 'w[0]|w[1]=the|past': 1, 'w[0]|w[1]=a|firm': 1, 'w[1]=1.6': 1, 'w[0]=October': 1, 'w[-1]|w[0]=-RRB-|deficit': 1, 'w[-1]|w[0]=in|imports': 1, 'w[-1]|w[0]=,|U.K.': 1, 'w[0]=He': 1, 'w[0]|w[1]=another|sharp': 1, 'w[0]=economists': 1, 'w[0]|w[1]=sterling|of': 1, 'w[1]=import': 1, 'w[1]=new': 1, 'w[-1]|w[0]=but|suggestions': 1, 'pos[0]|pos[1]=JJR|NN': 1, 'w[1]=audience': 1, 'pos[-1]|pos[0]=VBG|PRP': 1, 'w[-1]|w[0]=into|the': 1, 'pos[0]|pos[1]=RB|JJ': 1, 'w[0]=release': 1, 'w[1]=rather': 1, 'w[-1]|w[0]=said|the': 1, 'w[0]=tomorrow': 1, 'pos[1]=VBN': 1, 'w[-1]|w[0]=reckons|the': 1, 'w[0]|w[1]=base|rates': 1, 'w[-1]|w[0]=in|exports': 1, 'w[-1]|w[0]=release|tomorrow': 1, 'w[-1]|w[0]=to|16': 1, 'pos[0]=VBG': 1, 'w[1]=economists': 1, 'w[0]|w[1]=1988|.': 1, 'w[0]|w[1]=underlying|support': 1, 'pos[-1]|pos[0]=TO|CD': 1, 'w[0]|w[1]=senior|U.K.': 1, 'w[-1]|w[0]=if|the': 1, 'w[-1]|w[0]=reckon|underlying': 1, 'w[0]|w[1]=Midland|Montagu': 1, 'w[1]=risks': 1, 'w[-1]=takes': 1, 'pos[0]|pos[1]=DT|PRP': 1, 'w[0]=European': 1, 'w[-1]=adjusting': 1, 'w[-1]|w[0]=of|a': 1, 'pos[0]|pos[1]=DT|RB': 1, 'w[-1]=transforming': 1, 'w[-1]|w[0]=to|as': 1, 'w[0]|w[1]=Midland|Bank': 1, 'w[-1]|w[0]=given|continued': 1, 'w[0]|w[1]=imports|,': 1, 'pos[0]|pos[1]=JJ|NNS': 1, \"w[-1]|w[0]=chancellor|'s\": 1, 'w[-1]|w[0]=Exchequer|Nigel': 1, 'w[0]=few': 1, 'w[0]=effect': 1, 'w[-1]|w[0]=,|overall': 1, 'pos[-1]|pos[0]=VBZ|JJ': 1, 'w[0]|w[1]=sterling|,': 1, 'w[1]=unexpected': 1, 'w[0]|w[1]=a|#': 1, 'w[0]|w[1]=August|.': 1, 'w[0]|w[1]=Sanjay|Joshi': 1, 'pos[1]=DT': 1, 'w[1]=tomorrow': 1, 'w[-1]=up': 1, 'w[-1]|w[0]=take|another': 1, 'pos[-1]|pos[0]=,|EX': 1, 'w[-1]|w[0]=than|Mr.': 1, 'w[1]=expenditure': 1, 'w[-1]|w[0]=takes|effect': 1, 'w[1]=years': 1, 'w[0]|w[1]=exchange|rate': 1, 'pos[0]|pos[1]=PRP$|JJ': 1, 'w[-1]|w[0]=noted|Simon': 1, 'w[-1]|w[0]=with|a': 1, 'w[0]|w[1]=economists|and': 1, 'w[1]=spending': 1, 'w[0]|w[1]=the|necessary': 1, 'w[1]=Exchequer': 1, 'w[0]|w[1]=U.K.|economist': 1, 'w[-1]|w[0]=least|some': 1, 'w[-1]=into': 1, 'w[-1]|w[0]=,|who': 1, 'w[0]=services': 1, 'w[-1]|w[0]=if|trade': 1, 'w[-1]|w[0]=announce|any': 1, 'w[0]=eight': 1, 'w[0]=raw': 1, 'w[0]|w[1]=fears|of': 1, 'w[-1]|w[0]=after|August': 1, 'w[1]=Bank': 1, 'pos[0]|pos[1]=NN|.': 1, 'w[0]|w[1]=few|economists': 1, 'pos[0]|pos[1]=NNP|CD': 1, 'w[0]=only': 1, 'w[1]=currency': 1, \"w[0]|w[1]='s|unexpected\": 1, \"w[0]|w[1]='s|manufacturing\": 1, 'w[0]|w[1]=3.8|%': 1, 'pos[0]|pos[1]=VBD|JJ': 1, 'w[0]|w[1]=continued|high': 1, 'pos[-1]|pos[0]=VBZ|NN': 1, 'w[-1]|w[0]=for|imports': 1, 'w[1]=Montagu': 1, 'w[1]=compares': 1, 'w[0]|w[1]=any|new': 1, 'w[0]|w[1]=Baring|Brothers': 1, 'w[-1]=Britain': 1, 'w[1]=after': 1, 'w[0]|w[1]=much|because': 1, 'pos[0]|pos[1]=EX|MD': 1, 'w[0]=little': 1, 'w[1]=moment': 1, 'w[-1]|w[0]=that|rates': 1, 'w[0]|w[1]=sterling|has': 1, 'w[1]=failure': 1, 'w[0]|w[1]=analysts|reckon': 1, 'w[-1]=rose': 1, 'w[-1]|w[0]=that|Britain': 1, 'w[-1]|w[0]=that|spending': 1, 'w[0]|w[1]=he|is': 1, 'w[1]=goods': 1, 'w[-1]|w[0]=in|sterling': 1, 'w[-1]|w[0]=for|September': 1, 'w[0]|w[1]=no|sign': 1, 'w[-1]=agree': 1, 'pos[-1]|pos[0]=,|NNS': 1, 'pos[0]|pos[1]=NNS|,': 1, 'pos[0]|pos[1]=NNP|CC': 1, 'w[-1]|w[0]=see|further': 1, 'w[-1]|w[0]=show|the': 1, 'w[-1]=expect': 1, 'w[-1]=If': 1, 'w[0]=suggestions': 1, 'w[-1]|w[0]=and|foreign': 1, 'w[1]=down': 1, 'pos[0]|pos[1]=RBR|DT': 1, 'pos[0]=WP': 1, 'w[0]=more': 1, 'pos[1]=PRP': 1, 'w[-1]|w[0]=``|The': 1, 'w[0]=place': 1, 'w[-1]=made': 1, 'w[0]|w[1]=This|compares': 1, 'w[0]|w[1]=the|same': 1, 'w[-1]=as': 1, 'w[-1]|w[0]=but|few': 1, 'w[1]=Thursday': 1, 'w[0]=trade': 1, 'w[0]|w[1]=The|risks': 1, 'w[0]|w[1]=sterling|over': 1, 'w[1]=also': 1, 'w[0]|w[1]=consumer|expenditure': 1, 'w[1]=deficit': 1, 'pos[0]|pos[1]=NNP|NN': 1, 'w[-1]|w[0]=But|analysts': 1, 'w[0]|w[1]=his|audience': 1, 'w[-1]|w[0]=expect|the': 1, 'w[-1]=chancellor': 1, 'w[-1]|w[0]=forecasts|a': 1, 'w[1]=rebound': 1, 'pos[-1]=)': 1, 'w[0]|w[1]=July|and': 1, 'w[-1]=rates': 1, 'w[-1]=speech': 1, 'w[1]=for': 1, 'w[-1]|w[0]=reduce|fears': 1, 'w[-1]|w[0]=that|he': 1, \"w[0]|w[1]='s|near-record\": 1, 'w[0]=underlying': 1, 'w[1]=last': 1, 'w[0]|w[1]=effect|.': 1, 'w[0]|w[1]=trade|figures': 1, 'pos[0]|pos[1]=POS|VBN': 1, 'w[0]=No': 1, 'w[-1]|w[0]=transforming|itself': 1}), 'O': Counter({'O': 81, 'pos[0]=,': 26, 'w[0]=,': 26, 'pos[0]=.': 25, 'w[0]=.': 25, 'pos[-1]=NN': 21, 'pos[-1]=NNP': 13, 'pos[-1]|pos[0]=NN|,': 10, 'pos[0]=CC': 9, 'pos[1]=DT': 9, 'pos[-1]=NNS': 9, 'pos[-1]|pos[0]=NNP|,': 8, 'pos[-1]=CD': 7, 'pos[-1]=RB': 7, 'pos[-1]|pos[0]=NNS|.': 7, 'pos[1]=JJ': 6, 'w[-1]=,': 5, 'pos[-1]|pos[0]=NNP|.': 5, 'w[0]=and': 5, 'w[0]=``': 5, \"pos[0]=''\": 5, 'pos[-1]=,': 5, \"w[0]=''\": 5, 'pos[-1]|pos[0]=RB|,': 5, 'pos[0]=``': 5, 'pos[-1]|pos[0]=NN|CC': 4, 'pos[0]|pos[1]=,|DT': 4, 'w[1]=the': 4, 'pos[1]=NN': 4, \"w[1]=''\": 4, \"pos[1]=''\": 4, 'pos[-1]|pos[0]=NN|.': 4, 'pos[0]|pos[1]=,|JJ': 4, 'pos[1]=VBD': 4, 'pos[0]=CD': 4, 'w[1]=he': 3, 'pos[0]=DT': 3, 'pos[0]|pos[1]=,|PRP': 3, 'pos[1]=NNP': 3, 'pos[1]=CD': 3, \"w[-1]|w[0]=,|''\": 3, 'pos[0]|pos[1]=CC|DT': 3, 'pos[1]=IN': 3, 'pos[-1]=JJ': 3, 'w[0]|w[1]=,|the': 3, 'pos[1]=NNS': 3, \"pos[0]|pos[1]=,|''\": 3, 'pos[0]|pos[1]=,|NNP': 3, 'w[-1]=billion': 3, 'pos[1]=PRP': 3, \"pos[-1]|pos[0]=,|''\": 3, 'w[0]|w[1]=,|he': 3, 'pos[-1]|pos[0]=CD|.': 3, \"w[0]|w[1]=,|''\": 3, 'pos[-1]|pos[0]=JJ|.': 2, 'pos[0]|pos[1]=CD|CD': 2, 'pos[1]=CC': 2, 'w[-1]=Briscoe': 2, 'w[-1]|w[0]=quarter|and': 2, 'w[0]=billion': 2, 'pos[0]|pos[1]=DT|NN': 2, 'w[1]=Mr.': 2, 'pos[-1]=VBP': 2, 'w[1]=but': 2, 'w[0]=that': 2, 'w[1]=said': 2, 'pos[0]|pos[1]=CC|NNS': 2, 'pos[0]|pos[1]=CC|JJ': 2, 'pos[0]|pos[1]=``|DT': 2, 'w[0]=But': 2, 'w[0]|w[1]=,|Mr.': 2, 'w[-1]=pound': 2, 'w[-1]=Thursday': 2, 'w[-1]|w[0]=Briscoe|,': 2, 'pos[1]=VBZ': 2, 'w[-1]|w[0]=1988|.': 2, 'w[-1]=September': 2, 'w[1]=a': 2, 'w[-1]=imports': 2, 'w[-1]=1988': 2, 'w[1]=billion': 2, 'pos[-1]|pos[0]=NN|``': 2, \"pos[0]|pos[1]=''|VBD\": 2, 'w[0]=but': 2, 'pos[-1]|pos[0]=RB|.': 2, 'w[-1]=quarter': 2, 'pos[-1]|pos[0]=CD|CD': 2, 'pos[1]=VB': 1, 'w[-1]=exports': 1, 'pos[-1]|pos[0]=IN|DT': 1, 'pos[0]|pos[1]=,|WP': 1, 'w[-1]|w[0]=positions|.': 1, 'w[1]=noted': 1, 'pos[1]=)': 1, 'pos[-1]|pos[0]=,|``': 1, 'w[1]=-LRB-': 1, 'w[-1]=sterling': 1, 'w[1]=given': 1, 'w[1]=that': 1, 'pos[0]|pos[1]=,|NNS': 1, 'pos[0]|pos[1]=,|EX': 1, 'w[-1]=#': 1, 'w[-1]=$': 1, 'w[1]=analysts': 1, 'w[-1]|w[0]=time|,': 1, 'w[0]=the': 1, 'w[-1]=and': 1, 'w[0]|w[1]=,|there': 1, 'w[-1]=tomorrow': 1, 'pos[0]|pos[1]=#|CD': 1, 'w[-1]|w[0]=Thursday|.': 1, 'w[1]=-RRB-': 1, 'pos[0]|pos[1]=DT|#': 1, 'w[0]|w[1]=the|#': 1, 'w[-1]=Nevertheless': 1, \"pos[-1]|pos[0]=NN|''\": 1, 'w[-1]|w[0]=economists|and': 1, 'pos[0]|pos[1]=CD|(': 1, 'w[-1]=side': 1, 'w[0]=Chancellor': 1, \"pos[-1]|pos[0]=.|''\": 1, 'w[-1]|w[0]=government|``': 1, 'pos[-1]|pos[0]=VBP|DT': 1, 'w[-1]=effect': 1, 'w[0]|w[1]=``|is': 1, 'w[-1]|w[0]=$|3.2': 1, 'w[0]|w[1]=,|economists': 1, 'w[-1]=place': 1, 'w[-1]=Certainly': 1, 'w[1]=European': 1, 'w[-1]=position': 1, 'w[-1]=Co.': 1, 'w[1]=few': 1, 'w[-1]=gap': 1, \"w[0]|w[1]=''|in\": 1, \"w[-1]=''\": 1, 'w[1]=in': 1, \"pos[-1]|pos[0]=''|CC\": 1, 'w[0]|w[1]=``|can': 1, 'pos[-1]|pos[0]=$|CD': 1, 'w[-1]|w[0]=Thursday|,': 1, 'w[-1]=number': 1, 'w[-1]|w[0]=necessary|.': 1, 'w[-1]=Institute': 1, 'pos[0]|pos[1]=,|``': 1, 'w[-1]|w[0]=August|.': 1, 'pos[1]=$': 1, 'w[0]|w[1]=-RRB-|deficit': 1, 'w[-1]|w[0]=September|.': 1, 'w[1]=``': 1, 'pos[-1]=VBN': 1, 'w[-1]|w[0]=decline|,': 1, 'w[-1]|w[0]=Joshi|,': 1, \"w[-1]|w[0]=''|but\": 1, 'w[-1]=PLC': 1, 'w[-1]|w[0]=Certainly|,': 1, 'pos[-1]=VBD': 1, 'w[-1]=strong': 1, 'pos[0]=#': 1, 'w[-1]|w[0]=clouded|.': 1, 'w[1]=can': 1, 'w[1]=was': 1, 'w[-1]|w[0]=#|2': 1, 'pos[-1]|pos[0]=JJ|,': 1, 'pos[1]=EX': 1, 'w[0]=2': 1, 'w[-1]|w[0]=effect|.': 1, 'w[0]|w[1]=,|overall': 1, 'w[0]|w[1]=that|sterling': 1, 'w[0]|w[1]=and|that': 1, 'w[-1]|w[0]=Dillow|,': 1, \"w[-1]|w[0]=position|''\": 1, 'w[1]=sterling': 1, 'w[0]|w[1]=,|senior': 1, 'pos[-1]|pos[0]=DT|#': 1, 'w[1]=No': 1, 'w[-1]|w[0]=,|``': 1, 'pos[-1]|pos[0]=VBN|.': 1, 'w[0]|w[1]=and|was': 1, 'w[-1]|w[0]=place|and': 1, 'pos[0]|pos[1]=)|NN': 1, 'pos[-1]=DT': 1, 'w[1]=consumer': 1, 'w[-1]|w[0]=gap|,': 1, 'pos[0]|pos[1]=``|VBZ': 1, 'pos[-1]|pos[0]=CD|(': 1, 'w[-1]|w[0]=inflows|.': 1, 'w[0]|w[1]=billion|-LRB-': 1, 'w[-1]|w[0]=number|,': 1, 'pos[1]=VBN': 1, 'pos[0]|pos[1]=NNP|IN': 1, 'w[0]|w[1]=and|a': 1, 'w[-1]=economists': 1, 'w[-1]|w[0]=the|#': 1, 'w[0]|w[1]=,|said': 1, 'w[0]=3.2': 1, 'w[1]=economists': 1, 'w[-1]|w[0]=sterling|,': 1, 'pos[-1]=$': 1, 'w[-1]=August': 1, 'w[-1]=deficit': 1, 'w[-1]=3.2': 1, 'w[0]|w[1]=,|warns': 1, 'w[-1]=Meanwhile': 1, 'w[0]=#': 1, 'w[-1]|w[0]=further|.': 1, 'pos[-1]|pos[0]=VBP|.': 1, 'w[1]=fail': 1, 'w[0]|w[1]=#|2': 1, 'w[-1]|w[0]=quickly|.': 1, 'w[-1]|w[0]=economy|``': 1, 'w[-1]|w[0]=pound|,': 1, 'w[-1]=rises': 1, 'w[-1]=speech': 1, \"pos[0]|pos[1]=''|CC\": 1, 'w[1]=suggestions': 1, 'w[1]=$': 1, 'w[0]|w[1]=But|consumer': 1, \"w[-1]|w[0]=.|''\": 1, 'w[-1]|w[0]=deficit|and': 1, 'w[-1]|w[0]=speech|,': 1, 'w[-1]|w[0]=imports|.': 1, 'w[-1]|w[0]=exports|.': 1, 'w[0]|w[1]=Chancellor|of': 1, 'w[0]|w[1]=,|a': 1, 'w[-1]=from': 1, 'w[-1]|w[0]=noted|,': 1, 'pos[-1]=IN': 1, 'w[0]|w[1]=billion|-RRB-': 1, 'w[-1]|w[0]=3.2|billion': 1, 'w[1]=The': 1, 'pos[-1]|pos[0]=,|CC': 1, 'pos[0]|pos[1]=CD|)': 1, 'pos[-1]|pos[0]=#|CD': 1, 'pos[0]|pos[1]=``|IN': 1, 'w[0]|w[1]=2|billion': 1, 'w[0]|w[1]=,|fail': 1, 'w[0]|w[1]=3.2|billion': 1, 'w[-1]=clouded': 1, 'pos[-1]=.': 1, 'w[-1]|w[0]=pressure|,': 1, 'w[1]=spending': 1, 'w[-1]|w[0]=billion|.': 1, 'pos[0]|pos[1]=,|CC': 1, 'w[-1]|w[0]=weakness|.': 1, \"w[0]|w[1]=.|''\": 1, 'pos[0]|pos[1]=,|VB': 1, 'w[-1]=necessary': 1, 'w[0]|w[1]=,|but': 1, 'w[0]|w[1]=but|few': 1, 'w[0]=-RRB-': 1, 'w[1]=of': 1, 'w[-1]|w[0]=widely|,': 1, 'pos[1]=#': 1, 'w[0]|w[1]=that|spending': 1, 'w[-1]|w[0]=say|.': 1, 'w[-1]|w[0]=side|,': 1, 'w[-1]|w[0]=from|the': 1, 'pos[0]|pos[1]=``|MD': 1, 'w[-1]|w[0]=billion|-RRB-': 1, 'w[0]=-LRB-': 1, 'w[1]=overall': 1, 'w[0]|w[1]=,|``': 1, 'w[-1]|w[0]=week|.': 1, 'w[-1]=Joshi': 1, 'pos[-1]|pos[0]=NNS|CC': 1, 'w[-1]=2': 1, 'w[1]=2': 1, 'w[-1]=economy': 1, 'pos[-1]|pos[0]=CD|)': 1, 'w[1]=#': 1, 'w[-1]|w[0]=billion|-LRB-': 1, 'w[0]|w[1]=and|the': 1, 'pos[0]=NNP': 1, 'w[-1]=noted': 1, 'w[-1]=time': 1, 'w[0]|w[1]=,|due': 1, 'w[-1]|w[0]=PLC|.': 1, \"w[0]|w[1]=''|said\": 1, 'w[-1]|w[0]=deficits|.': 1, 'w[-1]=pressure': 1, 'w[1]=is': 1, 'w[0]|w[1]=,|European': 1, 'w[-1]=show': 1, 'w[0]|w[1]=but|suggestions': 1, 'w[-1]=widely': 1, \"w[0]|w[1]=''|noted\": 1, 'w[-1]=further': 1, 'w[-1]=say': 1, 'w[0]|w[1]=But|analysts': 1, 'w[-1]|w[0]=,|but': 1, 'w[1]=U.K.': 1, 'w[1]=foreign': 1, 'w[0]|w[1]=,|U.K.': 1, 'w[-1]|w[0]=September|,': 1, 'w[-1]|w[0]=Montagu|,': 1, 'pos[0]|pos[1]=(|$': 1, 'pos[1]=MD': 1, 'w[-1]=Montagu': 1, 'pos[-1]|pos[0]=CC|DT': 1, \"pos[-1]=''\": 1, 'w[-1]=positions': 1, 'w[-1]=inflows': 1, 'w[-1]|w[0]=show|that': 1, 'pos[-1]=#': 1, 'w[-1]=week': 1, 'pos[1]=``': 1, 'w[-1]=deficits': 1, 'w[1]=due': 1, 'pos[-1]|pos[0]=VBD|,': 1, 'w[-1]=weakness': 1, 'pos[0]|pos[1]=,|VBD': 1, 'w[-1]=decline': 1, 'pos[0]|pos[1]=CC|NN': 1, 'pos[0]|pos[1]=,|VBZ': 1, 'w[1]=warns': 1, 'w[1]=senior': 1, 'w[-1]=years': 1, \"w[0]|w[1]=''|but\": 1, 'w[-1]=.': 1, 'w[0]|w[1]=-LRB-|$': 1, 'w[0]|w[1]=and|foreign': 1, 'w[1]=If': 1, 'w[-1]|w[0]=Institute|.': 1, 'w[-1]|w[0]=ago|.': 1, 'w[0]|w[1]=``|The': 1, 'w[-1]|w[0]=years|.': 1, 'w[0]|w[1]=,|given': 1, \"pos[0]|pos[1]=''|IN\": 1, 'w[-1]|w[0]=rises|.': 1, 'w[0]|w[1]=``|If': 1, \"pos[0]|pos[1]=.|''\": 1, 'pos[-1]=CC': 1, 'w[1]=deficit': 1, 'w[1]=there': 1, 'w[-1]=ago': 1, 'w[-1]|w[0]=and|that': 1, 'w[-1]|w[0]=tomorrow|,': 1, 'w[-1]|w[0]=Co.|,': 1, 'pos[0]|pos[1]=,|VBN': 1, 'pos[0]=(': 1, 'w[-1]=quickly': 1, 'w[-1]|w[0]=Nevertheless|,': 1, 'w[-1]=However': 1, 'pos[0]=)': 1, 'w[1]=who': 1, 'pos[0]|pos[1]=CC|VBD': 1, 'w[0]|w[1]=``|No': 1, 'w[-1]=government': 1, 'w[-1]=the': 1, 'w[-1]|w[0]=imports|,': 1, 'pos[1]=WP': 1, 'w[-1]|w[0]=2|billion': 1, 'w[-1]|w[0]=However|,': 1, 'w[-1]|w[0]=Meanwhile|,': 1, 'w[-1]=Dillow': 1, 'w[-1]|w[0]=strong|,': 1, 'pos[-1]|pos[0]=NNS|,': 1, 'w[0]|w[1]=,|who': 1, 'w[-1]|w[0]=pound|.': 1, 'pos[1]=(': 1}), 'B-PP|B-VP': Counter({'B-PP|B-VP': 1}), 'B-VP|B-PP': Counter({'B-VP|B-PP': 5}), 'B-SBAR|B-ADJP': Counter({'B-SBAR|B-ADJP': 2})}\n"
     ]
    }
   ],
   "source": [
    "print(\"number of generated features:\")\n",
    "print(len(crf_m.model.modelfeatures_codebook))\n",
    "print(\"features:\")\n",
    "print(crf_m.model.modelfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Training CRFs model (i.e. estimating parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we build our CRFs model, we move to the parameters training/estimating phase. In this stage, we basically learn the parameters of a CRFs model where by the end of the training, our CRFs model will be able to decode sequences (i.e. assign labels/tags by using the observations/attributes tracks) with a good performance.\n",
    "To do so, we use the <code class=\"pseq_method\">train_model(args)</code> method in the <code class=\"pseq_class\">GenericTrainingWorkflow</code> class. The method takes the following arguments:\n",
    "<ul>\n",
    "<li><code class=\"pseq_args\">seqs_id</code>: list of sequence ids referring to the sequences to be used for training the model. These ids refer to the same sequences we used for building the model. They are found in the <code class=\"pseq_var\">data_split</code> variable.</li>\n",
    "<li><code class=\"pseq_args\">crf_model</code>: instance of a CRFs model such as the one returned by <code class=\"pseq_method\">build_crf_model(args)</code> method we used earlier (<a href=\"#pseq_buildcrfmodel\">see this section</a>).\n",
    "<li><code class=\"pseq_args\">optimization_options</code>: dictionary specifying the training method and its corresponding options. Below, we will discuss this in detail.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Training methods -- optimization options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a> supports multiple optimization options that are grouped into two categories:\n",
    "<ul>\n",
    "<li><strong>gradient-based</strong>: these methods compute the gradient of the sequences to train model parameters</li>\n",
    "<li><strong>perceptron/search-based</strong>: these methods use perceptron-like training that do not use the gradient for learning model parameters</li>\n",
    "</ul>\n",
    "\n",
    "Generally, perceptron training methods are faster to use compared to gradient-based ones. However, gradient-based methods yield solutions (parameter estimates) that are closer to the optimal solution. This does not necessarily mean that such solutions would result in better performing models. But on average, the gradient-based methods generate better estimates resulting in better performing models. <strong><span style=\"color:red\">NB</span></strong>: exceptions do arise and therefore deciding on which category to choose is problem specific/dependent.\n",
    "\n",
    "The available training options are described in the following table:\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "    <th>Training option</th>\n",
    "    <th>Perceptron/search based</th>\n",
    "    <th>Gradient based</th>\n",
    "    <th>Reference</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">COLLINS-PERCEPTRON</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td></td>\n",
    "<td>(Collins, 2002)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SAPO</code></td>\n",
    "<td>&#10003;</td>\n",
    "<td></td>\n",
    "<td>(Sun, 2015)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SGA</code></td>\n",
    "<td></td>\n",
    "<td>&#10003;</td>\n",
    "<td>(Bottou et al., 2004)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SGA-ADADELTA</code></td>\n",
    "<td></td>\n",
    "<td>&#10003;</td>\n",
    "<td>(Zeiler, 2012)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SVRG</code></td>\n",
    "<td></td>\n",
    "<td>&#10003;</td>\n",
    "<td>(Johnson et al., 2013)</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">L-BFGS-B</code></td>\n",
    "<td></td>\n",
    "<td>&#10003;</td>\n",
    "<td>(Byrd et al., 1995)</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "For each method we can further specify corresponding options to be used while training.\n",
    "<a id=\"pseq_training_options\"></a>\n",
    "<table>\n",
    "<tr>\n",
    "    <th>Training method</th>\n",
    "    <th>Options</th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">COLLINS-PERCEPTRON</code></td>\n",
    "<td>\n",
    "<pre style=\"font-size:0.8em;\">\n",
    "        'method': 'COLLINS-PERCEPTRON'\n",
    "        'num_epochs': integer\n",
    "        'update_type':{'early', 'max-fast', 'max-exhaustive'}\n",
    "        'shuffle_seq': boolean\n",
    "        'beam_size': integer\n",
    "        'avg_scheme': {'avg_error', 'avg_uniform'}\n",
    "        'tolerance': float\n",
    "</pre>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SAPO</code></td>\n",
    "<td><pre style=\"font-size:0.8em;\">\n",
    "\n",
    "        'method': 'SAPO'\n",
    "        'num_epochs': integer\n",
    "        'update_type':'early'\n",
    "        'shuffle_seq': boolean\n",
    "        'beam_size': integer\n",
    "        'topK': integer\n",
    "        'tolerance': float\n",
    "</pre>                     \n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SGA</code></td>\n",
    "<td><pre style=\"font-size:0.74em;\">\n",
    "          \n",
    "         'method': 'SGA'\n",
    "         'regularization_type': {'l1', 'l2'}\n",
    "         'regularization_value': float\n",
    "         'num_epochs': integer\n",
    "         'tolerance': float\n",
    "         'learning_rate_schedule': {\"bottu\", \"exponential_decay\", \"t_inverse\", \"constant\"}\n",
    "         't0': float\n",
    "         'alpha': float\n",
    "         'eta0': float\n",
    "</pre>                     \n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SGA-ADADELTA</code></td>\n",
    "<td><pre style=\"font-size:0.8em;\">\n",
    "         'method': 'SGA-ADADELTA'\n",
    "         'regularization_type': {'l1', 'l2'}\n",
    "         'regularization_value': float\n",
    "         'num_epochs': integer\n",
    "         'tolerance': float\n",
    "         'rho': float\n",
    "         'epsilon': float\n",
    "</pre>\n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">SVRG</code></td>\n",
    "<td><pre style=\"font-size:0.74em;\">\n",
    "          \n",
    "         'method': 'SGA'\n",
    "         'regularization_type': {'l1', 'l2'}\n",
    "         'regularization_value': float\n",
    "         'num_epochs': integer\n",
    "         'tolerance': float\n",
    "         'learning_rate_schedule': {\"bottu\", \"exponential_decay\", \"t_inverse\", \"constant\"}\n",
    "         't0': float\n",
    "         'alpha': float\n",
    "         'eta0': float\n",
    "</pre>     \n",
    "</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><code class=\"pseq_code\">L-BFGS-B</code></td>\n",
    "<td><pre style=\"font-size:0.8em;\">\n",
    "         'method': {'L-BFGS-B', 'BFGS'}\n",
    "         'regularization_type': 'l2'\n",
    "         'regularization_value': float\n",
    "         (options below are eqivalent to one provided by <a href=\"https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html\">scipy.optimize package</a>)\n",
    "         'disp': boolean\n",
    "         'maxcor': integer, \n",
    "         'ftol': float, \n",
    "         'gtol': float,\n",
    "         'eps': float, \n",
    "         'maxls': integer,\n",
    "         'maxiter': integer, \n",
    "         'maxfun': integer\n",
    "</pre>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "General comments on the options provided to <strong>perceptron/search-based</strong> methods:\n",
    "\n",
    "<ul>\n",
    "<li><code class=\"pseq_code\">num_epochs</code> refers to the number of epochs/passes to go through the sequences/segments</li>\n",
    "<li><code class=\"pseq_code\">shuffle_seq</code> decides if to shuffle the sequences in every epoch </li>\n",
    "<li><code class=\"pseq_code\">tolerance</code> represents the threshold to check against as a stopping criterion. If the relative difference between the average decoding error across all sequences between the current and previous epoch is below the threshold (tolerance), then we stop the training.</li>\n",
    "<li><code class=\"pseq_code\">update_type</code> and <code class=\"pseq_code\">beam_size</code> are related options. <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a> supports inexact search by using beam search (i.e. pruning states falling off a specified beam size) allowing for faster inference and training. This is implemented within the <strong>violation-fixing framework</strong> (see (Huang et al., 2012) for more details). Hence, if we want to prune states (i.e. use beam search) while learning the parameters, we can specify the <code class=\"pseq_code\">update_type</code> we want based on the <strong>violation-fixing framework</strong>. If we are to use a full beam (i.e. no pruning), then the <code class=\"pseq_code\">update_type</code> is irrelevant as we will be doing full update.</li>\n",
    "<li><code class=\"pseq_code\">topK</code> is an available option in <code class=\"pseq_code\">SAPO</code> method. It specifies how many sequences to decode/use while learning the parameters of the model. For more info on the procedure, see (Sun, 2015).</li>\n",
    "</ul>\n",
    "\n",
    "Lastly, the learned parameters are based on the average values across the training updates in all the epochs. This  provides a sort of regularization and as a result reduces overfitting. As a reminder, many of these options are set by default. What only matters is to specify the <code class=\"pseq_code\">method</code> and the rest is figured out automatically.\n",
    "\n",
    "General comments on the options provided to <strong>gradient-based</strong> methods:\n",
    "\n",
    "<ul>\n",
    "<li><code class=\"pseq_code\">num_epochs</code> refers to the number of epochs/passes to go through the sequences/segments</li>\n",
    "<li><code class=\"pseq_code\">shuffle_seq</code> decides if to shuffle the sequences in every epoch </li>\n",
    "<li><code class=\"pseq_code\">tolerance</code> represents the threshold to check against as a stopping criterion. If the relative difference between the estimated average log-likelihood across all sequences between the current and previous epoch is below the threshold (tolerance), then we stop the training.</li>\n",
    "<li><code class=\"pseq_code\">regularization_type</code> and <code class=\"pseq_code\">regularization_value</code> are related options. <a href=\"https://bitbucket.org/A_2/pyseqlab\">PySeqLab</a> supports maximum likelihood (MLE) and maximum a posteriori (MAP) estimation. This is done by offering two regularization schemes: (1) L2 regularization (i.e. assuming prior Gaussian distribution on the model weights) and (2) L1 regularization using the approach in (Tsuruoka et al., 2009). Hence, once we specify the type of regularization (i.e. <code class=\"pseq_code\">regularization_type</code>), we specify the regularization value (i.e. <code class=\"pseq_code\">regularization_value</code>)\n",
    "</li>\n",
    "<li><code class=\"pseq_code\">learning_rate_schedule</code> option for methods <code class=\"pseq_code\">SGA</code> and <code class=\"pseq_code\">SVRG</code> specifies the computation of the step size parameter multiplying the gradient. <code class=\"pseq_code\">constant</code> supports fixed step size while <code class=\"pseq_code\">bottu</code>, <code class=\"pseq_code\">exponential_decay</code> and <code class=\"pseq_code\">t_inverse</code> updates the step size iteratively each using different methods/formulas. All approaches require to specify the initial step size <code class=\"pseq_code\">t0</code>. Additionally, <code class=\"pseq_code\">exponential_decay</code> option requires the specification of <code class=\"pseq_code\">alpha</code> and <code class=\"pseq_code\">eta0</code> (see Tsuruoka et al., 2009 for more info about <code class=\"pseq_code\">exponential_decay</code> approach).</li>\n",
    "<li><code class=\"pseq_code\">rho</code> and <code class=\"pseq_code\">epsilon</code> options are related to <code class=\"pseq_code\">SGA-ADADELTA</code> method. In this method, the step size is an adaptive vector where each component represent a step size for a corresponding parameter in the CRFs model. For more info regarding both options (<code class=\"pseq_code\">rho</code> and <code class=\"pseq_code\">epsilon</code>) and their role in the computation of the adaptive step size, consult to ADADELTA (Zeiler, 2012).</li> \n",
    "</ul>\n",
    "\n",
    "Again as a reminder, many of these options are set by default. What only matters is to specify the <code class=\"pseq_code\">method</code> and the rest is figured out automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Learning/estimating model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we learned about the available training methods, we proceed to train <a href=\"#pseq_inspect_modelfeatures\">our constructed CRFs model</a>. We will be using first the gradient-based training methods such as {<code class=\"pseq_code\">SGA</code>, <code class=\"pseq_code\">SGA-ADADELTA</code>, <code class=\"pseq_code\">SVRG</code>}. We start by having the parameter weights initialized to <code class=\"pseq_code\">0</code> and once we run <code class=\"pseq_method\">train_model(args)</code> method in the <code class=\"pseq_class\">GenericTrainingWorkflow</code> class, the process of optimization and parameter estimation starts. At the end of the process, we will get a new estimates/values for the weights and the trained model will be dumped on disk. Traversing our working directory (i.e. <code class=\"pseq_code\">working_dir</code>) we specified earlier, we will find a new created folder called <code class=\"pseq_code\">models</code>. In this folder, each time we train a model, we will get a separate folder named based on a generated date/time string. This folder will comprise <code class=\"pseq_code\">model_parts</code> folder and another log file named <code class=\"pseq_code\">crf_training_log.txt</code>. The <code class=\"pseq_code\">model_parts</code> folder holds the saved parts of the trained model. Whereas the log file contains log of the training process (such as the time of finishing an epoch, the estimated average log-likelihood, etc.). Additionally, if the training method is one of {<code class=\"pseq_code\">SGA</code>, <code class=\"pseq_code\">SGA-ADADELTA</code>, <code class=\"pseq_code\">SVRG</code>}, we will get additional file named <code class=\"pseq_code\">avg_loglikelihood_training</code>. This file is a <code class=\"pseq_code\">numpy</code> array containing estimated average log-likelihood for each epoch. We can plot this array for diagnostics (generally, it should be a growing curve as we are performing gradient ascent). In case we are using <code class=\"pseq_code\">L-BFGS-B</code> method, we will have gradient descent as we are optimizing the negative log-likelihood (see [scipy.optimize package](https://docs.scipy.org/doc/scipy/reference/optimize.minimize-lbfgsb.html) for more info). The tree path visualization for the working directory is provide below:\n",
    "<a id=\"pseq_modelparts_pointer\"></a>\n",
    "<pre style=\"font-size:0.8em;\">\n",
    "working_dir\n",
    "│   ├── reference_corpus_2017_5_17-8_56_49_631884\n",
    "│   │   ├── data_split\n",
    "│   │   ├── global_features\n",
    "│   │   │   ├── log.txt\n",
    "│   │   │   ├── seq_1\n",
    "│   │   │   ├── seq_10\n",
    "│   │   │   ├── seq_11\n",
    "│   │   │   ├── seq_12\n",
    "│   │   │   ├── seq_13\n",
    "│   │   │   ├── seq_14\n",
    "│   │   │   ├── seq_15\n",
    "│   │   │   ├── seq_16\n",
    "│   │   │   ├── seq_17\n",
    "│   │   │   ├── seq_18\n",
    "│   │   │   ├── seq_19\n",
    "│   │   │   ├── seq_2\n",
    "│   │   │   ├── seq_20\n",
    "│   │   │   ├── seq_21\n",
    "│   │   │   ├── seq_22\n",
    "│   │   │   ├── seq_23\n",
    "│   │   │   ├── seq_24\n",
    "│   │   │   ├── seq_25\n",
    "│   │   │   ├── seq_3\n",
    "│   │   │   ├── seq_4\n",
    "│   │   │   ├── seq_5\n",
    "│   │   │   ├── seq_6\n",
    "│   │   │   ├── seq_7\n",
    "│   │   │   ├── seq_8\n",
    "│   │   │   ├── seq_9\n",
    "│   │   ├── model_activefeatures_f_0 \n",
    "│   ├── models\n",
    "│   │   ├── 2017_5_17-14_11_15_259071\n",
    "│   │   │   ├── model_parts\n",
    "│   │   │   ├── avg_loglikelihood_training\n",
    "│   │   │   ├── crf_training_log.txt\n",
    "</pre>\n",
    "\n",
    "<a href=\"#pseq_gradientbased_methods\">Below is an example</a> for training a CRFs model using {<code class=\"pseq_code\">SGA</code>, <code class=\"pseq_code\">SGA-ADADELTA</code>, <code class=\"pseq_code\">SVRG</code>} methods. The training will yield three models, each dumped on disk. For every model, we will get a pointer to its <code class=\"pseq_code\">model_part</code> folder that could be utilized for reviving and using the model later. We also plot the estimated average log-likelihood of each training method. Another training example, which involves using <code class=\"pseq_code\">L-BGFS-B</code> method is <a href=\"#pseq_lbfgs_method\">provided below</a>. The training method displayed a success message (i.e. optimal solution is found). As a result, we have trained four models in total that use gradient-based training methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_gradientbased_methods\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing using optimization options:\n",
      "{'regularization_value': 0, 'num_epochs': 10, 'method': 'SGA-ADADELTA', 'regularization_type': 'l2'}\n",
      "k  0\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 1.0\n",
      "k  1\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.08000904984373394\n",
      "k  2\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.07782893946701097\n",
      "k  3\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.07278748769680521\n",
      "k  4\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.06585750263263428\n",
      "k  5\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.05855458475701265\n",
      "k  6\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.051670904497450286\n",
      "k  7\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.04633502025455483\n",
      "k  8\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.04162623339077581\n",
      "k  9\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.03784491294167672\n",
      "**************************************************\n",
      "trianing using optimization options:\n",
      "{'regularization_value': 0, 'num_epochs': 10, 'method': 'SGA', 'regularization_type': 'l2'}\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 1.0\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.357379117320816\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.13934649080254785\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.07802543702038112\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.057307019920274406\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.04499771901652247\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.037135144032312994\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.030221216092835932\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.02655704695304125\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 0.02286622525606504\n",
      "**************************************************\n",
      "trianing using optimization options:\n",
      "{'regularization_value': 0, 'num_epochs': 2, 'method': 'SVRG', 'regularization_type': 'l2'}\n",
      "num seqs left: 24\n",
      "num seqs left: 23\n",
      "num seqs left: 22\n",
      "num seqs left: 21\n",
      "num seqs left: 20\n",
      "num seqs left: 19\n",
      "num seqs left: 18\n",
      "num seqs left: 17\n",
      "num seqs left: 16\n",
      "num seqs left: 15\n",
      "num seqs left: 14\n",
      "num seqs left: 13\n",
      "num seqs left: 12\n",
      "num seqs left: 11\n",
      "num seqs left: 10\n",
      "num seqs left: 9\n",
      "num seqs left: 8\n",
      "num seqs left: 7\n",
      "num seqs left: 6\n",
      "num seqs left: 5\n",
      "num seqs left: 4\n",
      "num seqs left: 3\n",
      "num seqs left: 2\n",
      "num seqs left: 1\n",
      "num seqs left: 0\n",
      "reldiff = 1.0\n",
      "stage 0\n",
      "average gradient phase: 24 seqs left\n",
      "average gradient phase: 23 seqs left\n",
      "average gradient phase: 22 seqs left\n",
      "average gradient phase: 21 seqs left\n",
      "average gradient phase: 20 seqs left\n",
      "average gradient phase: 19 seqs left\n",
      "average gradient phase: 18 seqs left\n",
      "average gradient phase: 17 seqs left\n",
      "average gradient phase: 16 seqs left\n",
      "average gradient phase: 15 seqs left\n",
      "average gradient phase: 14 seqs left\n",
      "average gradient phase: 13 seqs left\n",
      "average gradient phase: 12 seqs left\n",
      "average gradient phase: 11 seqs left\n",
      "average gradient phase: 10 seqs left\n",
      "average gradient phase: 9 seqs left\n",
      "average gradient phase: 8 seqs left\n",
      "average gradient phase: 7 seqs left\n",
      "average gradient phase: 6 seqs left\n",
      "average gradient phase: 5 seqs left\n",
      "average gradient phase: 4 seqs left\n",
      "average gradient phase: 3 seqs left\n",
      "average gradient phase: 2 seqs left\n",
      "average gradient phase: 1 seqs left\n",
      "average gradient phase: 0 seqs left\n",
      "we are in round 1 out of 50\n",
      "we are in round 2 out of 50\n",
      "we are in round 3 out of 50\n",
      "we are in round 4 out of 50\n",
      "we are in round 5 out of 50\n",
      "we are in round 6 out of 50\n",
      "we are in round 7 out of 50\n",
      "we are in round 8 out of 50\n",
      "we are in round 9 out of 50\n",
      "we are in round 10 out of 50\n",
      "we are in round 11 out of 50\n",
      "we are in round 12 out of 50\n",
      "we are in round 13 out of 50\n",
      "we are in round 14 out of 50\n",
      "we are in round 15 out of 50\n",
      "we are in round 16 out of 50\n",
      "we are in round 17 out of 50\n",
      "we are in round 18 out of 50\n",
      "we are in round 19 out of 50\n",
      "we are in round 20 out of 50\n",
      "we are in round 21 out of 50\n",
      "we are in round 22 out of 50\n",
      "we are in round 23 out of 50\n",
      "we are in round 24 out of 50\n",
      "we are in round 25 out of 50\n",
      "we are in round 26 out of 50\n",
      "we are in round 27 out of 50\n",
      "we are in round 28 out of 50\n",
      "we are in round 29 out of 50\n",
      "we are in round 30 out of 50\n",
      "we are in round 31 out of 50\n",
      "we are in round 32 out of 50\n",
      "we are in round 33 out of 50\n",
      "we are in round 34 out of 50\n",
      "we are in round 35 out of 50\n",
      "we are in round 36 out of 50\n",
      "we are in round 37 out of 50\n",
      "we are in round 38 out of 50\n",
      "we are in round 39 out of 50\n",
      "we are in round 40 out of 50\n",
      "we are in round 41 out of 50\n",
      "we are in round 42 out of 50\n",
      "we are in round 43 out of 50\n",
      "we are in round 44 out of 50\n",
      "we are in round 45 out of 50\n",
      "we are in round 46 out of 50\n",
      "we are in round 47 out of 50\n",
      "we are in round 48 out of 50\n",
      "we are in round 49 out of 50\n",
      "we are in round 50 out of 50\n",
      "reldiff = 1.0\n",
      "stage 1\n",
      "average gradient phase: 24 seqs left\n",
      "average gradient phase: 23 seqs left\n",
      "average gradient phase: 22 seqs left\n",
      "average gradient phase: 21 seqs left\n",
      "average gradient phase: 20 seqs left\n",
      "average gradient phase: 19 seqs left\n",
      "average gradient phase: 18 seqs left\n",
      "average gradient phase: 17 seqs left\n",
      "average gradient phase: 16 seqs left\n",
      "average gradient phase: 15 seqs left\n",
      "average gradient phase: 14 seqs left\n",
      "average gradient phase: 13 seqs left\n",
      "average gradient phase: 12 seqs left\n",
      "average gradient phase: 11 seqs left\n",
      "average gradient phase: 10 seqs left\n",
      "average gradient phase: 9 seqs left\n",
      "average gradient phase: 8 seqs left\n",
      "average gradient phase: 7 seqs left\n",
      "average gradient phase: 6 seqs left\n",
      "average gradient phase: 5 seqs left\n",
      "average gradient phase: 4 seqs left\n",
      "average gradient phase: 3 seqs left\n",
      "average gradient phase: 2 seqs left\n",
      "average gradient phase: 1 seqs left\n",
      "average gradient phase: 0 seqs left\n",
      "we are in round 1 out of 50\n",
      "we are in round 2 out of 50\n",
      "we are in round 3 out of 50\n",
      "we are in round 4 out of 50\n",
      "we are in round 5 out of 50\n",
      "we are in round 6 out of 50\n",
      "we are in round 7 out of 50\n",
      "we are in round 8 out of 50\n",
      "we are in round 9 out of 50\n",
      "we are in round 10 out of 50\n",
      "we are in round 11 out of 50\n",
      "we are in round 12 out of 50\n",
      "we are in round 13 out of 50\n",
      "we are in round 14 out of 50\n",
      "we are in round 15 out of 50\n",
      "we are in round 16 out of 50\n",
      "we are in round 17 out of 50\n",
      "we are in round 18 out of 50\n",
      "we are in round 19 out of 50\n",
      "we are in round 20 out of 50\n",
      "we are in round 21 out of 50\n",
      "we are in round 22 out of 50\n",
      "we are in round 23 out of 50\n",
      "we are in round 24 out of 50\n",
      "we are in round 25 out of 50\n",
      "we are in round 26 out of 50\n",
      "we are in round 27 out of 50\n",
      "we are in round 28 out of 50\n",
      "we are in round 29 out of 50\n",
      "we are in round 30 out of 50\n",
      "we are in round 31 out of 50\n",
      "we are in round 32 out of 50\n",
      "we are in round 33 out of 50\n",
      "we are in round 34 out of 50\n",
      "we are in round 35 out of 50\n",
      "we are in round 36 out of 50\n",
      "we are in round 37 out of 50\n",
      "we are in round 38 out of 50\n",
      "we are in round 39 out of 50\n",
      "we are in round 40 out of 50\n",
      "we are in round 41 out of 50\n",
      "we are in round 42 out of 50\n",
      "we are in round 43 out of 50\n",
      "we are in round 44 out of 50\n",
      "we are in round 45 out of 50\n",
      "we are in round 46 out of 50\n",
      "we are in round 47 out of 50\n",
      "we are in round 48 out of 50\n",
      "we are in round 49 out of 50\n",
      "we are in round 50 out of 50\n",
      "reldiff = 0.18551894353442097\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAAGnCAYAAACQMR4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxm9ZsmqMMcYYY/yWJavGGGOMMcZv/X+lEUS9ICM3aAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcdc1fdd128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimization_options = {\"method\" : \"\",\n",
    "                        \"regularization_type\": \"l2\",\n",
    "                        \"regularization_value\":0,\n",
    "                        }\n",
    "# train models using SGA, SGA-ADADELTA, and SVRG methods\n",
    "trained_models_dir = {}\n",
    "for fold in data_split:\n",
    "    train_seqs_id = data_split[fold]['train']\n",
    "    for method in (\"SGA-ADADELTA\", \"SGA\", \"SVRG\"):\n",
    "        optimization_options['method'] = method\n",
    "        if(method in {'SGA', 'SGA-ADADELTA'}):\n",
    "            num_epochs = 10\n",
    "        else:\n",
    "            num_epochs = 2\n",
    "        optimization_options['num_epochs'] = num_epochs\n",
    "        print(\"trianing using optimization options:\")\n",
    "        print(optimization_options)\n",
    "        # make sure we are initializing the weights to be 0\n",
    "        crf_m.weights.fill(0)\n",
    "        model_dir = workflow.train_model(train_seqs_id, crf_m, optimization_options)\n",
    "        print(\"*\"*50)\n",
    "        avg_ll = ReaderWriter.read_data(os.path.join(model_dir, 'avg_loglikelihood_training'))\n",
    "        plt.plot(avg_ll[1:], label=\"method:{}, {}:{}\".format(optimization_options['method'], \n",
    "                                                     optimization_options['regularization_type'],\n",
    "                                                     optimization_options['regularization_value']))\n",
    "        trained_models_dir[method] = model_dir\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.xlabel('number of epochs')\n",
    "    plt.ylabel('estimated average loglikelihood')\n",
    "    eval_options = {'model_eval':True,\n",
    "                    'metric':'f1',\n",
    "                    'seqs_info':workflow.seqs_info}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_lbfgs_method\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  1\n",
      "iteration  2\n",
      "iteration  3\n",
      "iteration  4\n",
      "iteration  5\n",
      "iteration  6\n",
      "iteration  7\n",
      "iteration  8\n",
      "iteration  9\n",
      "iteration  10\n",
      "iteration  11\n",
      "iteration  12\n",
      "iteration  13\n",
      "iteration  14\n",
      "iteration  15\n",
      "iteration  16\n",
      "iteration  17\n",
      "iteration  18\n",
      "iteration  19\n",
      "iteration  20\n",
      "iteration  21\n",
      "iteration  22\n",
      "iteration  23\n",
      "iteration  24\n",
      "iteration  25\n",
      "iteration  26\n",
      "iteration  27\n",
      "iteration  28\n",
      "iteration  29\n",
      "success:  True\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# use L-BFGS-B method for training\n",
    "optimization_options = {\"method\" : \"L-BFGS-B\",\n",
    "                        \"regularization_type\": \"l2\",\n",
    "                        \"regularization_value\":0,\n",
    "                        }\n",
    "# start with 0 weights \n",
    "crf_m.weights.fill(0)\n",
    "model_dir = workflow.train_model(train_seqs_id, crf_m, optimization_options)\n",
    "trained_models_dir['L-BFGS-B'] = model_dir\n",
    "print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the perceptron-based training methods, we use (<code class=\"pseq_code\">COLLINS-PERCEPTRON</code>, <code class=\"pseq_code\">SAPO</code>) for training CRFs model (<a href=\"#pseq_perceptrontraining_demo1\">see code</a>). We specify the training to run for 10 epochs with full beam size (i.e. no pruning), and <code class=\"pseq_code\">topK=5</code> (number of decoded sequences to use) for the <code class=\"pseq_code\">SAPO</code> method. We also plot the estimated average decoding error for every epoch. We see that the decoding error is decreasing indicating the learning is going well. The estimated average decoding error is dumped on disk in a file named <code class=\"pseq_code\">avg_decodingerror_training</code> which is the equivalent to the <code class=\"pseq_code\">avg_loglikelihood_training</code> file for the gradient-based methods. Another example using perceptron-based training is <a href=\"#pseq_perceptrontraining_demo2\">provided in this section</a>. It uses a beam search (i.e pruning) with <code class=\"pseq_code\">beam_size=5 </code>(i.e. keeping at most 5 labels at every position) and <code class=\"pseq_code\">update_type=early</code> while decoding the given sequences. Again, consult to <a href=\"#pseq_training_options\"> the training table options</a> for exploring further training options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_perceptrontraining_demo1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing using optimization options:\n",
      "{'method': 'COLLINS-PERCEPTRON', 'topK': 1, 'num_epochs': 10}\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 1.0\n",
      "average error : [0, 0.3699841540938161]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.591260465441891\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.2144932080925909\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972, 0.06146718884759971]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.01022764465144764\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972, 0.06146718884759971, 0.06022258904163503]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.34146774384145107\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972, 0.06146718884759971, 0.06022258904163503, 0.029563526678420295]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.3357559437469824\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972, 0.06146718884759971, 0.06022258904163503, 0.029563526678420295, 0.014701335951335952]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.8630018356680673\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972, 0.06146718884759971, 0.06022258904163503, 0.029563526678420295, 0.014701335951335952, 0.001081081081081081]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "average error : [0, 0.3699841540938161, 0.09503607625680972, 0.06146718884759971, 0.06022258904163503, 0.029563526678420295, 0.014701335951335952, 0.001081081081081081, 0.0]\n",
      "self._exitloop True\n",
      "**************************************************\n",
      "trianing using optimization options:\n",
      "{'method': 'SAPO', 'topK': 5, 'num_epochs': 10}\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 1.0\n",
      "average error : [0, 0.3617501171594703]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.5104021074289946\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.44129202217958297\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.001974893616365963\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.4554317791388255\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605, 0.016940787490787493]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.15302451777783838\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605, 0.016940787490787493, 0.012444168734491313]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.11769362944891781\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605, 0.016940787490787493, 0.012444168734491313, 0.015764102564102565]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.24039682368891088\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605, 0.016940787490787493, 0.012444168734491313, 0.015764102564102565, 0.025742049742049744]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.3996240990917687\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605, 0.016940787490787493, 0.012444168734491313, 0.015764102564102565, 0.025742049742049744, 0.011042183622828782]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.7468791709193686\n",
      "average error : [0, 0.3617501171594703, 0.1172615518261366, 0.04545571854188875, 0.04527653199949605, 0.016940787490787493, 0.012444168734491313, 0.015764102564102565, 0.025742049742049744, 0.011042183622828782, 0.0016]\n",
      "self._exitloop False\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqwAAAGnCAYAAABy7QVuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVoEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcdbd501cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# full beam -- using all states/labels detected in the training data\n",
    "optimization_options = {\"method\" : \"\",\n",
    "                        \"num_epochs\":10,\n",
    "                       }\n",
    "topK = 1\n",
    "# train models using COLLINS-PERCEPTRON, SAPO\n",
    "for fold in data_split:\n",
    "    train_seqs_id = data_split[fold]['train']\n",
    "    for method in (\"COLLINS-PERCEPTRON\", \"SAPO\"):\n",
    "        optimization_options['method'] = method\n",
    "        if(method == 'SAPO'):\n",
    "            topK = 5\n",
    "        optimization_options['topK'] = topK           \n",
    "        print(\"trianing using optimization options:\")\n",
    "        print(optimization_options)\n",
    "        # make sure we are initializing the weights to be 0\n",
    "        crf_m.weights.fill(0)\n",
    "        model_dir = workflow.train_model(train_seqs_id, crf_m, optimization_options)\n",
    "        print(\"*\"*50)\n",
    "        avg_ll = ReaderWriter.read_data(os.path.join(model_dir, 'avg_decodingerror_training'))\n",
    "        plt.plot(avg_ll[1:], label=\"method:{}, topK:{}\".format(optimization_options['method'], topK))\n",
    "        trained_models_dir[method] = model_dir\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('number of epochs')\n",
    "    plt.ylabel('estimated decoding error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_perceptrontraining_demo2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trianing using optimization options:\n",
      "{'update_type': 'early', 'beam_size': 5, 'method': 'COLLINS-PERCEPTRON', 'topK': 1, 'num_epochs': 10}\n",
      "sequences left 25\n",
      "in early update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in early update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in early update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in early update routine ...\n",
      "sequences left 14\n",
      "in early update routine ...\n",
      "sequences left 13\n",
      "in early update routine ...\n",
      "sequences left 12\n",
      "in early update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in early update routine ...\n",
      "sequences left 8\n",
      "in early update routine ...\n",
      "sequences left 7\n",
      "in early update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in early update routine ...\n",
      "sequences left 4\n",
      "in early update routine ...\n",
      "sequences left 3\n",
      "in early update routine ...\n",
      "sequences left 2\n",
      "in early update routine ...\n",
      "sequences left 1\n",
      "in early update routine ...\n",
      "reldiff = 1.0\n",
      "average error : [0, 0.6388045112781955]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in early update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in early update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in early update routine ...\n",
      "sequences left 14\n",
      "in early update routine ...\n",
      "sequences left 13\n",
      "in early update routine ...\n",
      "sequences left 12\n",
      "in early update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in early update routine ...\n",
      "sequences left 2\n",
      "in early update routine ...\n",
      "sequences left 1\n",
      "in early update routine ...\n",
      "reldiff = 0.3586912339211921\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in early update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in early update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in early update routine ...\n",
      "reldiff = 0.38179498451432975\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in early update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in early update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.012277556525226812\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.24220712129769942\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379, 0.08433822968818715]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.1168339018908714\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379, 0.08433822968818715, 0.06669269719431009]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.37174253236465665\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379, 0.08433822968818715, 0.06669269719431009, 0.030545225551065366]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.011169545335369797\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379, 0.08433822968818715, 0.06669269719431009, 0.030545225551065366, 0.031235285773143443]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.8705193183412996\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379, 0.08433822968818715, 0.06669269719431009, 0.030545225551065366, 0.031235285773143443, 0.002162162162162162]\n",
      "self._exitloop False\n",
      "sequences left 25\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "reldiff = 0.5074139287243898\n",
      "average error : [0, 0.6388045112781955, 0.3015187870985834, 0.1348973100470587, 0.1382509026684379, 0.08433822968818715, 0.06669269719431009, 0.030545225551065366, 0.031235285773143443, 0.002162162162162162, 0.006616657574104382]\n",
      "self._exitloop False\n",
      "**************************************************\n",
      "trianing using optimization options:\n",
      "{'update_type': 'early', 'beam_size': 5, 'method': 'SAPO', 'topK': 5, 'num_epochs': 10}\n",
      "in early update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in early update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in early update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in early update routine ...\n",
      "sequences left 14\n",
      "in early update routine ...\n",
      "sequences left 13\n",
      "in early update routine ...\n",
      "sequences left 12\n",
      "in early update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in early update routine ...\n",
      "sequences left 8\n",
      "in early update routine ...\n",
      "sequences left 7\n",
      "in early update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in early update routine ...\n",
      "sequences left 4\n",
      "in early update routine ...\n",
      "sequences left 3\n",
      "in early update routine ...\n",
      "sequences left 2\n",
      "in early update routine ...\n",
      "sequences left 1\n",
      "in early update routine ...\n",
      "sequences left 0\n",
      "reldiff = 1.0\n",
      "average error : [0, 0.5849884559884561]\n",
      "self._exitloop False\n",
      "in early update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in early update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in early update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in early update routine ...\n",
      "sequences left 14\n",
      "in early update routine ...\n",
      "sequences left 13\n",
      "in early update routine ...\n",
      "sequences left 12\n",
      "in early update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in early update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in early update routine ...\n",
      "sequences left 4\n",
      "in early update routine ...\n",
      "sequences left 3\n",
      "in early update routine ...\n",
      "sequences left 2\n",
      "in early update routine ...\n",
      "sequences left 1\n",
      "in early update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.32246417651821924\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in early update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in early update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in early update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in early update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in early update routine ...\n",
      "sequences left 12\n",
      "in early update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in early update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.30510046850844047\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in early update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in early update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.16843812881132217\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in early update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in early update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.26736421798890686\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283, 0.06565219445279417]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in early update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in early update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.06861519983999292\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283, 0.06565219445279417, 0.07532540028896126]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in early update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.4144010827369444\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283, 0.06565219445279417, 0.07532540028896126, 0.031186679217090077]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in full update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in early update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in early update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.49900965364686495\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283, 0.06565219445279417, 0.07532540028896126, 0.031186679217090077, 0.09331344117088801]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.687048545244188\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283, 0.06565219445279417, 0.07532540028896126, 0.031186679217090077, 0.09331344117088801, 0.01730986179681832]\n",
      "self._exitloop False\n",
      "in full update routine ...\n",
      "sequences left 24\n",
      "in full update routine ...\n",
      "sequences left 23\n",
      "in full update routine ...\n",
      "sequences left 22\n",
      "in early update routine ...\n",
      "sequences left 21\n",
      "in full update routine ...\n",
      "sequences left 20\n",
      "in full update routine ...\n",
      "sequences left 19\n",
      "in full update routine ...\n",
      "sequences left 18\n",
      "in full update routine ...\n",
      "sequences left 17\n",
      "in full update routine ...\n",
      "sequences left 16\n",
      "in full update routine ...\n",
      "sequences left 15\n",
      "in full update routine ...\n",
      "sequences left 14\n",
      "in full update routine ...\n",
      "sequences left 13\n",
      "in full update routine ...\n",
      "sequences left 12\n",
      "in full update routine ...\n",
      "sequences left 11\n",
      "in full update routine ...\n",
      "sequences left 10\n",
      "in full update routine ...\n",
      "sequences left 9\n",
      "in full update routine ...\n",
      "sequences left 8\n",
      "in full update routine ...\n",
      "sequences left 7\n",
      "in full update routine ...\n",
      "sequences left 6\n",
      "in full update routine ...\n",
      "sequences left 5\n",
      "in full update routine ...\n",
      "sequences left 4\n",
      "in full update routine ...\n",
      "sequences left 3\n",
      "in full update routine ...\n",
      "sequences left 2\n",
      "in full update routine ...\n",
      "sequences left 1\n",
      "in full update routine ...\n",
      "sequences left 0\n",
      "reldiff = 0.008228378315698049\n",
      "average error : [0, 0.5849884559884561, 0.29970614122719386, 0.15957825634829528, 0.1135697219886283, 0.06565219445279417, 0.07532540028896126, 0.031186679217090077, 0.09331344117088801, 0.01730986179681832, 0.0175970893970894]\n",
      "self._exitloop False\n",
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqUAAAGmCAYAAABFpP0BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb8UOq+YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcde3ad93c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using beam search with 5 states and early update\n",
    "optimization_options = {\"method\" : \"\",\n",
    "                        \"num_epochs\":10,\n",
    "                        \"beam_size\":5,\n",
    "                        \"update_type\":'early'\n",
    "                        }\n",
    "topK = 1\n",
    "# train models using COLLINS-PERCEPTRON, SAPO\n",
    "for fold in data_split:\n",
    "    train_seqs_id = data_split[fold]['train']\n",
    "    for method in (\"COLLINS-PERCEPTRON\", \"SAPO\"):\n",
    "        optimization_options['method'] = method\n",
    "        if(method == 'SAPO'):\n",
    "            topK = 5\n",
    "        optimization_options['topK'] = topK           \n",
    "        print(\"trianing using optimization options:\")\n",
    "        print(optimization_options)\n",
    "        # make sure we are initializing the weights to be 0\n",
    "        crf_m.weights.fill(0)\n",
    "        model_dir = workflow.train_model(train_seqs_id, crf_m, optimization_options)\n",
    "        print(\"*\"*50)\n",
    "        avg_ll = ReaderWriter.read_data(os.path.join(model_dir, 'avg_decodingerror_training'))\n",
    "        plt.plot(avg_ll[1:], label=\"method:{}, topK:{}, beam_size:5\".format(optimization_options['method'], topK))\n",
    "        trained_models_dir[method] = model_dir\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('number of epochs')\n",
    "    plt.ylabel('estimated decoding error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Using trained CRFs model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final part of the workflow is to evaluate the trained models on test/validation sequences (i.e. sequences that we did not use for building and training the CRFs model). In our previous setup, we used all the sequences for training. We could still test the performance of the trained models on those sequences. Although, we are overfitting here, but it is worth to compare the different training methods using a performance measure. \n",
    "\n",
    "The method <code class=\"pseq_method\">use_model(args)</code> in <code class=\"pseq_class\">GenericWorkflowTrainer</code> class is used for: <br/>\n",
    "<strong>A</strong>) reviving a trained model to decode sequences <br/>\n",
    "<strong>B</strong>) writing the decoded sequences on a file and/or <br/>\n",
    "<strong>C</strong>) evaluating the decoding performance based on a specified metric <br/>\n",
    "\n",
    "The arguments for the <code class=\"pseq_method\">use_model(args)</code> method are:\n",
    "\n",
    "<strong>Args</strong>:\n",
    "<ul>\n",
    "<li><code class=\"pseq_args\">savedmodel_dir</code>: the path to the trained model dumped on disk. In our setting/example, the <code class=\"pseq_var\">trained_models_dir</code> contains the directory of the models we trained.</li>\n",
    "<li>\n",
    "<code class=\"pseq_args\">options</code>: dictionary that specifies options needed to performs tasks (<strong>A</strong>, <strong>B</strong> and <strong>C</strong>). Generally, we have two scenarios:\n",
    "<ul>\n",
    "<li>If we already parsed and processed the sequences like in our example, then we use <code class=\"pseq_var\">seqs_info</code> key, passing the <code class=\"pseq_attr\">seqs_info</code> instance attribute in our workflow trainer (<a href=\"#pseq_wft_seqsinfo_decoding\">see code example</a>).<br/><br/>\n",
    "\n",
    "<strong>Example</strong>: <br/><br/>\n",
    "\n",
    "Sequences are parsed and processed (i.e. using seqs_info)\n",
    "<pre style=\"font-size:0.72em\">\n",
    "options = {'seqs_info': dictionary comprising the processed info of the sequences saved on disk\n",
    "           'seqbatch_size':integer, number of sequences in a batch to process \n",
    "           'model_eval': boolean, deciding if to evaluate performance\n",
    "           'metric': {'f1', 'precision', 'recall', 'accuracy'},\n",
    "           'exclude_states': list of labels to exclude form the decoding evaluation,\n",
    "           'file_name': string, name of the file where decoded sequences will written on,\n",
    "           'sep': string, separator between the columns \n",
    "                 (i.e. the tracks, reference label and predicted label when written on file) \n",
    "           'beam_size': integer, the number of states to keep while decoding with beam search\n",
    "           }\n",
    "</pre>\n",
    "</li>\n",
    "<li>If we have new sequences in a file, then we use <code class=\"pseq_args\">seq_file</code> key, passing the path to the file containing the sequences to decode (<a href=\"#pseq_wft_seqfile_decoding\">see code example</a>).<br/><br/>\n",
    "\n",
    "<strong>Example</strong>: <br/><br/>\n",
    "\n",
    "Sequences are still in a file (i.e. using <code class=\"pseq_args\">seq_file</code>)\n",
    "<pre style=\"font-size:0.72em\">\n",
    "options = {'seqs_file': path to the sequences file\n",
    "           'data_parser_options': dictionary stating the options to be used by the parser\n",
    "                                  for reading the seqs_file (i.e. <a href=\"#pseq_seqfile_option\">see here for more info</a>) \n",
    "           'num_seqs': integer, specifying the maximum number of sequences to read from the given file\n",
    "           'seqbatch_size':integer, number of sequences in a batch to process \n",
    "           'model_eval': boolean, deciding if to evaluate performance\n",
    "           'metric': {'f1', 'precision', 'recall', 'accuracy'},\n",
    "           'exclude_states': list of labels to exclude form the decoding evaluation,\n",
    "           'file_name': string, name of the file where decoded sequences will written on,\n",
    "           'sep': string, separator between the columns\n",
    "                 (i.e. the tracks, reference label and predicted label when written on file) \n",
    "           'beam_size': integer, the number of states to keep while decoding with beam search\n",
    "           }\n",
    "</pre>\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "A direct approach for using a trained CRFs model without the use of <code class=\"pseq_class\">GenericWorkflowTrainer</code> class/subclass is through <code class=\"pseq_method\">generate_trained_model(args)</code> function found in the <code class=\"pseq_code\">utilities</code> module. The function takes the following arguments:\n",
    "\n",
    "<ul>\n",
    "<li><code class=\"pseq_args\">model_parts_dir</code>: directory to the <code class=\"pseq_code\">model_parts</code> folder of a trained CRFs model (<a href=\"#pseq_modelparts_pointer\">see here</a> for a refresher)</li>\n",
    "<li><code class=\"pseq_args\">aextractor_obj</code>: initialized instance of class/subclass of <code class=\"pseq_class\">GenericAttributeExtractor</code></li>\n",
    "</ul>\n",
    "\n",
    "Below is <a href=\"#pseq_reviveandusemodel_demo\">an example</a> on reviving a trained model (the trained model used <code class=\"pseq_code\">COLLINS-PERCEPTRON</code> method). Once, we have the revived model, it is ready for decoding sequences. For that purpose, we use the main decoding method  \n",
    "<code class=\"pseq_method\">decode_seqs(decoding_method, out_dir, **kwargs)</code> (<a href=\"#pseq_reviveandusemodel_demo\">see code for a demo</a>)\n",
    "<br/>\n",
    "\n",
    "<strong>Args</strong>:\n",
    "\n",
    "<ol>\n",
    "<li>\n",
    "<code class=\"pseq_args\">decoding_method</code>: string defining the decoding method. It is one of <code class=\"pseq_code\">{'viterbi', 'per_state_decoding'}</code>. As not all decoders support <code class=\"pseq_code\">'per_state_decoding'</code>, we primarily use <code class=\"pseq_code\">'viterbi'</code> for now.\n",
    "</li>\n",
    "<li>\n",
    "<code class=\"pseq_args\">out_dir</code>: string representing the path to the output directory where sequence parsing will take place\n",
    "</li>\n",
    "</ol>\n",
    "\n",
    "<br/>\n",
    "<strong>Keyword arguments</strong>:\n",
    "\n",
    "The main ones to specify are:<br/>\n",
    "\n",
    "<ul>\n",
    "<li>\n",
    "We choose one of the following options <code class=\"pseq_code\">{'seqs', 'seqs_dict', 'seqs_info'}</code>\n",
    "<ul>\n",
    "<li>\n",
    "<code class=\"pseq_args\">seqs</code>: list of sequences that are instances of <code class=\"pseq_class\">SequenceStruct</code> class\n",
    "</li>\n",
    "<li><code class=\"pseq_args\">seqs_dict</code>: a dictionary comprising of ids as keys (i.e. representing sequence ids) and corresponding sequences that are instances of <code class=\"pseq_class\">SequenceStruct</code> class as values\n",
    "</li>\n",
    "<li><code class=\"pseq_args\">seqs_info</code>: dictionary containing the info about already parsed and processed sequences\n",
    "</li>\n",
    "</ul>\n",
    "</li>\n",
    "<li>\n",
    "<code class=\"pseq_args\">file_name</code>: string representing the name of the file where the CRFs model writes the decoded sequences to (it is optional)\n",
    "</li>\n",
    "<li>\n",
    "<code class=\"pseq_args\">sep</code>: string representing separator between the columns/observations when writing decoded sequences on the specified file using <code class=\"pseq_args\">file_name</code> keyword argument\n",
    "</li>\n",
    "</ul>\n",
    "\n",
    "Now that we know how to revive a CRFs model and decode sequences, we need to evaluate how good is our decoding. This will be tackled using <code class=\"pseq_class\">SeqDecodingEvaluator</code> class. Its constructor takes an instance of a CRFs model representation class (<a href=\"#pseq_crfmodels_repr_map\">see this table</a> for a refresher). This is an <a href=\"#pseq_seqdecodingevaluator_class\">example</a> demonstrating the use of <code class=\"pseq_class\">SeqDecodingEvaluator</code> class for evaluating the decoded sequences by our revived model. In addition, it shows how to obtain/show the confusion matrix for every decoded label/state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_wft_seqsinfo_decoding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seqs_info option\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.839031339031339\n",
      "model trained using SGA-ADADELTA method\n",
      "metric:f1, value:0.839031339031339\n",
      "\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 1.0\n",
      "model trained using L-BFGS-B method\n",
      "metric:f1, value:1.0\n",
      "\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9602272727272727\n",
      "model trained using SGA method\n",
      "metric:f1, value:0.9602272727272727\n",
      "\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9793887704335464\n",
      "model trained using SAPO method\n",
      "metric:f1, value:0.9793887704335464\n",
      "\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9758522727272727\n",
      "model trained using SVRG method\n",
      "metric:f1, value:0.9758522727272727\n",
      "\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9679715302491104\n",
      "model trained using COLLINS-PERCEPTRON method\n",
      "metric:f1, value:0.9679715302491104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# case of using seqs_info\n",
    "# eval_options used:\n",
    "# seqs_info since we already parsed and processed the sequences\n",
    "# model_eval = True -- we need to evaluate model performance\n",
    "# metric = f1 -- F1 score\n",
    "# the other keys are not specified and hence by default, we will not write the decoded sequences to file \n",
    "# using full beam\n",
    "use_options = {'seqs_info':workflow.seqs_info,\n",
    "                'model_eval':True,\n",
    "                'metric':'f1'\n",
    "               }\n",
    "print(\"Using seqs_info option\")\n",
    "for method, model_dir in trained_models_dir.items():\n",
    "    perf = workflow.use_model(model_dir, use_options)\n",
    "    print(\"model trained using {} method\".format(method))\n",
    "    metric_chosen = use_options['metric']\n",
    "    print(\"metric:{}, value:{}\".format(metric_chosen, perf[metric_chosen]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_wft_seqfile_decoding\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using seq_file option\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.839031339031339\n",
      "model trained using SGA-ADADELTA method\n",
      "metric:f1, value:0.839031339031339\n",
      "\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 1.0\n",
      "model trained using L-BFGS-B method\n",
      "metric:f1, value:1.0\n",
      "\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9602272727272727\n",
      "model trained using SGA method\n",
      "metric:f1, value:0.9602272727272727\n",
      "\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9793887704335464\n",
      "model trained using SAPO method\n",
      "metric:f1, value:0.9793887704335464\n",
      "\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9758522727272727\n",
      "model trained using SVRG method\n",
      "metric:f1, value:0.9758522727272727\n",
      "\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "f1 0.9679715302491104\n",
      "model trained using COLLINS-PERCEPTRON method\n",
      "metric:f1, value:0.9679715302491104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_file = os.path.join(dataset_dir, 'train.txt')\n",
    "#case of using seq_file\n",
    "# eval_options used:\n",
    "# seq_file path to the CoNLL train.txt file\n",
    "# data_parser_optoins dictionary to parse the train.txt file\n",
    "# model_eval = True -- we need to evaluate model performance\n",
    "# metric = f1 -- F1 score\n",
    "# the other keys are not specified and hence by default, we will not write the decoded sequences to file \n",
    "# using full beam\n",
    "parser_options = {'header': 'main', # main means the header is found in the first line of the file\n",
    "                  'y_ref':True, # y_ref is a boolean indicating if the label to predict is already found in the file\n",
    "                  'column_sep': \" \",\n",
    "                  'seg_other_symbol':None # spearator between the words/observations\n",
    "                  }\n",
    "use_options = {'seq_file':train_file,\n",
    "               'data_parser_options':parser_options,\n",
    "               'num_seqs':25,\n",
    "               'model_eval':True,\n",
    "               'metric':'f1'\n",
    "              }\n",
    "print(\"Using seq_file option\")\n",
    "for method, model_dir in trained_models_dir.items():\n",
    "    perf = workflow.use_model(model_dir, use_options)\n",
    "    print(\"model trained using {} method\".format(method))\n",
    "    metric_chosen = use_options['metric']\n",
    "    print(\"metric:{}, value:{}\".format(metric_chosen, perf[metric_chosen]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_reviveandusemodel_demo\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyseqlab.fo_crf.FirstOrderCRF object at 0x7fcdbd6af908>\n",
      "\n",
      "identifying model active features -- processed seqs:  1\n",
      "identifying model active features -- processed seqs:  2\n",
      "identifying model active features -- processed seqs:  3\n",
      "identifying model active features -- processed seqs:  4\n",
      "identifying model active features -- processed seqs:  5\n",
      "identifying model active features -- processed seqs:  6\n",
      "identifying model active features -- processed seqs:  7\n",
      "identifying model active features -- processed seqs:  8\n",
      "identifying model active features -- processed seqs:  9\n",
      "identifying model active features -- processed seqs:  10\n",
      "identifying model active features -- processed seqs:  11\n",
      "identifying model active features -- processed seqs:  12\n",
      "identifying model active features -- processed seqs:  13\n",
      "identifying model active features -- processed seqs:  14\n",
      "identifying model active features -- processed seqs:  15\n",
      "identifying model active features -- processed seqs:  16\n",
      "identifying model active features -- processed seqs:  17\n",
      "identifying model active features -- processed seqs:  18\n",
      "identifying model active features -- processed seqs:  19\n",
      "identifying model active features -- processed seqs:  20\n",
      "identifying model active features -- processed seqs:  21\n",
      "identifying model active features -- processed seqs:  22\n",
      "identifying model active features -- processed seqs:  23\n",
      "identifying model active features -- processed seqs:  24\n",
      "identifying model active features -- processed seqs:  25\n",
      "sequence decoded -- 24 sequences are left\n",
      "sequence decoded -- 23 sequences are left\n",
      "sequence decoded -- 22 sequences are left\n",
      "sequence decoded -- 21 sequences are left\n",
      "sequence decoded -- 20 sequences are left\n",
      "sequence decoded -- 19 sequences are left\n",
      "sequence decoded -- 18 sequences are left\n",
      "sequence decoded -- 17 sequences are left\n",
      "sequence decoded -- 16 sequences are left\n",
      "sequence decoded -- 15 sequences are left\n",
      "sequence decoded -- 14 sequences are left\n",
      "sequence decoded -- 13 sequences are left\n",
      "sequence decoded -- 12 sequences are left\n",
      "sequence decoded -- 11 sequences are left\n",
      "sequence decoded -- 10 sequences are left\n",
      "sequence decoded -- 9 sequences are left\n",
      "sequence decoded -- 8 sequences are left\n",
      "sequence decoded -- 7 sequences are left\n",
      "sequence decoded -- 6 sequences are left\n",
      "sequence decoded -- 5 sequences are left\n",
      "sequence decoded -- 4 sequences are left\n",
      "sequence decoded -- 3 sequences are left\n",
      "sequence decoded -- 2 sequences are left\n",
      "sequence decoded -- 1 sequences are left\n",
      "sequence decoded -- 0 sequences are left\n",
      "\n",
      "seq_id  1\n",
      "predicted labels:\n",
      "['B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'B-ADJP', 'B-PP', 'B-NP', 'I-NP', 'O', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'B-ADJP', 'B-PP', 'B-NP', 'B-NP', 'O', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  2\n",
      "predicted labels:\n",
      "['O', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['O', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  3\n",
      "predicted labels:\n",
      "['O', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['O', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  4\n",
      "predicted labels:\n",
      "['B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'O', 'B-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'O', 'B-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  5\n",
      "predicted labels:\n",
      "['O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'B-ADVP', 'I-ADVP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'O', 'B-VP', 'B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'B-ADVP', 'I-ADVP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'O', 'B-VP', 'B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  6\n",
      "predicted labels:\n",
      "['O', 'B-SBAR', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'O', 'B-VP', 'B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['O', 'B-SBAR', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'O', 'B-VP', 'B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  7\n",
      "predicted labels:\n",
      "['B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-ADVP', 'O', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'O', 'B-ADJP', 'O', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-ADVP', 'O', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'O', 'O', 'O', 'O', 'O', 'B-ADJP', 'O', 'O', 'O', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  8\n",
      "predicted labels:\n",
      "['B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'B-ADJP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'B-ADVP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  9\n",
      "predicted labels:\n",
      "['B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-SBAR', 'B-NP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-SBAR', 'B-NP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'B-VP', 'I-VP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  10\n",
      "predicted labels:\n",
      "['B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'B-VP', 'B-ADJP', 'I-ADJP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'B-VP', 'B-ADJP', 'I-ADJP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  11\n",
      "predicted labels:\n",
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  12\n",
      "predicted labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  13\n",
      "predicted labels:\n",
      "['B-PP', 'B-PP', 'B-ADVP', 'I-ADVP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-ADJP', 'I-ADJP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-PP', 'B-PP', 'B-ADVP', 'I-ADVP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  14\n",
      "predicted labels:\n",
      "['B-NP', 'I-NP', 'O', 'B-NP', 'B-ADVP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-VP', 'B-SBAR', 'B-SBAR', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-ADJP', 'B-PP', 'B-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'I-NP', 'O', 'B-NP', 'B-ADVP', 'B-VP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-VP', 'B-SBAR', 'B-SBAR', 'I-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-ADJP', 'B-PP', 'B-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-VP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  15\n",
      "predicted labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'B-VP', 'O', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'B-VP', 'O', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  16\n",
      "predicted labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'B-ADJP', 'I-ADJP', 'O']\n",
      "refernce labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'B-ADJP', 'I-ADJP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  17\n",
      "predicted labels:\n",
      "['B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'B-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  18\n",
      "predicted labels:\n",
      "['B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  19\n",
      "predicted labels:\n",
      "['O', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-ADVP', 'I-ADVP', 'O']\n",
      "refernce labels:\n",
      "['O', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-ADVP', 'I-ADVP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  20\n",
      "predicted labels:\n",
      "['B-NP', 'I-NP', 'B-VP', 'O', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-VP', 'B-ADVP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-ADVP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'I-NP', 'B-VP', 'O', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-VP', 'B-ADVP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-ADVP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  21\n",
      "predicted labels:\n",
      "['B-NP', 'B-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'B-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  22\n",
      "predicted labels:\n",
      "['B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'O', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'O', 'O', 'O', 'B-NP', 'B-SBAR', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'B-PP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'B-VP', 'B-NP', 'I-NP', 'O', 'B-VP', 'B-ADVP', 'B-ADJP', 'I-ADJP', 'O', 'O', 'O', 'B-NP', 'B-SBAR', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'B-PP', 'B-NP', 'B-PP', 'I-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  23\n",
      "predicted labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'B-ADJP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-ADVP', 'B-SBAR', 'B-ADJP', 'B-VP', 'I-VP', 'I-VP', 'B-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'O']\n",
      "refernce labels:\n",
      "['B-ADVP', 'O', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'B-ADJP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-ADVP', 'B-SBAR', 'B-ADJP', 'B-VP', 'I-VP', 'I-VP', 'B-SBAR', 'B-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'B-NP', 'O', 'O', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-ADVP', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  24\n",
      "predicted labels:\n",
      "['B-NP', 'O', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'O', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'O', 'B-NP', 'B-VP', 'B-NP', 'I-NP', 'B-SBAR', 'B-NP', 'I-NP', 'O', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O', 'O']\n",
      "--------------------------------------------------\n",
      "seq_id  25\n",
      "predicted labels:\n",
      "['B-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'B-ADJP', 'B-PP', 'B-NP', 'I-NP', 'B-ADJP', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-ADJP', 'B-SBAR', 'B-ADJP', 'O']\n",
      "refernce labels:\n",
      "['B-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'B-VP', 'B-NP', 'B-ADJP', 'B-PP', 'B-NP', 'I-NP', 'B-ADJP', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-SBAR', 'B-NP', 'B-VP', 'I-VP', 'I-VP', 'B-ADJP', 'B-SBAR', 'B-ADJP', 'O']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#print(trained_models_dir)\n",
    "from pyseqlab.utilities import generate_trained_model\n",
    "# revive a model that was trained using COLLINS-PERCEPTRON method\n",
    "model_parts_dir = os.path.join(trained_models_dir['COLLINS-PERCEPTRON'], 'model_parts')\n",
    "crf_percep = generate_trained_model(model_parts_dir, generic_attr_extractor)\n",
    "print(crf_percep)\n",
    "print()\n",
    "\n",
    "# use viterbi for decoding\n",
    "decoding_method = 'viterbi'\n",
    "# use the same directory of the model\n",
    "output_dir = trained_models_dir['COLLINS-PERCEPTRON']\n",
    "# use tab as separator\n",
    "sep = \"\\t\"\n",
    "decoded_sequences = crf_percep.decode_seqs(decoding_method, output_dir, seqs= seqs[:25], file_name = 'tutorial_seqs_decoding.txt', sep=sep)\n",
    "print()\n",
    "# display the decoded sequnces\n",
    "for seq_id in decoded_sequences:\n",
    "    print(\"seq_id \", seq_id)\n",
    "    print(\"predicted labels:\")\n",
    "    print(decoded_sequences[seq_id]['Y_pred'])\n",
    "    print(\"refernce labels:\")\n",
    "    print(decoded_sequences[seq_id]['seq'].flat_y)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pseq_seqdecodingevaluator_class\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.9679715302491104\n",
      "precision 0.9700427960057061\n",
      "recall 0.9659090909090909\n",
      "accuracy 0.9913892078071183\n",
      "\n",
      "confusion_matrix for state=I-NP: \n",
      "[[ 200.    6.]\n",
      " [   3.  495.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=I-ADVP: \n",
      "[[  3.   0.]\n",
      " [  0.  72.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=B-VP: \n",
      "[[  66.    1.]\n",
      " [   3.  634.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=B-SBAR: \n",
      "[[  14.    0.]\n",
      " [   3.  334.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=I-VP: \n",
      "[[  53.    0.]\n",
      " [   1.  520.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=B-ADVP: \n",
      "[[  13.    0.]\n",
      " [   2.  332.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=I-ADJP: \n",
      "[[  3.   0.]\n",
      " [  0.  69.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=B-ADJP: \n",
      "[[  12.    0.]\n",
      " [   0.  246.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=B-PP: \n",
      "[[  72.    7.]\n",
      " [   0.  570.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=B-NP: \n",
      "[[ 168.    7.]\n",
      " [   5.  524.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=I-SBAR: \n",
      "[[  0.   0.]\n",
      " [  1.  46.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=I-PP: \n",
      "[[  0.   0.]\n",
      " [  1.  36.]]\n",
      "----------------------------------------\n",
      "confusion_matrix for state=O: \n",
      "[[  76.    0.]\n",
      " [   5.  623.]]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pyseqlab.crf_learning import SeqDecodingEvaluator\n",
    "# initialize an evaluator\n",
    "evaluator = SeqDecodingEvaluator(crf_percep.model)\n",
    "# evaluate performance \n",
    "Y_seqs_dict = GenericTrainingWorkflow.map_pred_to_ref_seqs(decoded_sequences)\n",
    "taglevel_perf = evaluator.compute_states_confmatrix(Y_seqs_dict)\n",
    "perf = evaluator.get_performance_metric(taglevel_perf, \"f1\", exclude_states=[])\n",
    "perf = evaluator.get_performance_metric(taglevel_perf, \"precision\", exclude_states=[])\n",
    "perf = evaluator.get_performance_metric(taglevel_perf, \"recall\", exclude_states=[])\n",
    "perf = evaluator.get_performance_metric(taglevel_perf, \"accuracy\", exclude_states=[])\n",
    "print()\n",
    "# demonstrate confusion matrix per label/state\n",
    "for state, code in crf_percep.model.Y_codebook.items():\n",
    "    print(\"confusion_matrix for state={}: \".format(state))\n",
    "    print(taglevel_perf[code])\n",
    "    print(\"-\"*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are still many aspects to explore and experiment with. We show the potentials of the package by developing [applications](/applications) in three different areas:\n",
    "<ol>\n",
    "<li>Natural language processing (i.e. shallow parsing, part-of-speech tagging, bio-medical named entity recognition)</li>\n",
    "<li>Wearable and sensor measurement sequences (human activity recognition)</li>\n",
    "<li>Classification of Eukaryotic splice-junction sequences</li>\n",
    "</ol>\n",
    "\n",
    "Each application has its own repository including notebook tutorials showing the:\n",
    "<ul>\n",
    "<li> statement of the problem</li>\n",
    "<li> model building and training procedure</li>\n",
    "<li> evaluation of the decoding performance </li>\n",
    "<li> process of reviving and using the trained models </li>\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References & relevant literature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottou, L., & Le Cun, Y. (2004). Large Scale Online Learning. Advances in Neural Information Processing Systems, 16, 217–225.\n",
    "\n",
    "Collins, M. (2002). Discriminative training methods for hidden Markov models: theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - EMNLP ’02 (pp. 1–8). doi:10.3115/1118693.1118694\n",
    "\n",
    "Cuong, V. N., Ye, N., Lee, W. S., & Chieu, H. L. (2014). Conditional Random Field with High-order Dependencies for Sequence Labeling and Segmentation. Journal of Machine Learning Research, 15, 981–1009.\n",
    "Huang, L., Fayong, S., & Guo, Y. (2012). Structured perceptron with inexact search. 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 142–151. Retrieved from http://dl.acm.org/citation.cfm?id=2382029.2382049\n",
    "\n",
    "Johnson, R., & Zhang, T. (2013). Accelerating Stochastic Gradient Descent using Predictive Variance Reduction. Advances in Neural Information Processing Systems 26, 1(3), 315–323. \n",
    "\n",
    "Kim, J.-D., Ohta, T., Tsuruoka, Y., Tateisi, Y., & Collier, N. (2004). Introduction to the Bio-entity Recognition Task at JNLPBA. Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and Its Applications, 70–75. doi:10.3115/1567594.1567610\n",
    "\n",
    "Lafferty, J., McCallum, A., & Pereira, F. C. N. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. ICML ’01 Proceedings of the Eighteenth International Conference on Machine Learning, 8(June), 282–289. doi:10.1038/nprot.2006.61\n",
    "\n",
    "Sarawagi, S., & Cohen, W. W. (2005). Semi-Markov Conditional Random Fields for Information Extraction. Advances in Neural Information Processing Systems, 1185–1192. doi:10.1.1.128.3524\n",
    "\n",
    "Soong, F. K., & Huang, E.-F. (1990). A tree-trellis based fast search for finding the N Best sentence hypotheses in continuous speech recognition. Proceedings of the Workshop on Speech and Natural Language - HLT ’90, 12–19. doi:10.3115/116580.116591\n",
    "\n",
    "Sun, X. (2015). Towards Shockingly Easy Structured Classification: A Search-based Probabilistic Online Learning Framework. Retrieved from http://arxiv.org/abs/1503.08381\n",
    "\n",
    "Tsuruoka, Y., Tsujii, J., & Ananiadou, S. (2009). Stochastic gradient descent training for L1-regularized log-linear models with cumulative penalty. Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 1, 477. doi:10.3115/1687878.1687946\n",
    "Vieira, T., Cotterell, R., & Eisner, J. (2016). Speed-Accuracy Tradeoffs in Tagging with Variable-Order CRFs and Structured Sparsity. In EMNLP.\n",
    "\n",
    "Viterbi, A. (1967). Error bounds for convolutional codes and an asymptotically optimum decoding algorithm. IEEE Transactions on Information Theory, 13(2), 260–269. doi:10.1109/TIT.1967.1054010\n",
    "Ye, N., Lee, W. S., Chieu, H. L., & Wu, D. (2009). Conditional Random Fields with High-Order Features for Sequence Labeling. Neural Information Processing Systems, 2, 2. Retrieved from http://www.comp.nus.edu.sg/~leews/publications/nips09_paper.pdf\n",
    "\n",
    "Zeiler, M. D. (2012). ADADELTA: An Adaptive Learning Rate Method. Retrieved from http://arxiv.org/abs/1212.5701\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
